{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=physical_devices[0], device_type='GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义matries 计算r2\n",
    "def R2(y_true, y_pred):\n",
    "    sst = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    ssr = K.sum(K.square(y_pred - y_true))\n",
    "    R2 = 1 - ssr/sst\n",
    "    return R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mode = 'model' # parameter\n",
    "max_trials = 26\n",
    "batch_size = 4096*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Choices\n",
    "units_choice = [[32,64,64,64],[32,64,64,128],[32,64,128,128],[32,128,128,128],[32,64,128,256]\n",
    "                       [64,128,128,128],[64,128,128,256],[64,128,256,256],[64,256,256,256],[64,128,256,512],\n",
    "                       [64,128,128,128,256],[64,128,128,256,256],[64,128,256,256,512]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the keras tuner model.\n",
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    \n",
    "    def build(self, hp):\n",
    "        input_layer = layers.Input(shape = (18,1))\n",
    "        out = input_layer\n",
    "        units_choices = [[32,64,64,64],[32,64,64,128],[32,64,128,128],[32,128,128,128],[32,64,128,256],\n",
    "                       [64,128,128,128],[64,128,128,256],[64,128,256,256],[64,256,256,256],[64,128,256,512],\n",
    "                       [64,128,128,128,256],[64,128,128,256,256],[64,128,256,256,512]]\n",
    "        choice = hp.Choice('units_choice',values = [i for i in range(len(units_choices))])\n",
    "        for unit in units_choices[choice]:\n",
    "            out = layers.Conv1D(filters=unit,kernel_size=hp.Choice('kernel_size',values = [3,5]),padding='same')(out)\n",
    "            out = layers.BatchNormalization(momentum=0.8)(out)\n",
    "            out = layers.Activation('relu')(out)\n",
    "\n",
    "        out = layers.Flatten()(out)\n",
    "        out = layers.BatchNormalization(momentum=0.8)(out)\n",
    "        drop = hp.Boolean('dropout')\n",
    "        out = layers.Dense(units=256,activation='relu')(out)\n",
    "        if drop:\n",
    "            out = layers.Dropout(0.2)(out)\n",
    "\n",
    "        out = layers.Dense(units=256,activation='relu')(out)\n",
    "        if drop:\n",
    "            out = layers.Dropout(0.2)(out)\n",
    "\n",
    "        out = layers.Dense(units=128,activation='relu')(out)\n",
    "        if drop:\n",
    "            out = layers.Dropout(0.2)(out) \n",
    "\n",
    "        final_out =  layers.Dense(1,activation=hp.Choice('activate_dense1',values = ['linear','sigmoid']))(out)\n",
    "        model = keras.Model(inputs = input_layer, outputs = final_out)\n",
    "        learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),loss='mse',metrics=[R2,'mae'])\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (426038, 18, 1)\n",
      "X_validate shape: (127812, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2001\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 10m 58s]\n",
      "val_R2: 0.46270227432250977\n",
      "\n",
      "Best val_R2 So Far: 0.8359763622283936\n",
      "Total elapsed time: 02h 06m 06s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00122, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2001_best.hdf5\n",
      "27/27 - 8s - loss: 0.0011 - R2: 0.8535 - mae: 0.0244 - val_loss: 0.0012 - val_R2: 0.8361 - val_mae: 0.0260 - lr: 1.4993e-06 - 8s/epoch - 295ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8482 - mae: 0.0244 - val_loss: 0.0012 - val_R2: 0.8325 - val_mae: 0.0262 - lr: 1.4993e-06 - 6s/epoch - 224ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8559 - mae: 0.0244 - val_loss: 0.0013 - val_R2: 0.8257 - val_mae: 0.0272 - lr: 1.4993e-06 - 6s/epoch - 212ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8548 - mae: 0.0244 - val_loss: 0.0012 - val_R2: 0.8352 - val_mae: 0.0262 - lr: 1.4993e-06 - 6s/epoch - 226ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8562 - mae: 0.0244 - val_loss: 0.0012 - val_R2: 0.8360 - val_mae: 0.0260 - lr: 1.4993e-06 - 6s/epoch - 225ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss improved from 0.00122 to 0.00122, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2001_best.hdf5\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8563 - mae: 0.0244 - val_loss: 0.0012 - val_R2: 0.8363 - val_mae: 0.0260 - lr: 1.4993e-06 - 6s/epoch - 234ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8521 - mae: 0.0244 - val_loss: 0.0013 - val_R2: 0.8254 - val_mae: 0.0273 - lr: 1.4993e-06 - 6s/epoch - 227ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8560 - mae: 0.0244 - val_loss: 0.0012 - val_R2: 0.8347 - val_mae: 0.0262 - lr: 1.4993e-06 - 6s/epoch - 225ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8551 - mae: 0.0243 - val_loss: 0.0013 - val_R2: 0.8322 - val_mae: 0.0265 - lr: 1.4993e-06 - 6s/epoch - 225ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8549 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8356 - val_mae: 0.0261 - lr: 1.4993e-06 - 6s/epoch - 228ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8534 - mae: 0.0244 - val_loss: 0.0012 - val_R2: 0.8360 - val_mae: 0.0260 - lr: 1.4993e-06 - 6s/epoch - 228ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8559 - mae: 0.0244 - val_loss: 0.0013 - val_R2: 0.8204 - val_mae: 0.0279 - lr: 1.4993e-06 - 6s/epoch - 228ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss improved from 0.00122 to 0.00122, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2001_best.hdf5\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8579 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8363 - val_mae: 0.0260 - lr: 1.4993e-06 - 6s/epoch - 235ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8527 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8354 - val_mae: 0.0260 - lr: 1.4993e-06 - 6s/epoch - 227ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8578 - mae: 0.0244 - val_loss: 0.0013 - val_R2: 0.8270 - val_mae: 0.0271 - lr: 1.4993e-06 - 6s/epoch - 228ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8564 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8357 - val_mae: 0.0261 - lr: 1.4993e-06 - 6s/epoch - 214ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.7953 - mae: 0.0243 - val_loss: 0.0150 - val_R2: -1.0105e+00 - val_mae: 0.1002 - lr: 1.4993e-06 - 6s/epoch - 218ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8562 - mae: 0.0243 - val_loss: 0.0014 - val_R2: 0.8100 - val_mae: 0.0286 - lr: 1.4993e-06 - 6s/epoch - 220ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8548 - mae: 0.0244 - val_loss: 0.0012 - val_R2: 0.8350 - val_mae: 0.0263 - lr: 1.4993e-06 - 6s/epoch - 218ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss improved from 0.00122 to 0.00122, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2001_best.hdf5\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8557 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8364 - val_mae: 0.0259 - lr: 1.4993e-06 - 6s/epoch - 227ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8565 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8364 - val_mae: 0.0259 - lr: 1.4993e-06 - 6s/epoch - 215ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8556 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8328 - val_mae: 0.0264 - lr: 1.4993e-06 - 6s/epoch - 217ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8590 - mae: 0.0243 - val_loss: 0.0013 - val_R2: 0.8316 - val_mae: 0.0266 - lr: 1.4993e-06 - 6s/epoch - 219ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8573 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8340 - val_mae: 0.0264 - lr: 1.4993e-06 - 6s/epoch - 218ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8566 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8360 - val_mae: 0.0261 - lr: 1.4993e-06 - 6s/epoch - 218ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8562 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8360 - val_mae: 0.0261 - lr: 1.4993e-06 - 6s/epoch - 217ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8554 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8364 - val_mae: 0.0260 - lr: 1.4993e-06 - 6s/epoch - 218ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8593 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8363 - val_mae: 0.0260 - lr: 1.4993e-06 - 6s/epoch - 218ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8583 - mae: 0.0243 - val_loss: 0.0013 - val_R2: 0.8266 - val_mae: 0.0271 - lr: 1.4993e-06 - 6s/epoch - 217ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8577 - mae: 0.0243 - val_loss: 0.0013 - val_R2: 0.8254 - val_mae: 0.0274 - lr: 1.4993e-06 - 6s/epoch - 213ms/step\n",
      "lr changed to 1.4992879187047948e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8584 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8364 - val_mae: 0.0260 - lr: 1.4993e-07 - 6s/epoch - 221ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8569 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8354 - val_mae: 0.0260 - lr: 1.4993e-07 - 6s/epoch - 220ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8551 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8347 - val_mae: 0.0262 - lr: 1.4993e-07 - 6s/epoch - 226ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8576 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8350 - val_mae: 0.0262 - lr: 1.4993e-07 - 6s/epoch - 222ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8560 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8362 - val_mae: 0.0260 - lr: 1.4993e-07 - 6s/epoch - 220ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00122\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8581 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8357 - val_mae: 0.0261 - lr: 1.4993e-07 - 6s/epoch - 222ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss improved from 0.00122 to 0.00121, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2001_best.hdf5\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8550 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8370 - val_mae: 0.0259 - lr: 1.4993e-07 - 6s/epoch - 231ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8536 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8347 - val_mae: 0.0263 - lr: 1.4993e-07 - 6s/epoch - 223ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8559 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8367 - val_mae: 0.0259 - lr: 1.4993e-07 - 6s/epoch - 220ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8506 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8341 - val_mae: 0.0261 - lr: 1.4993e-07 - 6s/epoch - 219ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8569 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8352 - val_mae: 0.0262 - lr: 1.4993e-07 - 6s/epoch - 221ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8592 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8330 - val_mae: 0.0265 - lr: 1.4993e-07 - 6s/epoch - 220ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8533 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8350 - val_mae: 0.0261 - lr: 1.4993e-07 - 6s/epoch - 221ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8551 - mae: 0.0243 - val_loss: 0.0013 - val_R2: 0.8238 - val_mae: 0.0275 - lr: 1.4993e-07 - 6s/epoch - 218ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8572 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8365 - val_mae: 0.0261 - lr: 1.4993e-07 - 6s/epoch - 221ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8530 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8358 - val_mae: 0.0261 - lr: 1.4993e-07 - 6s/epoch - 207ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8575 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8352 - val_mae: 0.0262 - lr: 1.4993e-07 - 6s/epoch - 216ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8570 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8370 - val_mae: 0.0260 - lr: 1.4993e-07 - 6s/epoch - 219ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8534 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8357 - val_mae: 0.0260 - lr: 1.4993e-07 - 6s/epoch - 219ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8573 - mae: 0.0243 - val_loss: 0.0012 - val_R2: 0.8368 - val_mae: 0.0260 - lr: 1.4993e-07 - 6s/epoch - 214ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8598 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8355 - val_mae: 0.0261 - lr: 1.4993e-07 - 6s/epoch - 215ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0011 - R2: 0.8562 - mae: 0.0243 - val_loss: 0.0013 - val_R2: 0.8203 - val_mae: 0.0278 - lr: 1.4993e-07 - 6s/epoch - 213ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8562 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8351 - val_mae: 0.0262 - lr: 1.4993e-07 - 6s/epoch - 217ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8577 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8357 - val_mae: 0.0261 - lr: 1.4993e-07 - 6s/epoch - 213ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8585 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8359 - val_mae: 0.0261 - lr: 1.4993e-07 - 6s/epoch - 218ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8560 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8365 - val_mae: 0.0260 - lr: 1.4993e-07 - 6s/epoch - 215ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8544 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8359 - val_mae: 0.0262 - lr: 1.4993e-07 - 6s/epoch - 214ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8594 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8357 - val_mae: 0.0262 - lr: 1.4993e-07 - 6s/epoch - 214ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8593 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8358 - val_mae: 0.0261 - lr: 1.4993e-07 - 6s/epoch - 211ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8576 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8341 - val_mae: 0.0262 - lr: 1.4993e-07 - 6s/epoch - 216ms/step\n",
      "lr changed to 1.4992879471265043e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8572 - mae: 0.0242 - val_loss: 0.0014 - val_R2: 0.8183 - val_mae: 0.0281 - lr: 1.4993e-08 - 6s/epoch - 221ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8551 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8358 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 220ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8594 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8344 - val_mae: 0.0262 - lr: 1.4993e-08 - 6s/epoch - 225ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8436 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8346 - val_mae: 0.0262 - lr: 1.4993e-08 - 6s/epoch - 217ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8584 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8356 - val_mae: 0.0262 - lr: 1.4993e-08 - 6s/epoch - 217ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8584 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8352 - val_mae: 0.0263 - lr: 1.4993e-08 - 6s/epoch - 218ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8532 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8351 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 218ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8572 - mae: 0.0242 - val_loss: 0.0013 - val_R2: 0.8241 - val_mae: 0.0275 - lr: 1.4993e-08 - 6s/epoch - 221ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8583 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8353 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 217ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8578 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8368 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 220ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8565 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8367 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 218ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss improved from 0.00121 to 0.00121, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2001_best.hdf5\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8604 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8370 - val_mae: 0.0259 - lr: 1.4993e-08 - 6s/epoch - 232ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8528 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8353 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 222ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8546 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8369 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 218ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8594 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8370 - val_mae: 0.0259 - lr: 1.4993e-08 - 6s/epoch - 209ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8584 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8340 - val_mae: 0.0264 - lr: 1.4993e-08 - 6s/epoch - 215ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8597 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8365 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 218ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8573 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8359 - val_mae: 0.0261 - lr: 1.4993e-08 - 6s/epoch - 217ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8587 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8344 - val_mae: 0.0263 - lr: 1.4993e-08 - 6s/epoch - 217ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8578 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8364 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 217ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8597 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8362 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 216ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8591 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8369 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 218ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8579 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8365 - val_mae: 0.0261 - lr: 1.4993e-08 - 6s/epoch - 214ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8563 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8361 - val_mae: 0.0261 - lr: 1.4993e-08 - 6s/epoch - 217ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8590 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8359 - val_mae: 0.0261 - lr: 1.4993e-08 - 6s/epoch - 215ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8509 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8346 - val_mae: 0.0263 - lr: 1.4993e-08 - 6s/epoch - 217ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8565 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8363 - val_mae: 0.0260 - lr: 1.4993e-08 - 6s/epoch - 215ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8570 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8363 - val_mae: 0.0261 - lr: 1.4993e-08 - 6s/epoch - 216ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8566 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8344 - val_mae: 0.0262 - lr: 1.4993e-08 - 6s/epoch - 235ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00121\n",
      "27/27 - 7s - loss: 0.0010 - R2: 0.8583 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8364 - val_mae: 0.0261 - lr: 1.4993e-08 - 7s/epoch - 241ms/step\n",
      "lr changed to 1.4992879826536411e-09\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00121\n",
      "27/27 - 7s - loss: 0.0010 - R2: 0.8580 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8368 - val_mae: 0.0260 - lr: 1.4993e-09 - 7s/epoch - 243ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00121\n",
      "27/27 - 7s - loss: 0.0010 - R2: 0.8555 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8353 - val_mae: 0.0262 - lr: 1.4993e-09 - 7s/epoch - 248ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8582 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8353 - val_mae: 0.0262 - lr: 1.4993e-09 - 6s/epoch - 234ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8570 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8354 - val_mae: 0.0260 - lr: 1.4993e-09 - 6s/epoch - 232ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8555 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8351 - val_mae: 0.0262 - lr: 1.4993e-09 - 6s/epoch - 234ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8577 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8360 - val_mae: 0.0260 - lr: 1.4993e-09 - 6s/epoch - 235ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00121\n",
      "27/27 - 7s - loss: 0.0010 - R2: 0.8552 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8347 - val_mae: 0.0262 - lr: 1.4993e-09 - 7s/epoch - 242ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8530 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8369 - val_mae: 0.0260 - lr: 1.4993e-09 - 6s/epoch - 235ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8580 - mae: 0.0242 - val_loss: 0.0013 - val_R2: 0.8266 - val_mae: 0.0271 - lr: 1.4993e-09 - 6s/epoch - 231ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8549 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8365 - val_mae: 0.0259 - lr: 1.4993e-09 - 6s/epoch - 241ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8591 - mae: 0.0242 - val_loss: 0.0013 - val_R2: 0.8234 - val_mae: 0.0275 - lr: 1.4993e-09 - 6s/epoch - 236ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8530 - mae: 0.0242 - val_loss: 0.0013 - val_R2: 0.8305 - val_mae: 0.0268 - lr: 1.4993e-09 - 6s/epoch - 240ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00121\n",
      "27/27 - 7s - loss: 0.0010 - R2: 0.8590 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8352 - val_mae: 0.0263 - lr: 1.4993e-09 - 7s/epoch - 243ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00121\n",
      "27/27 - 7s - loss: 0.0010 - R2: 0.8580 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8369 - val_mae: 0.0260 - lr: 1.4993e-09 - 7s/epoch - 243ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8567 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8367 - val_mae: 0.0259 - lr: 1.4993e-09 - 6s/epoch - 240ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8586 - mae: 0.0242 - val_loss: 0.0013 - val_R2: 0.8296 - val_mae: 0.0269 - lr: 1.4993e-09 - 6s/epoch - 230ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00121\n",
      "27/27 - 7s - loss: 0.0010 - R2: 0.8548 - mae: 0.0242 - val_loss: 0.0013 - val_R2: 0.8239 - val_mae: 0.0274 - lr: 1.4993e-09 - 7s/epoch - 247ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00121\n",
      "27/27 - 7s - loss: 0.0010 - R2: 0.8584 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8355 - val_mae: 0.0261 - lr: 1.4993e-09 - 7s/epoch - 245ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00121\n",
      "27/27 - 7s - loss: 0.0010 - R2: 0.8583 - mae: 0.0242 - val_loss: 0.0013 - val_R2: 0.8312 - val_mae: 0.0267 - lr: 1.4993e-09 - 7s/epoch - 247ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8608 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8366 - val_mae: 0.0260 - lr: 1.4993e-09 - 6s/epoch - 229ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8595 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8355 - val_mae: 0.0262 - lr: 1.4993e-09 - 6s/epoch - 233ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8557 - mae: 0.0242 - val_loss: 0.0013 - val_R2: 0.8267 - val_mae: 0.0272 - lr: 1.4993e-09 - 6s/epoch - 235ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8582 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8362 - val_mae: 0.0260 - lr: 1.4993e-09 - 6s/epoch - 235ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8521 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8353 - val_mae: 0.0261 - lr: 1.4993e-09 - 6s/epoch - 237ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8578 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8355 - val_mae: 0.0261 - lr: 1.4993e-09 - 6s/epoch - 234ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8576 - mae: 0.0242 - val_loss: 0.0013 - val_R2: 0.8288 - val_mae: 0.0270 - lr: 1.4993e-09 - 6s/epoch - 236ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8550 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8348 - val_mae: 0.0262 - lr: 1.4993e-09 - 6s/epoch - 235ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8570 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8365 - val_mae: 0.0261 - lr: 1.4993e-09 - 6s/epoch - 223ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8580 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8352 - val_mae: 0.0262 - lr: 1.4993e-09 - 6s/epoch - 229ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8574 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8363 - val_mae: 0.0260 - lr: 1.4993e-09 - 6s/epoch - 233ms/step\n",
      "lr changed to 1.499288027062562e-10\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8580 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8359 - val_mae: 0.0261 - lr: 1.4993e-10 - 6s/epoch - 233ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00121\n",
      "27/27 - 6s - loss: 0.0010 - R2: 0.8591 - mae: 0.0242 - val_loss: 0.0012 - val_R2: 0.8351 - val_mae: 0.0263 - lr: 1.4993e-10 - 6s/epoch - 237ms/step\n",
      "Epoch 122: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8a3bfdcd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2001\n",
      "{'units_choice': 9, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.00014992878789921055}\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 0.0012 - R2: 0.8221 - mae: 0.0264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0012353284982964396, 0.8220560550689697, 0.026356060057878494]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (505950, 18, 1)\n",
      "X_validate shape: (151785, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2002\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 11m 58s]\n",
      "val_R2: 0.7393009662628174\n",
      "\n",
      "Best val_R2 So Far: 0.8670513033866882\n",
      "Total elapsed time: 03h 31m 00s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00093, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2002_best.hdf5\n",
      "31/31 - 9s - loss: 6.5215e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2507e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 9s/epoch - 290ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 0.00093 to 0.00093, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2002_best.hdf5\n",
      "31/31 - 7s - loss: 6.5252e-04 - R2: 0.9065 - mae: 0.0186 - val_loss: 9.2505e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 233ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00093 to 0.00092, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2002_best.hdf5\n",
      "31/31 - 7s - loss: 6.5237e-04 - R2: 0.9065 - mae: 0.0186 - val_loss: 9.2489e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 221ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5286e-04 - R2: 0.9065 - mae: 0.0186 - val_loss: 9.2503e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 224ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5283e-04 - R2: 0.9065 - mae: 0.0186 - val_loss: 9.2496e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 222ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5193e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2554e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 221ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5251e-04 - R2: 0.9065 - mae: 0.0186 - val_loss: 9.2507e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 214ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5175e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2522e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 213ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss improved from 0.00092 to 0.00092, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2002_best.hdf5\n",
      "31/31 - 7s - loss: 6.5205e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2483e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 229ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5166e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2494e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 222ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5159e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2540e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 217ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5208e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2524e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 217ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5198e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2587e-04 - val_R2: 0.8669 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 218ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5155e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2537e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 211ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5320e-04 - R2: 0.9064 - mae: 0.0186 - val_loss: 9.2522e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 218ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5206e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2523e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 221ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5144e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2490e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 213ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5224e-04 - R2: 0.9065 - mae: 0.0186 - val_loss: 9.2537e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 214ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5213e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2541e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 224ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5131e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2559e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 212ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5253e-04 - R2: 0.9065 - mae: 0.0186 - val_loss: 9.2598e-04 - val_R2: 0.8669 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 212ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5217e-04 - R2: 0.9065 - mae: 0.0186 - val_loss: 9.2560e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 213ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5200e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2516e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 221ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss improved from 0.00092 to 0.00092, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2002_best.hdf5\n",
      "31/31 - 7s - loss: 6.5197e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2480e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 223ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5182e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2544e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 227ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00092\n",
      "31/31 - 6s - loss: 6.5232e-04 - R2: 0.9065 - mae: 0.0186 - val_loss: 9.2540e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 6s/epoch - 207ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5178e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2520e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 210ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5172e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2560e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 223ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5163e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2542e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 225ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5161e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2526e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-06 - 7s/epoch - 215ms/step\n",
      "lr changed to 1.2455336673156125e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5094e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2533e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 219ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5072e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2506e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 223ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5120e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2495e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 218ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5065e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2529e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 215ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5073e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2485e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 218ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5097e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2495e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 219ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5091e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2557e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 213ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5098e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2517e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 221ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5079e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2480e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 219ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00092\n",
      "31/31 - 6s - loss: 6.5099e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2538e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 6s/epoch - 206ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5124e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2501e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 227ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5069e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2577e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 218ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5060e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2491e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 215ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5086e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2522e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 213ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5112e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2518e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 227ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00092\n",
      "31/31 - 8s - loss: 6.5046e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2502e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 8s/epoch - 260ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5109e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2513e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 240ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5051e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2517e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 237ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5095e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2480e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 224ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5036e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2488e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 225ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5037e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2535e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 231ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5111e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2497e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 222ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5095e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2555e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 233ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5069e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2545e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 217ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5116e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2531e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 232ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00092\n",
      "31/31 - 8s - loss: 6.5096e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2549e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 8s/epoch - 257ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss improved from 0.00092 to 0.00092, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2002_best.hdf5\n",
      "31/31 - 8s - loss: 6.5101e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2478e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 8s/epoch - 270ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5187e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2550e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 7s/epoch - 241ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00092\n",
      "31/31 - 8s - loss: 6.5007e-04 - R2: 0.9069 - mae: 0.0186 - val_loss: 9.2490e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-07 - 8s/epoch - 248ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00092\n",
      "31/31 - 8s - loss: 6.5113e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2536e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-07 - 8s/epoch - 250ms/step\n",
      "lr changed to 1.2455336673156126e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5052e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2567e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 238ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5040e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2506e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 237ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5087e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2502e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 239ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5058e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2545e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 242ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.4986e-04 - R2: 0.9069 - mae: 0.0186 - val_loss: 9.2504e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 223ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5095e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2552e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 228ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5147e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2506e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 213ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5080e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2563e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 217ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5127e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2511e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 225ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5057e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2518e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 224ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5021e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2548e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 223ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5082e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2525e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 220ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5128e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2489e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 225ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5096e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2512e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 222ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.4981e-04 - R2: 0.9069 - mae: 0.0186 - val_loss: 9.2511e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 224ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5099e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2508e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 215ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5133e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2495e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 233ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00092\n",
      "31/31 - 8s - loss: 6.5115e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2487e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 8s/epoch - 245ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5074e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2524e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 238ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5016e-04 - R2: 0.9069 - mae: 0.0186 - val_loss: 9.2530e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 225ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5043e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2496e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 226ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5042e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2479e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 219ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5061e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2482e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 232ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5046e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2499e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 224ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5125e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2500e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 226ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5108e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2521e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 218ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5016e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2480e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 222ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5044e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2523e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 227ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5061e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2511e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 217ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5012e-04 - R2: 0.9069 - mae: 0.0186 - val_loss: 9.2511e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-08 - 7s/epoch - 221ms/step\n",
      "lr changed to 1.245533631788476e-09\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5063e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2505e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 226ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5101e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2498e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 229ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5121e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2529e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 220ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5073e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2512e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 224ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5099e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2544e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 220ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5034e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2518e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 221ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss improved from 0.00092 to 0.00092, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2002_best.hdf5\n",
      "31/31 - 8s - loss: 6.5104e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2464e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-09 - 8s/epoch - 244ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5107e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2518e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 216ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5044e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2514e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 216ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5124e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2515e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 229ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5070e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2533e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 230ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5104e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2516e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 225ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5029e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2543e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 229ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5119e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2525e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 217ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5117e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2579e-04 - val_R2: 0.8669 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 227ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5120e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2500e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 220ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5089e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2503e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 215ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5055e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2489e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 216ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5051e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2472e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 218ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5054e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2482e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 214ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5129e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2592e-04 - val_R2: 0.8669 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 225ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5025e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2490e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 224ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5032e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2544e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 215ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5119e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2492e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 220ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5029e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2494e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 220ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5059e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2555e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 222ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5067e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2547e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 220ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5046e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2491e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 223ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5042e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2573e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 224ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5013e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2540e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-09 - 7s/epoch - 219ms/step\n",
      "lr changed to 1.2455336761973967e-10\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5022e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2494e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 222ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5035e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2529e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 224ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5043e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2579e-04 - val_R2: 0.8669 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 230ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5192e-04 - R2: 0.9066 - mae: 0.0186 - val_loss: 9.2499e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 221ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5070e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2521e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 227ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5063e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2495e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 234ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5055e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2527e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 230ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5083e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2531e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 234ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5075e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2514e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 227ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5036e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2559e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 233ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5082e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2538e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 223ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5102e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2505e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 222ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5070e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2545e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 223ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5074e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2505e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 215ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00092\n",
      "31/31 - 6s - loss: 6.5205e-04 - R2: 0.9065 - mae: 0.0186 - val_loss: 9.2512e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 6s/epoch - 189ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5069e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2565e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 220ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5097e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2529e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 217ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5058e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2472e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 219ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5092e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2511e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 227ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5060e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2566e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 223ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5080e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2541e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 217ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5131e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2541e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 226ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5056e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2511e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 212ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5141e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2513e-04 - val_R2: 0.8670 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 227ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5105e-04 - R2: 0.9067 - mae: 0.0186 - val_loss: 9.2496e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 224ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5011e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2498e-04 - val_R2: 0.8671 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 227ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00092\n",
      "31/31 - 7s - loss: 6.5031e-04 - R2: 0.9068 - mae: 0.0186 - val_loss: 9.2634e-04 - val_R2: 0.8669 - val_mae: 0.0219 - lr: 1.2455e-10 - 7s/epoch - 219ms/step\n",
      "Epoch 147: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8bae18880>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2002\n",
      "{'units_choice': 11, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0012455335520847452}\n",
      "2033/2033 [==============================] - 26s 13ms/step - loss: 9.3658e-04 - R2: 0.8576 - mae: 0.0220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00093657715478912, 0.8575628399848938, 0.02198295295238495]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (507932, 18, 1)\n",
      "X_validate shape: (152380, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2003\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 13m 04s]\n",
      "val_R2: 0.7450388073921204\n",
      "\n",
      "Best val_R2 So Far: 0.8559459447860718\n",
      "Total elapsed time: 02h 53m 17s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00101, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2003_best.hdf5\n",
      "32/32 - 10s - loss: 9.8958e-04 - R2: 0.8549 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8526 - val_mae: 0.0238 - lr: 3.6573e-06 - 10s/epoch - 315ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 0.00101 to 0.00100, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2003_best.hdf5\n",
      "32/32 - 8s - loss: 9.8837e-04 - R2: 0.8560 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8545 - val_mae: 0.0237 - lr: 3.6573e-06 - 8s/epoch - 261ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00100\n",
      "32/32 - 8s - loss: 9.8855e-04 - R2: 0.8545 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8544 - val_mae: 0.0235 - lr: 3.6573e-06 - 8s/epoch - 263ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00100\n",
      "32/32 - 7s - loss: 9.8935e-04 - R2: 0.8582 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8535 - val_mae: 0.0238 - lr: 3.6573e-06 - 7s/epoch - 232ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00100\n",
      "32/32 - 8s - loss: 9.8801e-04 - R2: 0.8549 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8544 - val_mae: 0.0237 - lr: 3.6573e-06 - 8s/epoch - 246ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss improved from 0.00100 to 0.00099, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2003_best.hdf5\n",
      "32/32 - 7s - loss: 9.8819e-04 - R2: 0.8577 - mae: 0.0233 - val_loss: 9.9074e-04 - val_R2: 0.8562 - val_mae: 0.0234 - lr: 3.6573e-06 - 7s/epoch - 222ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8902e-04 - R2: 0.8467 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8512 - val_mae: 0.0237 - lr: 3.6573e-06 - 7s/epoch - 232ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8871e-04 - R2: 0.8562 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8523 - val_mae: 0.0239 - lr: 3.6573e-06 - 8s/epoch - 245ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8844e-04 - R2: 0.8572 - mae: 0.0233 - val_loss: 9.9576e-04 - val_R2: 0.8554 - val_mae: 0.0235 - lr: 3.6573e-06 - 7s/epoch - 228ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8845e-04 - R2: 0.8515 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8520 - val_mae: 0.0237 - lr: 3.6573e-06 - 7s/epoch - 232ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8883e-04 - R2: 0.8585 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8525 - val_mae: 0.0239 - lr: 3.6573e-06 - 8s/epoch - 235ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00099\n",
      "32/32 - 6s - loss: 9.8759e-04 - R2: 0.8546 - mae: 0.0233 - val_loss: 9.9307e-04 - val_R2: 0.8558 - val_mae: 0.0235 - lr: 3.6573e-06 - 6s/epoch - 199ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00099\n",
      "32/32 - 5s - loss: 9.8835e-04 - R2: 0.8579 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8542 - val_mae: 0.0235 - lr: 3.6573e-06 - 5s/epoch - 164ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8791e-04 - R2: 0.8567 - mae: 0.0233 - val_loss: 9.9572e-04 - val_R2: 0.8554 - val_mae: 0.0235 - lr: 3.6573e-06 - 7s/epoch - 214ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00099\n",
      "32/32 - 6s - loss: 9.8712e-04 - R2: 0.8583 - mae: 0.0233 - val_loss: 9.9951e-04 - val_R2: 0.8549 - val_mae: 0.0236 - lr: 3.6573e-06 - 6s/epoch - 198ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8733e-04 - R2: 0.8576 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8543 - val_mae: 0.0237 - lr: 3.6573e-06 - 7s/epoch - 219ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8724e-04 - R2: 0.8478 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8521 - val_mae: 0.0239 - lr: 3.6573e-06 - 7s/epoch - 206ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8762e-04 - R2: 0.8542 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8546 - val_mae: 0.0237 - lr: 3.6573e-06 - 7s/epoch - 220ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8813e-04 - R2: 0.8567 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8537 - val_mae: 0.0235 - lr: 3.6573e-06 - 7s/epoch - 211ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8667e-04 - R2: 0.8569 - mae: 0.0232 - val_loss: 9.9501e-04 - val_R2: 0.8556 - val_mae: 0.0235 - lr: 3.6573e-06 - 7s/epoch - 222ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8778e-04 - R2: 0.8589 - mae: 0.0233 - val_loss: 9.9672e-04 - val_R2: 0.8553 - val_mae: 0.0236 - lr: 3.6573e-06 - 7s/epoch - 220ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8691e-04 - R2: 0.8543 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8526 - val_mae: 0.0239 - lr: 3.6573e-06 - 7s/epoch - 213ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8916e-04 - R2: 0.8545 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8534 - val_mae: 0.0237 - lr: 3.6573e-06 - 7s/epoch - 221ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8820e-04 - R2: 0.8531 - mae: 0.0233 - val_loss: 9.9441e-04 - val_R2: 0.8557 - val_mae: 0.0235 - lr: 3.6573e-06 - 7s/epoch - 206ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8689e-04 - R2: 0.8573 - mae: 0.0232 - val_loss: 9.9697e-04 - val_R2: 0.8553 - val_mae: 0.0235 - lr: 3.6573e-06 - 7s/epoch - 225ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8621e-04 - R2: 0.8565 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8535 - val_mae: 0.0236 - lr: 3.6573e-06 - 7s/epoch - 214ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8624e-04 - R2: 0.8576 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8518 - val_mae: 0.0236 - lr: 3.6573e-06 - 7s/epoch - 208ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8646e-04 - R2: 0.8563 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8544 - val_mae: 0.0235 - lr: 3.6573e-06 - 7s/epoch - 218ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8648e-04 - R2: 0.8548 - mae: 0.0233 - val_loss: 9.9523e-04 - val_R2: 0.8555 - val_mae: 0.0234 - lr: 3.6573e-06 - 7s/epoch - 214ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8637e-04 - R2: 0.8512 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8533 - val_mae: 0.0237 - lr: 3.6573e-06 - 7s/epoch - 221ms/step\n",
      "lr changed to 3.657308752735844e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8595e-04 - R2: 0.8584 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8544 - val_mae: 0.0235 - lr: 3.6573e-07 - 7s/epoch - 214ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00099\n",
      "32/32 - 6s - loss: 9.8605e-04 - R2: 0.8577 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8540 - val_mae: 0.0235 - lr: 3.6573e-07 - 6s/epoch - 202ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8677e-04 - R2: 0.8581 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8540 - val_mae: 0.0238 - lr: 3.6573e-07 - 7s/epoch - 222ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8577e-04 - R2: 0.8578 - mae: 0.0232 - val_loss: 9.9601e-04 - val_R2: 0.8554 - val_mae: 0.0236 - lr: 3.6573e-07 - 7s/epoch - 220ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8643e-04 - R2: 0.8584 - mae: 0.0232 - val_loss: 9.9813e-04 - val_R2: 0.8551 - val_mae: 0.0236 - lr: 3.6573e-07 - 7s/epoch - 216ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8613e-04 - R2: 0.8556 - mae: 0.0232 - val_loss: 9.9930e-04 - val_R2: 0.8550 - val_mae: 0.0237 - lr: 3.6573e-07 - 7s/epoch - 209ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8627e-04 - R2: 0.8539 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8520 - val_mae: 0.0238 - lr: 3.6573e-07 - 7s/epoch - 205ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8613e-04 - R2: 0.8569 - mae: 0.0232 - val_loss: 9.9992e-04 - val_R2: 0.8548 - val_mae: 0.0236 - lr: 3.6573e-07 - 7s/epoch - 228ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8692e-04 - R2: 0.8589 - mae: 0.0233 - val_loss: 9.9461e-04 - val_R2: 0.8556 - val_mae: 0.0235 - lr: 3.6573e-07 - 7s/epoch - 209ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8682e-04 - R2: 0.8575 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8533 - val_mae: 0.0239 - lr: 3.6573e-07 - 7s/epoch - 216ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8665e-04 - R2: 0.8531 - mae: 0.0232 - val_loss: 9.9927e-04 - val_R2: 0.8550 - val_mae: 0.0235 - lr: 3.6573e-07 - 7s/epoch - 227ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8633e-04 - R2: 0.8587 - mae: 0.0232 - val_loss: 9.9570e-04 - val_R2: 0.8554 - val_mae: 0.0235 - lr: 3.6573e-07 - 7s/epoch - 223ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8647e-04 - R2: 0.8543 - mae: 0.0232 - val_loss: 9.9739e-04 - val_R2: 0.8552 - val_mae: 0.0235 - lr: 3.6573e-07 - 7s/epoch - 215ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8560e-04 - R2: 0.8383 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8547 - val_mae: 0.0237 - lr: 3.6573e-07 - 7s/epoch - 220ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00099\n",
      "32/32 - 6s - loss: 9.8634e-04 - R2: 0.8539 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8520 - val_mae: 0.0236 - lr: 3.6573e-07 - 6s/epoch - 197ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8558e-04 - R2: 0.8571 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8540 - val_mae: 0.0238 - lr: 3.6573e-07 - 7s/epoch - 232ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8669e-04 - R2: 0.8572 - mae: 0.0232 - val_loss: 9.9865e-04 - val_R2: 0.8550 - val_mae: 0.0236 - lr: 3.6573e-07 - 7s/epoch - 207ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8599e-04 - R2: 0.8564 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8536 - val_mae: 0.0236 - lr: 3.6573e-07 - 7s/epoch - 208ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8562e-04 - R2: 0.8554 - mae: 0.0232 - val_loss: 9.9459e-04 - val_R2: 0.8556 - val_mae: 0.0235 - lr: 3.6573e-07 - 8s/epoch - 249ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8584e-04 - R2: 0.8575 - mae: 0.0232 - val_loss: 9.9766e-04 - val_R2: 0.8551 - val_mae: 0.0235 - lr: 3.6573e-07 - 8s/epoch - 257ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8616e-04 - R2: 0.8557 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8518 - val_mae: 0.0239 - lr: 3.6573e-07 - 8s/epoch - 250ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss improved from 0.00099 to 0.00099, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2003_best.hdf5\n",
      "32/32 - 8s - loss: 9.8533e-04 - R2: 0.8585 - mae: 0.0232 - val_loss: 9.9026e-04 - val_R2: 0.8562 - val_mae: 0.0235 - lr: 3.6573e-07 - 8s/epoch - 240ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8558e-04 - R2: 0.8583 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8545 - val_mae: 0.0237 - lr: 3.6573e-07 - 7s/epoch - 226ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8640e-04 - R2: 0.8591 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8546 - val_mae: 0.0236 - lr: 3.6573e-07 - 7s/epoch - 222ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8608e-04 - R2: 0.8584 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8539 - val_mae: 0.0236 - lr: 3.6573e-07 - 8s/epoch - 240ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8591e-04 - R2: 0.8542 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8541 - val_mae: 0.0236 - lr: 3.6573e-07 - 7s/epoch - 224ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8615e-04 - R2: 0.8546 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8533 - val_mae: 0.0238 - lr: 3.6573e-07 - 7s/epoch - 221ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8598e-04 - R2: 0.8593 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8544 - val_mae: 0.0235 - lr: 3.6573e-07 - 7s/epoch - 226ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8526e-04 - R2: 0.8594 - mae: 0.0232 - val_loss: 9.9839e-04 - val_R2: 0.8550 - val_mae: 0.0235 - lr: 3.6573e-07 - 7s/epoch - 229ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8593e-04 - R2: 0.8586 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8532 - val_mae: 0.0236 - lr: 3.6573e-07 - 8s/epoch - 245ms/step\n",
      "lr changed to 3.657308695892425e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00099\n",
      "32/32 - 9s - loss: 9.8551e-04 - R2: 0.8591 - mae: 0.0232 - val_loss: 9.9958e-04 - val_R2: 0.8548 - val_mae: 0.0236 - lr: 3.6573e-08 - 9s/epoch - 267ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8627e-04 - R2: 0.8588 - mae: 0.0232 - val_loss: 9.9566e-04 - val_R2: 0.8554 - val_mae: 0.0235 - lr: 3.6573e-08 - 8s/epoch - 256ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8593e-04 - R2: 0.8561 - mae: 0.0232 - val_loss: 9.9464e-04 - val_R2: 0.8556 - val_mae: 0.0234 - lr: 3.6573e-08 - 8s/epoch - 258ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8591e-04 - R2: 0.8566 - mae: 0.0232 - val_loss: 9.9747e-04 - val_R2: 0.8552 - val_mae: 0.0235 - lr: 3.6573e-08 - 8s/epoch - 248ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8682e-04 - R2: 0.8560 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8544 - val_mae: 0.0236 - lr: 3.6573e-08 - 8s/epoch - 254ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8515e-04 - R2: 0.8555 - mae: 0.0232 - val_loss: 9.9310e-04 - val_R2: 0.8558 - val_mae: 0.0235 - lr: 3.6573e-08 - 8s/epoch - 248ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss improved from 0.00099 to 0.00099, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2003_best.hdf5\n",
      "32/32 - 7s - loss: 9.8553e-04 - R2: 0.8584 - mae: 0.0232 - val_loss: 9.9021e-04 - val_R2: 0.8562 - val_mae: 0.0234 - lr: 3.6573e-08 - 7s/epoch - 234ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8583e-04 - R2: 0.8569 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8533 - val_mae: 0.0238 - lr: 3.6573e-08 - 7s/epoch - 221ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8559e-04 - R2: 0.8576 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8536 - val_mae: 0.0238 - lr: 3.6573e-08 - 7s/epoch - 223ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8630e-04 - R2: 0.8549 - mae: 0.0232 - val_loss: 9.9342e-04 - val_R2: 0.8558 - val_mae: 0.0235 - lr: 3.6573e-08 - 7s/epoch - 203ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8634e-04 - R2: 0.8550 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8530 - val_mae: 0.0235 - lr: 3.6573e-08 - 7s/epoch - 234ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8589e-04 - R2: 0.8564 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8546 - val_mae: 0.0237 - lr: 3.6573e-08 - 7s/epoch - 216ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8592e-04 - R2: 0.8545 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8535 - val_mae: 0.0237 - lr: 3.6573e-08 - 7s/epoch - 217ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8685e-04 - R2: 0.8559 - mae: 0.0233 - val_loss: 9.9467e-04 - val_R2: 0.8556 - val_mae: 0.0235 - lr: 3.6573e-08 - 7s/epoch - 226ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8569e-04 - R2: 0.8535 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8520 - val_mae: 0.0239 - lr: 3.6573e-08 - 7s/epoch - 227ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8546e-04 - R2: 0.8582 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8547 - val_mae: 0.0235 - lr: 3.6573e-08 - 7s/epoch - 220ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8594e-04 - R2: 0.8495 - mae: 0.0232 - val_loss: 9.9595e-04 - val_R2: 0.8554 - val_mae: 0.0234 - lr: 3.6573e-08 - 7s/epoch - 223ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8588e-04 - R2: 0.8577 - mae: 0.0232 - val_loss: 9.9927e-04 - val_R2: 0.8550 - val_mae: 0.0236 - lr: 3.6573e-08 - 7s/epoch - 216ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8593e-04 - R2: 0.8569 - mae: 0.0232 - val_loss: 9.9512e-04 - val_R2: 0.8555 - val_mae: 0.0236 - lr: 3.6573e-08 - 7s/epoch - 215ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8539e-04 - R2: 0.8579 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8525 - val_mae: 0.0236 - lr: 3.6573e-08 - 7s/epoch - 218ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8548e-04 - R2: 0.8586 - mae: 0.0232 - val_loss: 9.9625e-04 - val_R2: 0.8554 - val_mae: 0.0236 - lr: 3.6573e-08 - 7s/epoch - 223ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8606e-04 - R2: 0.8567 - mae: 0.0232 - val_loss: 9.9152e-04 - val_R2: 0.8560 - val_mae: 0.0234 - lr: 3.6573e-08 - 8s/epoch - 258ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8513e-04 - R2: 0.8528 - mae: 0.0232 - val_loss: 9.9785e-04 - val_R2: 0.8551 - val_mae: 0.0234 - lr: 3.6573e-08 - 8s/epoch - 249ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8556e-04 - R2: 0.8574 - mae: 0.0232 - val_loss: 9.9550e-04 - val_R2: 0.8555 - val_mae: 0.0235 - lr: 3.6573e-08 - 8s/epoch - 242ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8574e-04 - R2: 0.8569 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8518 - val_mae: 0.0237 - lr: 3.6573e-08 - 7s/epoch - 233ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8546e-04 - R2: 0.8512 - mae: 0.0232 - val_loss: 9.9660e-04 - val_R2: 0.8553 - val_mae: 0.0236 - lr: 3.6573e-08 - 8s/epoch - 261ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8601e-04 - R2: 0.8579 - mae: 0.0232 - val_loss: 9.9924e-04 - val_R2: 0.8550 - val_mae: 0.0236 - lr: 3.6573e-08 - 8s/epoch - 257ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8517e-04 - R2: 0.8559 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8547 - val_mae: 0.0236 - lr: 3.6573e-08 - 7s/epoch - 206ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8649e-04 - R2: 0.8525 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8524 - val_mae: 0.0238 - lr: 3.6573e-08 - 7s/epoch - 218ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8518e-04 - R2: 0.8539 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8541 - val_mae: 0.0235 - lr: 3.6573e-08 - 7s/epoch - 214ms/step\n",
      "lr changed to 3.6573087669466987e-09\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8535e-04 - R2: 0.8558 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8544 - val_mae: 0.0236 - lr: 3.6573e-09 - 7s/epoch - 214ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8574e-04 - R2: 0.8581 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8543 - val_mae: 0.0237 - lr: 3.6573e-09 - 7s/epoch - 207ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8554e-04 - R2: 0.8539 - mae: 0.0232 - val_loss: 9.9083e-04 - val_R2: 0.8562 - val_mae: 0.0235 - lr: 3.6573e-09 - 7s/epoch - 210ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8647e-04 - R2: 0.8562 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8546 - val_mae: 0.0235 - lr: 3.6573e-09 - 7s/epoch - 213ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00099\n",
      "32/32 - 6s - loss: 9.8601e-04 - R2: 0.8501 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8546 - val_mae: 0.0237 - lr: 3.6573e-09 - 6s/epoch - 199ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8588e-04 - R2: 0.8557 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8509 - val_mae: 0.0238 - lr: 3.6573e-09 - 7s/epoch - 211ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8652e-04 - R2: 0.8531 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8535 - val_mae: 0.0236 - lr: 3.6573e-09 - 7s/epoch - 207ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8685e-04 - R2: 0.8497 - mae: 0.0233 - val_loss: 0.0010 - val_R2: 0.8537 - val_mae: 0.0235 - lr: 3.6573e-09 - 7s/epoch - 209ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8665e-04 - R2: 0.8554 - mae: 0.0232 - val_loss: 9.9749e-04 - val_R2: 0.8552 - val_mae: 0.0235 - lr: 3.6573e-09 - 7s/epoch - 219ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8620e-04 - R2: 0.8554 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8530 - val_mae: 0.0237 - lr: 3.6573e-09 - 7s/epoch - 210ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8576e-04 - R2: 0.8568 - mae: 0.0232 - val_loss: 9.9495e-04 - val_R2: 0.8556 - val_mae: 0.0235 - lr: 3.6573e-09 - 7s/epoch - 220ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8538e-04 - R2: 0.8564 - mae: 0.0232 - val_loss: 9.9125e-04 - val_R2: 0.8561 - val_mae: 0.0235 - lr: 3.6573e-09 - 7s/epoch - 217ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8649e-04 - R2: 0.8562 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8546 - val_mae: 0.0235 - lr: 3.6573e-09 - 7s/epoch - 209ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8598e-04 - R2: 0.8555 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8544 - val_mae: 0.0236 - lr: 3.6573e-09 - 7s/epoch - 218ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8682e-04 - R2: 0.8574 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8547 - val_mae: 0.0236 - lr: 3.6573e-09 - 7s/epoch - 205ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8531e-04 - R2: 0.8563 - mae: 0.0232 - val_loss: 9.9302e-04 - val_R2: 0.8558 - val_mae: 0.0235 - lr: 3.6573e-09 - 7s/epoch - 212ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8572e-04 - R2: 0.8577 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8535 - val_mae: 0.0237 - lr: 3.6573e-09 - 7s/epoch - 212ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8592e-04 - R2: 0.8561 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8506 - val_mae: 0.0237 - lr: 3.6573e-09 - 7s/epoch - 218ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8568e-04 - R2: 0.8583 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8546 - val_mae: 0.0235 - lr: 3.6573e-09 - 7s/epoch - 220ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00099\n",
      "32/32 - 7s - loss: 9.8642e-04 - R2: 0.8555 - mae: 0.0232 - val_loss: 9.9103e-04 - val_R2: 0.8561 - val_mae: 0.0234 - lr: 3.6573e-09 - 7s/epoch - 233ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8546e-04 - R2: 0.8545 - mae: 0.0232 - val_loss: 9.9691e-04 - val_R2: 0.8553 - val_mae: 0.0234 - lr: 3.6573e-09 - 8s/epoch - 266ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8577e-04 - R2: 0.8592 - mae: 0.0232 - val_loss: 9.9360e-04 - val_R2: 0.8557 - val_mae: 0.0234 - lr: 3.6573e-09 - 8s/epoch - 253ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8565e-04 - R2: 0.8496 - mae: 0.0232 - val_loss: 9.9903e-04 - val_R2: 0.8550 - val_mae: 0.0235 - lr: 3.6573e-09 - 8s/epoch - 256ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8591e-04 - R2: 0.8454 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8487 - val_mae: 0.0239 - lr: 3.6573e-09 - 8s/epoch - 252ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8661e-04 - R2: 0.8499 - mae: 0.0232 - val_loss: 9.9879e-04 - val_R2: 0.8550 - val_mae: 0.0235 - lr: 3.6573e-09 - 8s/epoch - 247ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8639e-04 - R2: 0.8504 - mae: 0.0232 - val_loss: 0.0010 - val_R2: 0.8534 - val_mae: 0.0238 - lr: 3.6573e-09 - 8s/epoch - 257ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00099\n",
      "32/32 - 8s - loss: 9.8590e-04 - R2: 0.8559 - mae: 0.0232 - val_loss: 9.9035e-04 - val_R2: 0.8562 - val_mae: 0.0234 - lr: 3.6573e-09 - 8s/epoch - 258ms/step\n",
      "Epoch 117: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f881595e20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2003\n",
      "{'units_choice': 7, 'kernel_size': 5, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0036573086954592286}\n",
      "2041/2041 [==============================] - 34s 16ms/step - loss: 0.0010 - R2: 0.8453 - mae: 0.0236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0010202808771282434, 0.8453401923179626, 0.02358616515994072]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (500833, 18, 1)\n",
      "X_validate shape: (150250, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2004\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 05m 37s]\n",
      "val_R2: 0.6496430039405823\n",
      "\n",
      "Best val_R2 So Far: 0.882961094379425\n",
      "Total elapsed time: 04h 13m 43s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00081, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2004_best.hdf5\n",
      "31/31 - 10s - loss: 5.6481e-04 - R2: 0.9185 - mae: 0.0173 - val_loss: 8.0935e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 10s/epoch - 309ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6429e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0940e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 223ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00081 to 0.00081, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2004_best.hdf5\n",
      "31/31 - 8s - loss: 5.6402e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0903e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 8s/epoch - 244ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss improved from 0.00081 to 0.00081, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2004_best.hdf5\n",
      "31/31 - 6s - loss: 5.6412e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0902e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 6s/epoch - 185ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00081 to 0.00081, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2004_best.hdf5\n",
      "31/31 - 7s - loss: 5.6443e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0888e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 215ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6363e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0915e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 6s/epoch - 206ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00081\n",
      "31/31 - 8s - loss: 5.6378e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0926e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 8s/epoch - 247ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss improved from 0.00081 to 0.00081, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2004_best.hdf5\n",
      "31/31 - 7s - loss: 5.6391e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0879e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 229ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6415e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0912e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 225ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6340e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0925e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 219ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6361e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0889e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 6s/epoch - 209ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6373e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0919e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 224ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6362e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0930e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 227ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6351e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0882e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 230ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6330e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0930e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 226ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6392e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0891e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 210ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6356e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0901e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 215ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6369e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0893e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 215ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6380e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0934e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 215ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6400e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0943e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 216ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6355e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0883e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-07 - 6s/epoch - 206ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6355e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0887e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 214ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6393e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0895e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 6s/epoch - 207ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6369e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0915e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 215ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6348e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0911e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 6s/epoch - 207ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6311e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0917e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 210ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6406e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0887e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 212ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6328e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0902e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 219ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6330e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0893e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 212ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6306e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0927e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-07 - 7s/epoch - 213ms/step\n",
      "lr changed to 7.915242576927995e-08\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss improved from 0.00081 to 0.00081, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2004_best.hdf5\n",
      "31/31 - 7s - loss: 5.6328e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0859e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 214ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6332e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0881e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 6s/epoch - 200ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6311e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0912e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 6s/epoch - 204ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6305e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0912e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 220ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6319e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0918e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 213ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6290e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0865e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 212ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6315e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0916e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 210ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6345e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0863e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 218ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6320e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0923e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 6s/epoch - 207ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6299e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0892e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 235ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6285e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0905e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 230ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6317e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0881e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 219ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6278e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0910e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 236ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6322e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0907e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 237ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6339e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0902e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 232ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6332e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0864e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 231ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6327e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0863e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 213ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss improved from 0.00081 to 0.00081, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2004_best.hdf5\n",
      "31/31 - 7s - loss: 5.6299e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0854e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 218ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6276e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0885e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 6s/epoch - 210ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6277e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0898e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 212ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6301e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0864e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 6s/epoch - 206ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6338e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0873e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 6s/epoch - 201ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6342e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0898e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 6s/epoch - 209ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6295e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0910e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 211ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6323e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0854e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 212ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6340e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0925e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 212ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6306e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0877e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 6s/epoch - 208ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6313e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0928e-04 - val_R2: 0.8829 - val_mae: 0.0205 - lr: 7.9152e-08 - 7s/epoch - 213ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6301e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0877e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 215ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6313e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0883e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-08 - 7s/epoch - 213ms/step\n",
      "lr changed to 7.91524286114509e-09\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6271e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0862e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 210ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6288e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0886e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 206ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6261e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0903e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 212ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6368e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0918e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 202ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6284e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0856e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 202ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6256e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0892e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 202ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6284e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0878e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 202ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6315e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0864e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 201ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6293e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0893e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 204ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6303e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0885e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 207ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6256e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0875e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 210ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6288e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0926e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 207ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6315e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0872e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 206ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6284e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0898e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 225ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6244e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0869e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 217ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6244e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0911e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 207ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6329e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0896e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 215ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6281e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0871e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 218ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6282e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0864e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 218ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6302e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0905e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 204ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6287e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0872e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 211ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6259e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0910e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 224ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6236e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0887e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 216ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6306e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0886e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 6s/epoch - 209ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6302e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0862e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 218ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6281e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0974e-04 - val_R2: 0.8828 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 216ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6374e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0925e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 213ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6291e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0864e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 215ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss improved from 0.00081 to 0.00081, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2004_best.hdf5\n",
      "31/31 - 7s - loss: 5.6322e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0842e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 219ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6301e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0869e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-09 - 7s/epoch - 219ms/step\n",
      "lr changed to 7.915242683509406e-10\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6286e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0878e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 214ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6284e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0877e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 216ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6290e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0871e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 210ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6285e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0855e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 214ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6282e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0883e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 230ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6354e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0873e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 227ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6337e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0921e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 230ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6295e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0882e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 218ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6314e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0886e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 207ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6285e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0876e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 218ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6310e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0902e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 221ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6246e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0861e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 215ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6268e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0869e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 215ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6310e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0905e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 209ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6332e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0922e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 218ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6282e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0884e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 7s/epoch - 212ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6291e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0866e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 197ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6287e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0920e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 191ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6316e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0876e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 192ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6309e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0952e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 192ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6295e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0861e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 190ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6322e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0925e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 200ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6309e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0911e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 195ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6309e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0908e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 195ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6293e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0864e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 191ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6289e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0884e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 199ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6360e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0854e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 193ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6268e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0898e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-10 - 6s/epoch - 189ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00081\n",
      "31/31 - 5s - loss: 5.6315e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0885e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 5s/epoch - 171ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00081\n",
      "31/31 - 5s - loss: 5.6281e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0871e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-10 - 5s/epoch - 168ms/step\n",
      "lr changed to 7.91524290555401e-11\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00081\n",
      "31/31 - 5s - loss: 5.6311e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0921e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 5s/epoch - 169ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00081\n",
      "31/31 - 5s - loss: 5.6275e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0875e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 5s/epoch - 175ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6292e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0955e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 217ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6301e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0867e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 6s/epoch - 191ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6273e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0852e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 212ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss improved from 0.00081 to 0.00081, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2004_best.hdf5\n",
      "31/31 - 7s - loss: 5.6309e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0839e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 224ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6336e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0874e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 6s/epoch - 202ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6263e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0895e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 6s/epoch - 204ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6327e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0886e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 217ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6222e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0903e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 224ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6315e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0907e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 215ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6305e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0904e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 221ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6259e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0915e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 216ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6326e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0874e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 224ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6308e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0893e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 210ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6325e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0871e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 6s/epoch - 208ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6288e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0874e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 223ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6392e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0906e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 222ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6290e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0916e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 212ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6310e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0898e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 224ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6234e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0899e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 230ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6339e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0928e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 221ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6332e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0862e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 215ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6243e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0864e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 6s/epoch - 206ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6304e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0914e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 215ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6343e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0894e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 6s/epoch - 209ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6283e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0930e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 214ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6314e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0898e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 237ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6358e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0894e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 215ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6298e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0860e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-11 - 7s/epoch - 218ms/step\n",
      "lr changed to 7.915242766776131e-12\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6270e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0916e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-12 - 7s/epoch - 227ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6314e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0868e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 7s/epoch - 221ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6285e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0936e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-12 - 7s/epoch - 211ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6276e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0878e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 195ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00081\n",
      "31/31 - 7s - loss: 5.6308e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0856e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 7s/epoch - 212ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6324e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0881e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 199ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6296e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0906e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 201ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6281e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0868e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 204ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6310e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0903e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 207ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6247e-04 - R2: 0.9189 - mae: 0.0172 - val_loss: 8.0899e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 192ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6339e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0887e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 206ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6366e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0899e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 206ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6308e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0887e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 202ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6336e-04 - R2: 0.9186 - mae: 0.0172 - val_loss: 8.0889e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 206ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6285e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0923e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 196ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6279e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0876e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 201ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6323e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0877e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 201ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6330e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0892e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 210ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6299e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0890e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 204ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6278e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0873e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 208ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6342e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0896e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 195ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6295e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0919e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 197ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6356e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0890e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 196ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6269e-04 - R2: 0.9187 - mae: 0.0172 - val_loss: 8.0861e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 196ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6266e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0922e-04 - val_R2: 0.8829 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 197ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00081\n",
      "31/31 - 6s - loss: 5.6284e-04 - R2: 0.9188 - mae: 0.0172 - val_loss: 8.0890e-04 - val_R2: 0.8830 - val_mae: 0.0204 - lr: 7.9152e-12 - 6s/epoch - 208ms/step\n",
      "Epoch 176: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8814c07c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2004\n",
      "{'units_choice': 10, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.000791524243562959}\n",
      "2013/2013 [==============================] - 32s 16ms/step - loss: 7.8502e-04 - R2: 0.8780 - mae: 0.0203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0007850177935324609, 0.8779571056365967, 0.020342692732810974]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (505351, 18, 1)\n",
      "X_validate shape: (151606, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2005\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 07m 11s]\n",
      "val_R2: 0.8803035616874695\n",
      "\n",
      "Best val_R2 So Far: 0.883018970489502\n",
      "Total elapsed time: 03h 45m 52s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 6s - loss: 6.8961e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2082e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 6s/epoch - 192ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.9050e-04 - R2: 0.9022 - mae: 0.0192 - val_loss: 8.2090e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 134ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.9015e-04 - R2: 0.9022 - mae: 0.0192 - val_loss: 8.2210e-04 - val_R2: 0.8828 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 129ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 5s - loss: 6.9168e-04 - R2: 0.9020 - mae: 0.0193 - val_loss: 8.2077e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 149ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 4s - loss: 6.9052e-04 - R2: 0.9022 - mae: 0.0193 - val_loss: 8.2056e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 130ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8972e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2081e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 149ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.9092e-04 - R2: 0.9021 - mae: 0.0193 - val_loss: 8.2098e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 121ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.9074e-04 - R2: 0.9022 - mae: 0.0193 - val_loss: 8.2069e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 150ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.9018e-04 - R2: 0.9022 - mae: 0.0192 - val_loss: 8.2159e-04 - val_R2: 0.8829 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 154ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.9011e-04 - R2: 0.9022 - mae: 0.0192 - val_loss: 8.2088e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 144ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8986e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2080e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 142ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.9047e-04 - R2: 0.9022 - mae: 0.0193 - val_loss: 8.2096e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 129ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 5s - loss: 6.8960e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2053e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 155ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8925e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2139e-04 - val_R2: 0.8829 - val_mae: 0.0209 - lr: 2.5674e-06 - 4s/epoch - 134ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8874e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2074e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 156ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8907e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2138e-04 - val_R2: 0.8829 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 142ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8954e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2068e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 153ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8996e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2135e-04 - val_R2: 0.8829 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 144ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.9130e-04 - R2: 0.9021 - mae: 0.0193 - val_loss: 8.2169e-04 - val_R2: 0.8829 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 137ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.9014e-04 - R2: 0.9022 - mae: 0.0192 - val_loss: 8.2056e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 143ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8879e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2094e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 153ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 5s - loss: 6.9015e-04 - R2: 0.9023 - mae: 0.0193 - val_loss: 8.2048e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 171ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 4s - loss: 6.8877e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2037e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 145ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8931e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2038e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 154ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8885e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2090e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 151ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8862e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2075e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 148ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8841e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2081e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 142ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8882e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2131e-04 - val_R2: 0.8829 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 139ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8887e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2060e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 5s/epoch - 146ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8961e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2058e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-06 - 4s/epoch - 140ms/step\n",
      "lr changed to 2.5674423795862824e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 5s - loss: 6.8859e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2024e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 157ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8803e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2060e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 4s/epoch - 129ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8855e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2063e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 145ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8832e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2037e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 149ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 4s - loss: 6.8967e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2020e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 4s/epoch - 134ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8947e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2040e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 154ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8941e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2366e-04 - val_R2: 0.8826 - val_mae: 0.0210 - lr: 2.5674e-07 - 4s/epoch - 136ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8940e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2024e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-07 - 5s/epoch - 160ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8779e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2038e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 4s/epoch - 139ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8709e-04 - R2: 0.9027 - mae: 0.0192 - val_loss: 8.2061e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-07 - 4s/epoch - 134ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8737e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2048e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 163ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 5s - loss: 6.8888e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2018e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 146ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8865e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2051e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 160ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 4s - loss: 6.8871e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2015e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-07 - 4s/epoch - 128ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8809e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2032e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 156ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8775e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2043e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 4s/epoch - 140ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.9031e-04 - R2: 0.9022 - mae: 0.0193 - val_loss: 8.2068e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-07 - 4s/epoch - 140ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 5s - loss: 6.8723e-04 - R2: 0.9027 - mae: 0.0192 - val_loss: 8.2013e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-07 - 5s/epoch - 151ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8930e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2038e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 151ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8663e-04 - R2: 0.9027 - mae: 0.0192 - val_loss: 8.2065e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 153ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8781e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2048e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 4s/epoch - 132ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 5s - loss: 6.8758e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2009e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 155ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8913e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2041e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 4s/epoch - 138ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8896e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2021e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 4s/epoch - 130ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.9026e-04 - R2: 0.9022 - mae: 0.0193 - val_loss: 8.2030e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 155ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8929e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2015e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 4s/epoch - 132ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8982e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2082e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 151ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 5s - loss: 6.8926e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2003e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 152ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.9011e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2005e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 157ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8863e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2044e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-07 - 5s/epoch - 152ms/step\n",
      "lr changed to 2.567442436429701e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8843e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2055e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 160ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8969e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2053e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 159ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8868e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2078e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 151ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8905e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2097e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 166ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8836e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2050e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 4s/epoch - 144ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8754e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2020e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-08 - 5s/epoch - 155ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8923e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2069e-04 - val_R2: 0.8830 - val_mae: 0.0209 - lr: 2.5674e-08 - 4s/epoch - 135ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.9018e-04 - R2: 0.9022 - mae: 0.0193 - val_loss: 8.2077e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 163ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8794e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2011e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-08 - 5s/epoch - 157ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8839e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2080e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 157ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2005_best.hdf5\n",
      "31/31 - 5s - loss: 6.8790e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2002e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 161ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8865e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2023e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-08 - 5s/epoch - 153ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8870e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2022e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 158ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8890e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2023e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 4s/epoch - 143ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8754e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2068e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 161ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8850e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2020e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 154ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8961e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2036e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 154ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8799e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2049e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 163ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8848e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2066e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 163ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8936e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2054e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 163ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8945e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2037e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-08 - 5s/epoch - 170ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8896e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2022e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-08 - 5s/epoch - 150ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8895e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2067e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 146ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8766e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2032e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 172ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8895e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2032e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 160ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8842e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2076e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 162ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8929e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2030e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-08 - 4s/epoch - 135ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8874e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2096e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 166ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8744e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2082e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 147ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8935e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2079e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-08 - 5s/epoch - 162ms/step\n",
      "lr changed to 2.5674424364297012e-09\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8950e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2014e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-09 - 4s/epoch - 141ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00082\n",
      "31/31 - 5s - loss: 6.8971e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2106e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-09 - 5s/epoch - 146ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8786e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2011e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 134ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00082\n",
      "31/31 - 3s - loss: 6.8992e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2030e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 3s/epoch - 96ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00082\n",
      "31/31 - 3s - loss: 6.8960e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2011e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 3s/epoch - 110ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8981e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2037e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 117ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8813e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2070e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 130ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8961e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2061e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 128ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8808e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2011e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-09 - 4s/epoch - 129ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8913e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2057e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 130ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8832e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2072e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 127ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8859e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2060e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 124ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8823e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2029e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-09 - 4s/epoch - 126ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8905e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2072e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 128ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8930e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2068e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 130ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8769e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2031e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 123ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.9090e-04 - R2: 0.9021 - mae: 0.0193 - val_loss: 8.2046e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 129ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8928e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2100e-04 - val_R2: 0.8830 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 122ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8918e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2044e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 127ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8891e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2004e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-09 - 4s/epoch - 123ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8794e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2044e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 125ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8767e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2021e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 131ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8852e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2010e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-09 - 4s/epoch - 134ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8960e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2152e-04 - val_R2: 0.8829 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 128ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8908e-04 - R2: 0.9024 - mae: 0.0192 - val_loss: 8.2037e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 122ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8716e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2015e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 129ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8862e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2025e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 124ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8777e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2018e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 130ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8832e-04 - R2: 0.9025 - mae: 0.0192 - val_loss: 8.2021e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-09 - 4s/epoch - 130ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8787e-04 - R2: 0.9026 - mae: 0.0192 - val_loss: 8.2040e-04 - val_R2: 0.8831 - val_mae: 0.0209 - lr: 2.5674e-09 - 4s/epoch - 127ms/step\n",
      "lr changed to 2.567442480838622e-10\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00082\n",
      "31/31 - 4s - loss: 6.8980e-04 - R2: 0.9023 - mae: 0.0192 - val_loss: 8.2032e-04 - val_R2: 0.8831 - val_mae: 0.0210 - lr: 2.5674e-10 - 4s/epoch - 127ms/step\n",
      "Epoch 121: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f88293e400>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2005\n",
      "{'units_choice': 2, 'kernel_size': 5, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0025674422564504226}\n",
      "2031/2031 [==============================] - 22s 11ms/step - loss: 8.4027e-04 - R2: 0.8734 - mae: 0.0211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0008402664680033922, 0.8733550906181335, 0.02110433764755726]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (513265, 18, 1)\n",
      "X_validate shape: (153980, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2006\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 06m 46s]\n",
      "val_R2: 0.858832061290741\n",
      "\n",
      "Best val_R2 So Far: 0.8645362854003906\n",
      "Total elapsed time: 03h 46m 53s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00091, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2006_best.hdf5\n",
      "32/32 - 9s - loss: 6.2994e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.1059e-04 - val_R2: 0.8644 - val_mae: 0.0217 - lr: 6.7664e-07 - 9s/epoch - 280ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 0.00091 to 0.00091, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2006_best.hdf5\n",
      "32/32 - 7s - loss: 6.3016e-04 - R2: 0.9062 - mae: 0.0183 - val_loss: 9.0986e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-07 - 7s/epoch - 225ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.3002e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.1034e-04 - val_R2: 0.8644 - val_mae: 0.0218 - lr: 6.7664e-07 - 7s/epoch - 211ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.3014e-04 - R2: 0.9062 - mae: 0.0183 - val_loss: 9.0991e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-07 - 7s/epoch - 221ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.3011e-04 - R2: 0.9061 - mae: 0.0183 - val_loss: 9.1042e-04 - val_R2: 0.8644 - val_mae: 0.0218 - lr: 6.7664e-07 - 7s/epoch - 222ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.3003e-04 - R2: 0.9062 - mae: 0.0183 - val_loss: 9.0992e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-07 - 7s/epoch - 230ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.3006e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.1025e-04 - val_R2: 0.8644 - val_mae: 0.0217 - lr: 6.7664e-07 - 8s/epoch - 237ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss improved from 0.00091 to 0.00091, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2006_best.hdf5\n",
      "32/32 - 7s - loss: 6.3002e-04 - R2: 0.9060 - mae: 0.0183 - val_loss: 9.0986e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-07 - 7s/epoch - 230ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2930e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.1005e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-07 - 7s/epoch - 223ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2943e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.1005e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-07 - 7s/epoch - 232ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss improved from 0.00091 to 0.00091, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2006_best.hdf5\n",
      "32/32 - 8s - loss: 6.3009e-04 - R2: 0.9061 - mae: 0.0183 - val_loss: 9.0982e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-07 - 8s/epoch - 236ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2993e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.1054e-04 - val_R2: 0.8644 - val_mae: 0.0217 - lr: 6.7664e-07 - 7s/epoch - 227ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2983e-04 - R2: 0.9062 - mae: 0.0183 - val_loss: 9.1035e-04 - val_R2: 0.8644 - val_mae: 0.0217 - lr: 6.7664e-07 - 8s/epoch - 238ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2964e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.0988e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-07 - 7s/epoch - 221ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss improved from 0.00091 to 0.00091, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2006_best.hdf5\n",
      "32/32 - 7s - loss: 6.2979e-04 - R2: 0.9062 - mae: 0.0183 - val_loss: 9.0941e-04 - val_R2: 0.8646 - val_mae: 0.0217 - lr: 6.7664e-07 - 7s/epoch - 230ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2928e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.0970e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-07 - 7s/epoch - 212ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2921e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.0964e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-07 - 7s/epoch - 232ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2939e-04 - R2: 0.9064 - mae: 0.0183 - val_loss: 9.0981e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-07 - 7s/epoch - 216ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2931e-04 - R2: 0.9064 - mae: 0.0183 - val_loss: 9.1007e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-07 - 7s/epoch - 228ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2896e-04 - R2: 0.9064 - mae: 0.0183 - val_loss: 9.0984e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-07 - 7s/epoch - 226ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2919e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.1002e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-07 - 7s/epoch - 221ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2948e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.0996e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-07 - 7s/epoch - 221ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2886e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.0999e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-07 - 7s/epoch - 228ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2927e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.0982e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-07 - 7s/epoch - 224ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2965e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.1014e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-07 - 7s/epoch - 227ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2943e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.1149e-04 - val_R2: 0.8643 - val_mae: 0.0217 - lr: 6.7664e-07 - 7s/epoch - 220ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2906e-04 - R2: 0.9064 - mae: 0.0183 - val_loss: 9.1061e-04 - val_R2: 0.8644 - val_mae: 0.0218 - lr: 6.7664e-07 - 8s/epoch - 240ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2881e-04 - R2: 0.9064 - mae: 0.0183 - val_loss: 9.1004e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-07 - 8s/epoch - 254ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2876e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.1051e-04 - val_R2: 0.8644 - val_mae: 0.0218 - lr: 6.7664e-07 - 8s/epoch - 264ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2881e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.0970e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-07 - 8s/epoch - 253ms/step\n",
      "lr changed to 6.7664353764485e-08\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2853e-04 - R2: 0.9066 - mae: 0.0183 - val_loss: 9.0998e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 247ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2882e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.1005e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 239ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2860e-04 - R2: 0.9064 - mae: 0.0183 - val_loss: 9.1034e-04 - val_R2: 0.8644 - val_mae: 0.0218 - lr: 6.7664e-08 - 8s/epoch - 243ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2884e-04 - R2: 0.9064 - mae: 0.0183 - val_loss: 9.1045e-04 - val_R2: 0.8644 - val_mae: 0.0218 - lr: 6.7664e-08 - 8s/epoch - 236ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2847e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.1016e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 253ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2846e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.1021e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 7s/epoch - 226ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00091\n",
      "32/32 - 9s - loss: 6.2865e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.0969e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-08 - 9s/epoch - 280ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2876e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.0943e-04 - val_R2: 0.8646 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 252ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2901e-04 - R2: 0.9064 - mae: 0.0183 - val_loss: 9.0979e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 250ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2881e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.0977e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-08 - 8s/epoch - 249ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2869e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.0949e-04 - val_R2: 0.8646 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 258ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2814e-04 - R2: 0.9066 - mae: 0.0183 - val_loss: 9.1000e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 235ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2830e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.1015e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 238ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2808e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.1055e-04 - val_R2: 0.8644 - val_mae: 0.0218 - lr: 6.7664e-08 - 8s/epoch - 237ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2882e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.1091e-04 - val_R2: 0.8644 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 245ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2905e-04 - R2: 0.9064 - mae: 0.0183 - val_loss: 9.0960e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 256ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2899e-04 - R2: 0.9066 - mae: 0.0183 - val_loss: 9.0987e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 255ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2864e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.0972e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-08 - 8s/epoch - 251ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2831e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.0992e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 252ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2868e-04 - R2: 0.9066 - mae: 0.0183 - val_loss: 9.1033e-04 - val_R2: 0.8644 - val_mae: 0.0217 - lr: 6.7664e-08 - 7s/epoch - 232ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00091\n",
      "32/32 - 6s - loss: 6.2838e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.0971e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 6s/epoch - 188ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2824e-04 - R2: 0.9066 - mae: 0.0183 - val_loss: 9.1011e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 236ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2851e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.0995e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 7s/epoch - 224ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2844e-04 - R2: 0.9066 - mae: 0.0183 - val_loss: 9.0955e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 254ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2816e-04 - R2: 0.9066 - mae: 0.0183 - val_loss: 9.0976e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-08 - 8s/epoch - 249ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2885e-04 - R2: 0.9061 - mae: 0.0183 - val_loss: 9.1042e-04 - val_R2: 0.8644 - val_mae: 0.0218 - lr: 6.7664e-08 - 8s/epoch - 246ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2948e-04 - R2: 0.9063 - mae: 0.0183 - val_loss: 9.0967e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-08 - 8s/epoch - 263ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00091\n",
      "32/32 - 8s - loss: 6.2826e-04 - R2: 0.9066 - mae: 0.0183 - val_loss: 9.0968e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 8s/epoch - 247ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2821e-04 - R2: 0.9066 - mae: 0.0183 - val_loss: 9.0984e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 7s/epoch - 223ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2812e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.0977e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-08 - 7s/epoch - 222ms/step\n",
      "lr changed to 6.766435234339952e-09\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2845e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.0953e-04 - val_R2: 0.8646 - val_mae: 0.0217 - lr: 6.7664e-09 - 7s/epoch - 234ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2784e-04 - R2: 0.9067 - mae: 0.0183 - val_loss: 9.1015e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-09 - 7s/epoch - 225ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2856e-04 - R2: 0.9064 - mae: 0.0183 - val_loss: 9.1009e-04 - val_R2: 0.8645 - val_mae: 0.0218 - lr: 6.7664e-09 - 7s/epoch - 228ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2862e-04 - R2: 0.9065 - mae: 0.0183 - val_loss: 9.1036e-04 - val_R2: 0.8644 - val_mae: 0.0218 - lr: 6.7664e-09 - 7s/epoch - 232ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00091\n",
      "32/32 - 7s - loss: 6.2817e-04 - R2: 0.9062 - mae: 0.0183 - val_loss: 9.1006e-04 - val_R2: 0.8645 - val_mae: 0.0217 - lr: 6.7664e-09 - 7s/epoch - 232ms/step\n",
      "Epoch 65: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8815bf3d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2006\n",
      "{'units_choice': 10, 'kernel_size': 5, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0006766435736156065}\n",
      "2063/2063 [==============================] - 28s 13ms/step - loss: 8.9253e-04 - R2: 0.8582 - mae: 0.0217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0008925338042899966, 0.8582067489624023, 0.02168397791683674]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (618216, 18, 1)\n",
      "X_validate shape: (185465, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2007\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 19m 19s]\n",
      "val_R2: 0.8684059977531433\n",
      "\n",
      "Best val_R2 So Far: 0.8888434767723083\n",
      "Total elapsed time: 04h 21m 38s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00085, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2007_best.hdf5\n",
      "38/38 - 9s - loss: 6.7167e-04 - R2: 0.9119 - mae: 0.0191 - val_loss: 8.4713e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 9s/epoch - 226ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7116e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4739e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 182ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00085 to 0.00085, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2007_best.hdf5\n",
      "38/38 - 7s - loss: 6.7205e-04 - R2: 0.9119 - mae: 0.0191 - val_loss: 8.4698e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 185ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7090e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4722e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 189ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7109e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4771e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 180ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7185e-04 - R2: 0.9119 - mae: 0.0190 - val_loss: 8.4722e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 189ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7091e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4723e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 181ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7128e-04 - R2: 0.9119 - mae: 0.0190 - val_loss: 8.4782e-04 - val_R2: 0.8887 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 192ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7126e-04 - R2: 0.9119 - mae: 0.0190 - val_loss: 8.4712e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 177ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7120e-04 - R2: 0.9119 - mae: 0.0190 - val_loss: 8.4716e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 180ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7103e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4751e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 172ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7012e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4701e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 182ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7128e-04 - R2: 0.9119 - mae: 0.0190 - val_loss: 8.4704e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 177ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss improved from 0.00085 to 0.00085, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2007_best.hdf5\n",
      "38/38 - 7s - loss: 6.7121e-04 - R2: 0.9119 - mae: 0.0190 - val_loss: 8.4698e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 187ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7054e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4714e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7092e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4722e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 173ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7044e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4703e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 177ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7065e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4756e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 187ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss improved from 0.00085 to 0.00085, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2007_best.hdf5\n",
      "38/38 - 7s - loss: 6.7023e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4686e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 184ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7035e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4702e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 176ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7034e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4711e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 187ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.7012e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4705e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 188ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss improved from 0.00085 to 0.00085, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2007_best.hdf5\n",
      "38/38 - 7s - loss: 6.7031e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4671e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 184ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6977e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4708e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 190ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6968e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4716e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 185ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6962e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4685e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 175ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00085\n",
      "38/38 - 5s - loss: 6.6978e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4732e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 5s/epoch - 138ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00085\n",
      "38/38 - 6s - loss: 6.6949e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4722e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-06 - 6s/epoch - 164ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00085\n",
      "38/38 - 6s - loss: 6.6936e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4701e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-06 - 6s/epoch - 163ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss improved from 0.00085 to 0.00085, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2007_best.hdf5\n",
      "38/38 - 7s - loss: 6.6994e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4658e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-06 - 7s/epoch - 171ms/step\n",
      "lr changed to 2.525622676330386e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00085\n",
      "38/38 - 6s - loss: 6.6987e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4672e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 6s/epoch - 169ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00085\n",
      "38/38 - 6s - loss: 6.6946e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4685e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 6s/epoch - 154ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6942e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4671e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 171ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6955e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4672e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6903e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4728e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 177ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6909e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4704e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 175ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6938e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4720e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 187ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6902e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4754e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 196ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6934e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4677e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 181ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6936e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4694e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 177ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6883e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4680e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 184ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6956e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4720e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 182ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6948e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4667e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 173ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6921e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4688e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 175ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6922e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4707e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 175ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6900e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4680e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 173ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6952e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4680e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 186ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6913e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4680e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 175ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6954e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4667e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 185ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6906e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4690e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 181ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6881e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4713e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 178ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6937e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4744e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 174ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6925e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4703e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6928e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4683e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 182ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00085\n",
      "38/38 - 6s - loss: 6.6900e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4709e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 6s/epoch - 167ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6933e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4707e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 181ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6891e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4724e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 181ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6923e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4660e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 180ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6964e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4690e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6903e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4733e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-07 - 7s/epoch - 180ms/step\n",
      "lr changed to 2.5256227331738046e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6868e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4695e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 172ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6852e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4676e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 178ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6896e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4780e-04 - val_R2: 0.8887 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 179ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6859e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4674e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 181ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6918e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4731e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 197ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6902e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4667e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 191ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6938e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4669e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 182ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss improved from 0.00085 to 0.00085, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2007_best.hdf5\n",
      "38/38 - 7s - loss: 6.6881e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4656e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 194ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6912e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4667e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 177ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6897e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4698e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 189ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6918e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4707e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 180ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6931e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4687e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 176ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6894e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4704e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 184ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6874e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4672e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 176ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6941e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4672e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 182ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6920e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4671e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 182ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6872e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4670e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 180ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6930e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4724e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 179ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6993e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4697e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 177ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6855e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4670e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 189ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6896e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4678e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 174ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6948e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4672e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 178ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00085\n",
      "38/38 - 6s - loss: 6.6842e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4756e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-08 - 6s/epoch - 159ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6890e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4682e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 192ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6934e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4693e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6881e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4691e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 8s/epoch - 204ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6842e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4679e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 8s/epoch - 206ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6923e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4712e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-08 - 8s/epoch - 200ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6865e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4664e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 8s/epoch - 203ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6914e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4676e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-08 - 7s/epoch - 186ms/step\n",
      "lr changed to 2.525622733173805e-09\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6972e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4669e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 7s/epoch - 197ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6909e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4665e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 7s/epoch - 190ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6883e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4679e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 7s/epoch - 194ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6905e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4676e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 7s/epoch - 192ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6895e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4665e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 7s/epoch - 192ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6874e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4683e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 7s/epoch - 188ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6935e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4702e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 7s/epoch - 179ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6830e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4681e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 7s/epoch - 190ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6894e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4725e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-09 - 7s/epoch - 191ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6843e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4718e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-09 - 7s/epoch - 187ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss improved from 0.00085 to 0.00085, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2007_best.hdf5\n",
      "38/38 - 9s - loss: 6.6921e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4643e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 9s/epoch - 234ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00085\n",
      "38/38 - 9s - loss: 6.6874e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4714e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-09 - 9s/epoch - 227ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6864e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4714e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 202ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6885e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4698e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 214ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6858e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4679e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 209ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6879e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4684e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 214ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6904e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4670e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 213ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6879e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4694e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 213ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6825e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4675e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 205ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6971e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4685e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 222ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6907e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4670e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 206ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.7035e-04 - R2: 0.9120 - mae: 0.0190 - val_loss: 8.4719e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 213ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6909e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4665e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 217ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6875e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4693e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 213ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00085\n",
      "38/38 - 9s - loss: 6.6890e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4662e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 9s/epoch - 225ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6873e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4708e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 207ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6944e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4677e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 210ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6866e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4671e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 213ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00085\n",
      "38/38 - 9s - loss: 6.6867e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4675e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 9s/epoch - 225ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6885e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4661e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-09 - 8s/epoch - 212ms/step\n",
      "lr changed to 2.525622821991647e-10\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6929e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4681e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 201ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00085\n",
      "38/38 - 9s - loss: 6.6882e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4665e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 9s/epoch - 230ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6949e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4728e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 220ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6873e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4676e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 217ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6902e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4681e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 211ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6894e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4673e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 201ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6857e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4700e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 220ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6876e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4669e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 221ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00085\n",
      "38/38 - 9s - loss: 6.6890e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4695e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 9s/epoch - 227ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6868e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4696e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 211ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6894e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4701e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 216ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00085\n",
      "38/38 - 9s - loss: 6.6860e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4672e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 9s/epoch - 229ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6955e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4683e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 198ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6894e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4748e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-10 - 7s/epoch - 186ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6855e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4670e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 209ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6911e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4662e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 7s/epoch - 191ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6872e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4697e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 7s/epoch - 193ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6910e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4685e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 206ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6889e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4724e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 203ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6911e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4757e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 200ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6932e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4679e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 201ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6905e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4648e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 219ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6879e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4692e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 7s/epoch - 189ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6915e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4657e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 7s/epoch - 196ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6891e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4668e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 219ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6957e-04 - R2: 0.9121 - mae: 0.0190 - val_loss: 8.4749e-04 - val_R2: 0.8888 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 198ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6856e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4670e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 200ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6879e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4659e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 7s/epoch - 181ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6889e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4679e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 8s/epoch - 208ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00085\n",
      "38/38 - 7s - loss: 6.6939e-04 - R2: 0.9122 - mae: 0.0190 - val_loss: 8.4699e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-10 - 7s/epoch - 192ms/step\n",
      "lr changed to 2.5256227664804953e-11\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00085\n",
      "38/38 - 8s - loss: 6.6859e-04 - R2: 0.9123 - mae: 0.0190 - val_loss: 8.4656e-04 - val_R2: 0.8889 - val_mae: 0.0212 - lr: 2.5256e-11 - 8s/epoch - 208ms/step\n",
      "Epoch 151: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f883fc2b50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2007\n",
      "{'units_choice': 6, 'kernel_size': 5, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.002525622919996073}\n",
      "2484/2484 [==============================] - 25s 10ms/step - loss: 8.4063e-04 - R2: 0.8825 - mae: 0.0211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0008406255510635674, 0.8824700713157654, 0.021147213876247406]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (625440, 18, 1)\n",
      "X_validate shape: (187632, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2008\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 11m 18s]\n",
      "val_R2: 0.6717671751976013\n",
      "\n",
      "Best val_R2 So Far: 0.9013871550559998\n",
      "Total elapsed time: 04h 35m 55s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 8s - loss: 6.5625e-04 - R2: 0.9159 - mae: 0.0187 - val_loss: 7.7330e-04 - val_R2: 0.9008 - val_mae: 0.0203 - lr: 1.1664e-05 - 8s/epoch - 198ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00077\n",
      "39/39 - 5s - loss: 6.5737e-04 - R2: 0.9159 - mae: 0.0187 - val_loss: 7.7547e-04 - val_R2: 0.9005 - val_mae: 0.0203 - lr: 1.1664e-05 - 5s/epoch - 139ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5831e-04 - R2: 0.9153 - mae: 0.0187 - val_loss: 7.8805e-04 - val_R2: 0.8989 - val_mae: 0.0206 - lr: 1.1664e-05 - 6s/epoch - 143ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5691e-04 - R2: 0.9158 - mae: 0.0187 - val_loss: 7.9018e-04 - val_R2: 0.8986 - val_mae: 0.0206 - lr: 1.1664e-05 - 6s/epoch - 146ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 6s - loss: 6.5614e-04 - R2: 0.9159 - mae: 0.0187 - val_loss: 7.6935e-04 - val_R2: 0.9013 - val_mae: 0.0202 - lr: 1.1664e-05 - 6s/epoch - 148ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5573e-04 - R2: 0.9159 - mae: 0.0187 - val_loss: 7.7209e-04 - val_R2: 0.9010 - val_mae: 0.0202 - lr: 1.1664e-05 - 6s/epoch - 144ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5646e-04 - R2: 0.9158 - mae: 0.0187 - val_loss: 7.7125e-04 - val_R2: 0.9011 - val_mae: 0.0202 - lr: 1.1664e-05 - 6s/epoch - 147ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 6s - loss: 6.5487e-04 - R2: 0.9160 - mae: 0.0187 - val_loss: 7.6887e-04 - val_R2: 0.9014 - val_mae: 0.0202 - lr: 1.1664e-05 - 6s/epoch - 153ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00077\n",
      "39/39 - 5s - loss: 6.5545e-04 - R2: 0.9159 - mae: 0.0187 - val_loss: 7.7169e-04 - val_R2: 0.9010 - val_mae: 0.0202 - lr: 1.1664e-05 - 5s/epoch - 141ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 5s - loss: 6.5538e-04 - R2: 0.9160 - mae: 0.0187 - val_loss: 7.6844e-04 - val_R2: 0.9014 - val_mae: 0.0202 - lr: 1.1664e-05 - 5s/epoch - 124ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00077\n",
      "39/39 - 5s - loss: 6.5319e-04 - R2: 0.9163 - mae: 0.0186 - val_loss: 7.7408e-04 - val_R2: 0.9007 - val_mae: 0.0203 - lr: 1.1664e-05 - 5s/epoch - 116ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 5s - loss: 6.5291e-04 - R2: 0.9163 - mae: 0.0186 - val_loss: 7.6756e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-05 - 5s/epoch - 125ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 5s - loss: 6.5309e-04 - R2: 0.9162 - mae: 0.0186 - val_loss: 7.6748e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-05 - 5s/epoch - 127ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00077\n",
      "39/39 - 5s - loss: 6.5345e-04 - R2: 0.9163 - mae: 0.0186 - val_loss: 7.7011e-04 - val_R2: 0.9012 - val_mae: 0.0202 - lr: 1.1664e-05 - 5s/epoch - 118ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00077\n",
      "39/39 - 5s - loss: 6.5372e-04 - R2: 0.9162 - mae: 0.0187 - val_loss: 7.7441e-04 - val_R2: 0.9007 - val_mae: 0.0203 - lr: 1.1664e-05 - 5s/epoch - 123ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 7s - loss: 6.5318e-04 - R2: 0.9163 - mae: 0.0186 - val_loss: 7.6740e-04 - val_R2: 0.9016 - val_mae: 0.0201 - lr: 1.1664e-05 - 7s/epoch - 172ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5282e-04 - R2: 0.9164 - mae: 0.0186 - val_loss: 7.6980e-04 - val_R2: 0.9013 - val_mae: 0.0202 - lr: 1.1664e-05 - 6s/epoch - 150ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5255e-04 - R2: 0.9163 - mae: 0.0186 - val_loss: 7.7437e-04 - val_R2: 0.9007 - val_mae: 0.0203 - lr: 1.1664e-05 - 6s/epoch - 156ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 7s - loss: 6.5168e-04 - R2: 0.9166 - mae: 0.0186 - val_loss: 7.6571e-04 - val_R2: 0.9018 - val_mae: 0.0201 - lr: 1.1664e-05 - 7s/epoch - 175ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5177e-04 - R2: 0.9162 - mae: 0.0186 - val_loss: 8.2408e-04 - val_R2: 0.8943 - val_mae: 0.0212 - lr: 1.1664e-05 - 6s/epoch - 159ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5310e-04 - R2: 0.9164 - mae: 0.0187 - val_loss: 7.6961e-04 - val_R2: 0.9013 - val_mae: 0.0202 - lr: 1.1664e-05 - 6s/epoch - 157ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5258e-04 - R2: 0.9164 - mae: 0.0186 - val_loss: 7.6699e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-05 - 6s/epoch - 156ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5147e-04 - R2: 0.9165 - mae: 0.0186 - val_loss: 7.7862e-04 - val_R2: 0.9001 - val_mae: 0.0204 - lr: 1.1664e-05 - 6s/epoch - 161ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5372e-04 - R2: 0.9160 - mae: 0.0187 - val_loss: 7.7753e-04 - val_R2: 0.9003 - val_mae: 0.0204 - lr: 1.1664e-05 - 6s/epoch - 165ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.5159e-04 - R2: 0.9165 - mae: 0.0186 - val_loss: 7.6722e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-05 - 6s/epoch - 160ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.4822e-04 - R2: 0.9169 - mae: 0.0186 - val_loss: 7.6825e-04 - val_R2: 0.9015 - val_mae: 0.0202 - lr: 1.1664e-05 - 6s/epoch - 154ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 6s - loss: 6.4824e-04 - R2: 0.9170 - mae: 0.0186 - val_loss: 7.6569e-04 - val_R2: 0.9018 - val_mae: 0.0201 - lr: 1.1664e-05 - 6s/epoch - 163ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.4833e-04 - R2: 0.9168 - mae: 0.0186 - val_loss: 7.7766e-04 - val_R2: 0.9003 - val_mae: 0.0204 - lr: 1.1664e-05 - 6s/epoch - 160ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.4801e-04 - R2: 0.9171 - mae: 0.0186 - val_loss: 7.6682e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-05 - 6s/epoch - 155ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 7s - loss: 6.5026e-04 - R2: 0.9166 - mae: 0.0186 - val_loss: 7.6541e-04 - val_R2: 0.9018 - val_mae: 0.0201 - lr: 1.1664e-05 - 7s/epoch - 173ms/step\n",
      "lr changed to 1.1664403245958967e-06\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00077\n",
      "39/39 - 6s - loss: 6.4616e-04 - R2: 0.9171 - mae: 0.0185 - val_loss: 7.6878e-04 - val_R2: 0.9014 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 155ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss improved from 0.00077 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 6s - loss: 6.4669e-04 - R2: 0.9169 - mae: 0.0186 - val_loss: 7.6494e-04 - val_R2: 0.9019 - val_mae: 0.0201 - lr: 1.1664e-06 - 6s/epoch - 165ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4465e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6895e-04 - val_R2: 0.9014 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 163ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4565e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.7048e-04 - val_R2: 0.9012 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 166ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4654e-04 - R2: 0.9172 - mae: 0.0186 - val_loss: 7.6665e-04 - val_R2: 0.9017 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 164ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4745e-04 - R2: 0.9170 - mae: 0.0186 - val_loss: 7.7022e-04 - val_R2: 0.9012 - val_mae: 0.0202 - lr: 1.1664e-06 - 7s/epoch - 170ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 6s - loss: 6.4530e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6440e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-06 - 6s/epoch - 166ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4637e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6651e-04 - val_R2: 0.9017 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 159ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4537e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6881e-04 - val_R2: 0.9014 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 163ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4624e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6642e-04 - val_R2: 0.9017 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 161ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4534e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6784e-04 - val_R2: 0.9015 - val_mae: 0.0202 - lr: 1.1664e-06 - 7s/epoch - 170ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4510e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6698e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 164ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4472e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6508e-04 - val_R2: 0.9019 - val_mae: 0.0201 - lr: 1.1664e-06 - 6s/epoch - 163ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4525e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.7146e-04 - val_R2: 0.9011 - val_mae: 0.0203 - lr: 1.1664e-06 - 6s/epoch - 162ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4526e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6743e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-06 - 7s/epoch - 169ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4434e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6735e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 164ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4530e-04 - R2: 0.9170 - mae: 0.0185 - val_loss: 8.0120e-04 - val_R2: 0.8972 - val_mae: 0.0208 - lr: 1.1664e-06 - 6s/epoch - 165ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4523e-04 - R2: 0.9171 - mae: 0.0185 - val_loss: 7.6789e-04 - val_R2: 0.9015 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 165ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 7s - loss: 6.4414e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6422e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-06 - 7s/epoch - 187ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4584e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.7513e-04 - val_R2: 0.9006 - val_mae: 0.0203 - lr: 1.1664e-06 - 7s/epoch - 180ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4522e-04 - R2: 0.9170 - mae: 0.0185 - val_loss: 8.0629e-04 - val_R2: 0.8966 - val_mae: 0.0209 - lr: 1.1664e-06 - 7s/epoch - 175ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4287e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.7490e-04 - val_R2: 0.9006 - val_mae: 0.0203 - lr: 1.1664e-06 - 7s/epoch - 171ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 7s - loss: 6.4406e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6274e-04 - val_R2: 0.9022 - val_mae: 0.0201 - lr: 1.1664e-06 - 7s/epoch - 182ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4561e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6668e-04 - val_R2: 0.9017 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 165ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4522e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6556e-04 - val_R2: 0.9018 - val_mae: 0.0201 - lr: 1.1664e-06 - 7s/epoch - 178ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4392e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.8611e-04 - val_R2: 0.8992 - val_mae: 0.0205 - lr: 1.1664e-06 - 7s/epoch - 178ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4324e-04 - R2: 0.9176 - mae: 0.0185 - val_loss: 7.6656e-04 - val_R2: 0.9017 - val_mae: 0.0202 - lr: 1.1664e-06 - 6s/epoch - 164ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4505e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6371e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4409e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6378e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-06 - 7s/epoch - 186ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4485e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.7257e-04 - val_R2: 0.9009 - val_mae: 0.0203 - lr: 1.1664e-06 - 7s/epoch - 179ms/step\n",
      "lr changed to 1.1664403700706317e-07\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4525e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6380e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-07 - 7s/epoch - 188ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4408e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6537e-04 - val_R2: 0.9018 - val_mae: 0.0201 - lr: 1.1664e-07 - 7s/epoch - 172ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4600e-04 - R2: 0.9170 - mae: 0.0185 - val_loss: 7.7642e-04 - val_R2: 0.9004 - val_mae: 0.0203 - lr: 1.1664e-07 - 6s/epoch - 162ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4572e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.7032e-04 - val_R2: 0.9012 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 160ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4425e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.7802e-04 - val_R2: 0.9002 - val_mae: 0.0204 - lr: 1.1664e-07 - 6s/epoch - 157ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4478e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6527e-04 - val_R2: 0.9018 - val_mae: 0.0201 - lr: 1.1664e-07 - 7s/epoch - 167ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4398e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6791e-04 - val_R2: 0.9015 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 154ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4278e-04 - R2: 0.9177 - mae: 0.0185 - val_loss: 7.6385e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-07 - 6s/epoch - 160ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4355e-04 - R2: 0.9171 - mae: 0.0185 - val_loss: 8.2878e-04 - val_R2: 0.8937 - val_mae: 0.0212 - lr: 1.1664e-07 - 6s/epoch - 157ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4290e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6419e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-07 - 6s/epoch - 151ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4451e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.7161e-04 - val_R2: 0.9010 - val_mae: 0.0203 - lr: 1.1664e-07 - 6s/epoch - 155ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4401e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.8211e-04 - val_R2: 0.8997 - val_mae: 0.0205 - lr: 1.1664e-07 - 6s/epoch - 157ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4320e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.7603e-04 - val_R2: 0.9005 - val_mae: 0.0204 - lr: 1.1664e-07 - 6s/epoch - 159ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4342e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.7105e-04 - val_R2: 0.9011 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 163ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4711e-04 - R2: 0.9171 - mae: 0.0186 - val_loss: 7.9360e-04 - val_R2: 0.8982 - val_mae: 0.0207 - lr: 1.1664e-07 - 6s/epoch - 160ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 6s - loss: 6.4458e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6261e-04 - val_R2: 0.9022 - val_mae: 0.0201 - lr: 1.1664e-07 - 6s/epoch - 166ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4424e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6747e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 152ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4403e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6616e-04 - val_R2: 0.9017 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 159ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4538e-04 - R2: 0.9171 - mae: 0.0185 - val_loss: 7.6778e-04 - val_R2: 0.9015 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 159ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4457e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6555e-04 - val_R2: 0.9018 - val_mae: 0.0201 - lr: 1.1664e-07 - 6s/epoch - 160ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4344e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.7730e-04 - val_R2: 0.9003 - val_mae: 0.0204 - lr: 1.1664e-07 - 7s/epoch - 169ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4359e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6758e-04 - val_R2: 0.9015 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 159ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4149e-04 - R2: 0.9176 - mae: 0.0185 - val_loss: 7.6693e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 166ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00076\n",
      "39/39 - 5s - loss: 6.4332e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.8554e-04 - val_R2: 0.8992 - val_mae: 0.0205 - lr: 1.1664e-07 - 5s/epoch - 120ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00076\n",
      "39/39 - 5s - loss: 6.4433e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.7796e-04 - val_R2: 0.9002 - val_mae: 0.0204 - lr: 1.1664e-07 - 5s/epoch - 141ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4331e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6865e-04 - val_R2: 0.9014 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 147ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4450e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6853e-04 - val_R2: 0.9014 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 166ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4573e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6378e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-07 - 6s/epoch - 156ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4349e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6798e-04 - val_R2: 0.9015 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 153ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4437e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6953e-04 - val_R2: 0.9013 - val_mae: 0.0202 - lr: 1.1664e-07 - 6s/epoch - 165ms/step\n",
      "lr changed to 1.1664403842814864e-08\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4472e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.8081e-04 - val_R2: 0.8999 - val_mae: 0.0204 - lr: 1.1664e-08 - 6s/epoch - 159ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4530e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6600e-04 - val_R2: 0.9018 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 153ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4376e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6608e-04 - val_R2: 0.9017 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 165ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4217e-04 - R2: 0.9178 - mae: 0.0185 - val_loss: 7.6299e-04 - val_R2: 0.9021 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 161ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4379e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6804e-04 - val_R2: 0.9015 - val_mae: 0.0202 - lr: 1.1664e-08 - 6s/epoch - 159ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2008_best.hdf5\n",
      "39/39 - 6s - loss: 6.4351e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6115e-04 - val_R2: 0.9024 - val_mae: 0.0200 - lr: 1.1664e-08 - 6s/epoch - 163ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4231e-04 - R2: 0.9177 - mae: 0.0185 - val_loss: 7.6484e-04 - val_R2: 0.9019 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 152ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4501e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6424e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-08 - 7s/epoch - 169ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4438e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6698e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-08 - 6s/epoch - 166ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4544e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.7184e-04 - val_R2: 0.9010 - val_mae: 0.0203 - lr: 1.1664e-08 - 6s/epoch - 150ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4349e-04 - R2: 0.9177 - mae: 0.0185 - val_loss: 7.6262e-04 - val_R2: 0.9022 - val_mae: 0.0201 - lr: 1.1664e-08 - 7s/epoch - 171ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4366e-04 - R2: 0.9176 - mae: 0.0185 - val_loss: 7.7191e-04 - val_R2: 0.9010 - val_mae: 0.0203 - lr: 1.1664e-08 - 6s/epoch - 148ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4389e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6810e-04 - val_R2: 0.9015 - val_mae: 0.0202 - lr: 1.1664e-08 - 6s/epoch - 166ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4346e-04 - R2: 0.9176 - mae: 0.0185 - val_loss: 7.6925e-04 - val_R2: 0.9013 - val_mae: 0.0202 - lr: 1.1664e-08 - 6s/epoch - 161ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4498e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6414e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 160ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4481e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6509e-04 - val_R2: 0.9019 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 155ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4305e-04 - R2: 0.9176 - mae: 0.0185 - val_loss: 7.6306e-04 - val_R2: 0.9021 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 156ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4509e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6608e-04 - val_R2: 0.9017 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 162ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4488e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6429e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 162ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4168e-04 - R2: 0.9177 - mae: 0.0185 - val_loss: 7.6263e-04 - val_R2: 0.9022 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 161ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4538e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6373e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 164ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4347e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.8977e-04 - val_R2: 0.8987 - val_mae: 0.0206 - lr: 1.1664e-08 - 6s/epoch - 163ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4322e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6741e-04 - val_R2: 0.9016 - val_mae: 0.0202 - lr: 1.1664e-08 - 6s/epoch - 156ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4272e-04 - R2: 0.9176 - mae: 0.0185 - val_loss: 7.6298e-04 - val_R2: 0.9021 - val_mae: 0.0201 - lr: 1.1664e-08 - 7s/epoch - 167ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4532e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.7529e-04 - val_R2: 0.9006 - val_mae: 0.0203 - lr: 1.1664e-08 - 6s/epoch - 159ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4304e-04 - R2: 0.9176 - mae: 0.0185 - val_loss: 7.6452e-04 - val_R2: 0.9019 - val_mae: 0.0201 - lr: 1.1664e-08 - 7s/epoch - 168ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4256e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6948e-04 - val_R2: 0.9013 - val_mae: 0.0202 - lr: 1.1664e-08 - 6s/epoch - 150ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4562e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6675e-04 - val_R2: 0.9017 - val_mae: 0.0202 - lr: 1.1664e-08 - 6s/epoch - 160ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4429e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6349e-04 - val_R2: 0.9021 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 156ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4262e-04 - R2: 0.9176 - mae: 0.0185 - val_loss: 7.6216e-04 - val_R2: 0.9023 - val_mae: 0.0201 - lr: 1.1664e-08 - 6s/epoch - 161ms/step\n",
      "lr changed to 1.166440366517918e-09\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4432e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6769e-04 - val_R2: 0.9015 - val_mae: 0.0202 - lr: 1.1664e-09 - 7s/epoch - 169ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4322e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.7219e-04 - val_R2: 0.9010 - val_mae: 0.0203 - lr: 1.1664e-09 - 6s/epoch - 153ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4483e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6585e-04 - val_R2: 0.9018 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 153ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4425e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6592e-04 - val_R2: 0.9018 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 156ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4414e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.7170e-04 - val_R2: 0.9010 - val_mae: 0.0203 - lr: 1.1664e-09 - 6s/epoch - 161ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4602e-04 - R2: 0.9172 - mae: 0.0186 - val_loss: 7.6411e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-09 - 6s/epoch - 156ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4356e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6369e-04 - val_R2: 0.9021 - val_mae: 0.0201 - lr: 1.1664e-09 - 7s/epoch - 171ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4109e-04 - R2: 0.9177 - mae: 0.0185 - val_loss: 7.6440e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-09 - 6s/epoch - 163ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4710e-04 - R2: 0.9171 - mae: 0.0186 - val_loss: 7.6460e-04 - val_R2: 0.9019 - val_mae: 0.0201 - lr: 1.1664e-09 - 6s/epoch - 159ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4465e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.7046e-04 - val_R2: 0.9012 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 160ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4367e-04 - R2: 0.9176 - mae: 0.0185 - val_loss: 7.6372e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-09 - 6s/epoch - 159ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4422e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.6897e-04 - val_R2: 0.9014 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 160ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4386e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6889e-04 - val_R2: 0.9014 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 166ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00076\n",
      "39/39 - 7s - loss: 6.4636e-04 - R2: 0.9169 - mae: 0.0185 - val_loss: 8.1663e-04 - val_R2: 0.8952 - val_mae: 0.0211 - lr: 1.1664e-09 - 7s/epoch - 169ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4424e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6444e-04 - val_R2: 0.9020 - val_mae: 0.0201 - lr: 1.1664e-09 - 6s/epoch - 162ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4539e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6767e-04 - val_R2: 0.9015 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 166ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4631e-04 - R2: 0.9171 - mae: 0.0186 - val_loss: 7.6882e-04 - val_R2: 0.9014 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 160ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4620e-04 - R2: 0.9171 - mae: 0.0186 - val_loss: 7.6345e-04 - val_R2: 0.9021 - val_mae: 0.0201 - lr: 1.1664e-09 - 6s/epoch - 157ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4451e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6975e-04 - val_R2: 0.9013 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 163ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4554e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.7369e-04 - val_R2: 0.9008 - val_mae: 0.0203 - lr: 1.1664e-09 - 6s/epoch - 163ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4281e-04 - R2: 0.9175 - mae: 0.0185 - val_loss: 7.6672e-04 - val_R2: 0.9017 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 162ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4481e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.7765e-04 - val_R2: 0.9003 - val_mae: 0.0204 - lr: 1.1664e-09 - 6s/epoch - 162ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4441e-04 - R2: 0.9173 - mae: 0.0185 - val_loss: 7.7032e-04 - val_R2: 0.9012 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 158ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4510e-04 - R2: 0.9172 - mae: 0.0185 - val_loss: 7.6863e-04 - val_R2: 0.9014 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 166ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4510e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.6602e-04 - val_R2: 0.9018 - val_mae: 0.0202 - lr: 1.1664e-09 - 6s/epoch - 162ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00076\n",
      "39/39 - 6s - loss: 6.4407e-04 - R2: 0.9174 - mae: 0.0185 - val_loss: 7.9062e-04 - val_R2: 0.8986 - val_mae: 0.0206 - lr: 1.1664e-09 - 6s/epoch - 153ms/step\n",
      "Epoch 146: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f883f15d30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2008\n",
      "{'units_choice': 4, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0011664403407834704}\n",
      "2513/2513 [==============================] - 29s 12ms/step - loss: 7.9086e-04 - R2: 0.8912 - mae: 0.0207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0007908611441962421, 0.8911523222923279, 0.020687131211161613]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (613756, 18, 1)\n",
      "X_validate shape: (184127, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2009\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 08m 14s]\n",
      "val_R2: 0.8871708512306213\n",
      "\n",
      "Best val_R2 So Far: 0.8896893858909607\n",
      "Total elapsed time: 04h 37m 08s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 10s - loss: 6.6525e-04 - R2: 0.9109 - mae: 0.0189 - val_loss: 8.2064e-04 - val_R2: 0.8896 - val_mae: 0.0209 - lr: 7.1342e-07 - 10s/epoch - 257ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6497e-04 - R2: 0.9109 - mae: 0.0189 - val_loss: 8.2126e-04 - val_R2: 0.8895 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 217ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 9s - loss: 6.6494e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2051e-04 - val_R2: 0.8896 - val_mae: 0.0209 - lr: 7.1342e-07 - 9s/epoch - 233ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 9s - loss: 6.6521e-04 - R2: 0.9109 - mae: 0.0189 - val_loss: 8.2018e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-07 - 9s/epoch - 224ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6497e-04 - R2: 0.9109 - mae: 0.0189 - val_loss: 8.2058e-04 - val_R2: 0.8896 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 223ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6489e-04 - R2: 0.9109 - mae: 0.0189 - val_loss: 8.2046e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 213ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6504e-04 - R2: 0.9108 - mae: 0.0189 - val_loss: 8.2060e-04 - val_R2: 0.8896 - val_mae: 0.0210 - lr: 7.1342e-07 - 8s/epoch - 218ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6499e-04 - R2: 0.9109 - mae: 0.0189 - val_loss: 8.2027e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 208ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6486e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2035e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 219ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6464e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2025e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-07 - 8s/epoch - 220ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6482e-04 - R2: 0.9109 - mae: 0.0189 - val_loss: 8.2036e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 209ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6474e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2038e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 215ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6477e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2058e-04 - val_R2: 0.8896 - val_mae: 0.0210 - lr: 7.1342e-07 - 8s/epoch - 216ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6445e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2020e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 216ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 8s - loss: 6.6485e-04 - R2: 0.9109 - mae: 0.0189 - val_loss: 8.2007e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 212ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6447e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2043e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 206ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6494e-04 - R2: 0.9109 - mae: 0.0189 - val_loss: 8.2033e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 211ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6397e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2019e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 213ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6459e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2016e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 208ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 9s - loss: 6.6441e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2007e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 9s/epoch - 226ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6441e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2035e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 221ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6454e-04 - R2: 0.9109 - mae: 0.0189 - val_loss: 8.2023e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 9s/epoch - 225ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6450e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2029e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 215ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 9s - loss: 6.6415e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2004e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 9s/epoch - 224ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 8s - loss: 6.6418e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1972e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 211ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6448e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2038e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 220ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6416e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2018e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 218ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6413e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2011e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-07 - 8s/epoch - 207ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6366e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1981e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 214ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6385e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1975e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-07 - 8s/epoch - 210ms/step\n",
      "lr changed to 7.134180464163365e-08\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6358e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1998e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 9s/epoch - 226ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6400e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1994e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 223ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6360e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1999e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 220ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6331e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1987e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 204ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6368e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1991e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 218ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6368e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1980e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-08 - 8s/epoch - 221ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6342e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.2012e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 7s/epoch - 179ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00082\n",
      "38/38 - 6s - loss: 6.6345e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1987e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 6s/epoch - 149ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6374e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1990e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-08 - 8s/epoch - 199ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6347e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2055e-04 - val_R2: 0.8896 - val_mae: 0.0209 - lr: 7.1342e-08 - 7s/epoch - 193ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 8s - loss: 6.6349e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1969e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 210ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6346e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1983e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 197ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6385e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1986e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 7s/epoch - 197ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6374e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2059e-04 - val_R2: 0.8896 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 199ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6398e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2035e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 206ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6384e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1984e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 203ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6382e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1999e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 198ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6351e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1988e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-08 - 7s/epoch - 196ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6378e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2025e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 198ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6387e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1974e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 202ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6382e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1974e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 199ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 8s - loss: 6.6348e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1968e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 213ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6358e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2011e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 206ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6391e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1971e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 203ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6335e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1993e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 198ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6346e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1994e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 202ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 8s - loss: 6.6319e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1968e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 204ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6342e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2047e-04 - val_R2: 0.8896 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 199ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6378e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1974e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-08 - 8s/epoch - 205ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6355e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1992e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-08 - 8s/epoch - 198ms/step\n",
      "lr changed to 7.134180179946271e-09\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6321e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.2029e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 206ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6354e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1968e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 204ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6365e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1972e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 7s/epoch - 195ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6403e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1976e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 201ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6378e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2029e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 203ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6339e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1976e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 199ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6310e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2006e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-09 - 8s/epoch - 199ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6353e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1977e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 206ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6337e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2029e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 206ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6303e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1981e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 207ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6317e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.2003e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 201ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6347e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2000e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 201ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6311e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1968e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 198ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6362e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2017e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 198ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6355e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2004e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 205ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6360e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1991e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-09 - 8s/epoch - 201ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6390e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1993e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 206ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6319e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1995e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 208ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6379e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2007e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 202ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6379e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1993e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 209ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6343e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1991e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 207ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6332e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1979e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 205ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6380e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1984e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 7s/epoch - 197ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6323e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1998e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 201ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6310e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.2022e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 7s/epoch - 196ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6344e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1988e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 208ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6381e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1996e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-09 - 8s/epoch - 207ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6399e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1972e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 208ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6368e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2008e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 8s/epoch - 206ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6346e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2011e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-09 - 7s/epoch - 196ms/step\n",
      "lr changed to 7.134180357581954e-10\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6329e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1984e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 201ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6341e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1980e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-10 - 8s/epoch - 202ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6355e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2001e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 198ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6382e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2011e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 203ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6383e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1978e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 199ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00082\n",
      "38/38 - 5s - loss: 6.6356e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1977e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 5s/epoch - 144ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6341e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2008e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 203ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6347e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1981e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 7s/epoch - 188ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 9s - loss: 6.6365e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1954e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-10 - 9s/epoch - 224ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6409e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1985e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 222ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6357e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1989e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 9s/epoch - 225ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6349e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2004e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 222ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6340e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1963e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 209ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6339e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2061e-04 - val_R2: 0.8896 - val_mae: 0.0209 - lr: 7.1342e-10 - 9s/epoch - 229ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6327e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1988e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 215ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6406e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1980e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 217ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6380e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2013e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 215ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6353e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1996e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 9s/epoch - 231ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6345e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1957e-04 - val_R2: 0.8898 - val_mae: 0.0210 - lr: 7.1342e-10 - 8s/epoch - 224ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6330e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1967e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-10 - 9s/epoch - 232ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6339e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1987e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 213ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6349e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1989e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 9s/epoch - 225ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6329e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1997e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 9s/epoch - 230ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6364e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1985e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 217ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6367e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1983e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 9s/epoch - 229ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6331e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2008e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 9s/epoch - 233ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6356e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1958e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 214ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6367e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1991e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 9s/epoch - 234ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6332e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1981e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 215ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6378e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1992e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-10 - 8s/epoch - 220ms/step\n",
      "lr changed to 7.134180468604258e-11\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6357e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2022e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-11 - 9s/epoch - 231ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6341e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1976e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 231ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6338e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1990e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 226ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6324e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1997e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 231ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6342e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1974e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 230ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6389e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1978e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 234ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6313e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1959e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 231ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6333e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1979e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 223ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6342e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.2003e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 211ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6325e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1978e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 212ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6332e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1989e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 216ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6384e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2014e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 218ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6352e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1978e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 226ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2009_best.hdf5\n",
      "38/38 - 9s - loss: 6.6331e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1947e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 234ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6365e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2032e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 224ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6343e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1999e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 219ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6347e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1977e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 212ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6322e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1972e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 212ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6368e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2029e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 215ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6342e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1965e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 220ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6337e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1964e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 225ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6357e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2004e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 229ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6336e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1986e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 225ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6361e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2017e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 222ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6336e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1979e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 230ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6360e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1989e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 212ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6358e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.2013e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 217ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6355e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1987e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 219ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6384e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1966e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-11 - 8s/epoch - 215ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6355e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1967e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-11 - 9s/epoch - 229ms/step\n",
      "lr changed to 7.134180746160013e-12\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6354e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2011e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-12 - 9s/epoch - 227ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00082\n",
      "38/38 - 9s - loss: 6.6320e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1981e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 9s/epoch - 224ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00082\n",
      "38/38 - 5s - loss: 6.6344e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1981e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 5s/epoch - 144ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6330e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1973e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 7s/epoch - 188ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6374e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1974e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 199ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6376e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1968e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 203ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6348e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1995e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 202ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6356e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1999e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 200ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6347e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2055e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-12 - 8s/epoch - 199ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6369e-04 - R2: 0.9110 - mae: 0.0189 - val_loss: 8.1963e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 199ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6331e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1950e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-12 - 7s/epoch - 197ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6371e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1967e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 198ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6344e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1980e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 201ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6312e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.2000e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 198ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6364e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1979e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 199ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6381e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2002e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 199ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6361e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1984e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 198ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6361e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1994e-04 - val_R2: 0.8897 - val_mae: 0.0210 - lr: 7.1342e-12 - 8s/epoch - 198ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6346e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1986e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 7s/epoch - 197ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6318e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2011e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 7s/epoch - 197ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6346e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1979e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 201ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6366e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2003e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 201ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6349e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1980e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 200ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6313e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1987e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 198ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6341e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1983e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 199ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6354e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1998e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 198ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6328e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1978e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 204ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6334e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2003e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 203ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6344e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1967e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 199ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6354e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1992e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-12 - 8s/epoch - 200ms/step\n",
      "lr changed to 7.134180832896187e-13\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6352e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1984e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-13 - 7s/epoch - 196ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00082\n",
      "38/38 - 7s - loss: 6.6363e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.2018e-04 - val_R2: 0.8897 - val_mae: 0.0209 - lr: 7.1342e-13 - 7s/epoch - 194ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6357e-04 - R2: 0.9112 - mae: 0.0189 - val_loss: 8.1968e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-13 - 8s/epoch - 202ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.00082\n",
      "38/38 - 8s - loss: 6.6368e-04 - R2: 0.9111 - mae: 0.0189 - val_loss: 8.1965e-04 - val_R2: 0.8898 - val_mae: 0.0209 - lr: 7.1342e-13 - 8s/epoch - 205ms/step\n",
      "Epoch 184: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f884067790>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2009\n",
      "{'units_choice': 8, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0007134180666249963}\n",
      "2466/2466 [==============================] - 24s 10ms/step - loss: 8.1853e-04 - R2: 0.8833 - mae: 0.0209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0008185265469364822, 0.8833301663398743, 0.02090991660952568]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (650862, 18, 1)\n",
      "X_validate shape: (195259, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2010\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 02m 14s]\n",
      "val_R2: -6.503274917602539\n",
      "\n",
      "Best val_R2 So Far: 0.8944718241691589\n",
      "Total elapsed time: 04h 03m 03s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 10s - loss: 6.2681e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2327e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 10s/epoch - 262ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 9s - loss: 6.2617e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2320e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 226ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2646e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2323e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 215ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 9s - loss: 6.2840e-04 - R2: 0.9193 - mae: 0.0184 - val_loss: 8.2315e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 228ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 9s - loss: 6.2673e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2308e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 222ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2714e-04 - R2: 0.9195 - mae: 0.0184 - val_loss: 8.2336e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 220ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2610e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2325e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 227ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 9s - loss: 6.2676e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2291e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 219ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2749e-04 - R2: 0.9194 - mae: 0.0184 - val_loss: 8.2396e-04 - val_R2: 0.8943 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 220ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2774e-04 - R2: 0.9194 - mae: 0.0184 - val_loss: 8.2385e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 219ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2634e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2339e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 215ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2662e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2330e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 213ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2809e-04 - R2: 0.9193 - mae: 0.0184 - val_loss: 8.2321e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 232ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2605e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2332e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 217ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2684e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2363e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 220ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2675e-04 - R2: 0.9195 - mae: 0.0184 - val_loss: 8.2395e-04 - val_R2: 0.8943 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 219ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2703e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2316e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 220ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2648e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2331e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 218ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2632e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2345e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 216ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2740e-04 - R2: 0.9194 - mae: 0.0184 - val_loss: 8.2427e-04 - val_R2: 0.8943 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 216ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2643e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2348e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 8s/epoch - 212ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2633e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2346e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 216ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2584e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2337e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 220ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2553e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2305e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 216ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2598e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2296e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 229ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 9s - loss: 6.2665e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2283e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 218ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2593e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2300e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 214ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2615e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2312e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 218ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2567e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2316e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-07 - 9s/epoch - 225ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2651e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2288e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-07 - 8s/epoch - 205ms/step\n",
      "lr changed to 7.134180464163365e-08\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 9s - loss: 6.2624e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2268e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 9s/epoch - 227ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 9s - loss: 6.2581e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2259e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 9s/epoch - 232ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 9s - loss: 6.2617e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2255e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 9s/epoch - 227ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2575e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2343e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-08 - 9s/epoch - 214ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2469e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2296e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 9s/epoch - 218ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2504e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2276e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 8s/epoch - 210ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2569e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2304e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 9s/epoch - 220ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00082\n",
      "40/40 - 6s - loss: 6.2650e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2256e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 6s/epoch - 161ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2484e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2294e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 163ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2554e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2307e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 170ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2505e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2267e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 185ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2567e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2280e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2509e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2284e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 182ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2533e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2266e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 182ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2539e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2275e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2543e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2286e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 179ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2587e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2261e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 182ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2615e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2321e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 180ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2583e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2276e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 181ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2535e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2300e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 8s - loss: 6.2580e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2251e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 8s/epoch - 192ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2558e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2311e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 184ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2484e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2265e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 182ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2515e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2299e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 182ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2456e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2288e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 179ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2530e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2376e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 179ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2546e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2288e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 178ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2514e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2284e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 181ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2530e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2293e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2652e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2260e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-08 - 7s/epoch - 185ms/step\n",
      "lr changed to 7.134180179946271e-09\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2572e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2273e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2588e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2265e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 181ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2490e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2380e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 181ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2568e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2273e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 182ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2559e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2271e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 182ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2550e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2277e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 179ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2570e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2273e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 184ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2663e-04 - R2: 0.9195 - mae: 0.0184 - val_loss: 8.2321e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 182ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2664e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2274e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 184ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2598e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2278e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2516e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2331e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 182ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2620e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2276e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2521e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2256e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 182ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2540e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2311e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 181ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2526e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2261e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 180ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2583e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2298e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 182ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2499e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2313e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 182ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2610e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2296e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 181ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2601e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2271e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 182ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 8s - loss: 6.2550e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2249e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 8s/epoch - 195ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2561e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2285e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 184ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2541e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2390e-04 - val_R2: 0.8943 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 181ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2527e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2268e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 185ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2589e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2277e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 180ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2475e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2286e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 181ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2487e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2281e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 180ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2494e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2278e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 182ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2509e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2251e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 181ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2587e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2284e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2521e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2274e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-09 - 7s/epoch - 185ms/step\n",
      "lr changed to 7.134180357581954e-10\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2601e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2279e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 7s/epoch - 183ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2561e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2282e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 7s/epoch - 182ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2654e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2365e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-10 - 7s/epoch - 180ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2506e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2295e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 7s/epoch - 181ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2553e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2323e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-10 - 7s/epoch - 167ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00082\n",
      "40/40 - 6s - loss: 6.2622e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2333e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-10 - 6s/epoch - 154ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2520e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2258e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 199ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2612e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2305e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 209ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2558e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2273e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 9s/epoch - 213ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2524e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2271e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 209ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2546e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2269e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 209ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2529e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2291e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 209ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss improved from 0.00082 to 0.00082, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2010_best.hdf5\n",
      "40/40 - 9s - loss: 6.2513e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2246e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 9s/epoch - 214ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2574e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2278e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 208ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2577e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2276e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 208ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2511e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2283e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 210ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2621e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2265e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 202ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2578e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2269e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 207ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2554e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2277e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 207ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2526e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2259e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 202ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2525e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2277e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 204ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2561e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2329e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 207ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2525e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2271e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 188ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2520e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2268e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 209ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2558e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2284e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 210ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2577e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2304e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 211ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2524e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2275e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 209ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2591e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2303e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 209ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2591e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2295e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 208ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2499e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2295e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-10 - 8s/epoch - 207ms/step\n",
      "lr changed to 7.134180468604258e-11\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2447e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2289e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 207ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2534e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2255e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 206ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2511e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2282e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 203ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2506e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2323e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 208ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2532e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2259e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 207ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2536e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2293e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 203ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2527e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2287e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 207ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2538e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2302e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 210ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2565e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2327e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 206ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2572e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2443e-04 - val_R2: 0.8943 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 205ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2569e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2339e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 208ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2546e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2301e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 205ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2574e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2277e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 207ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2545e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2296e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 207ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2530e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2257e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 211ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2634e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2290e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 209ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2479e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2277e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 209ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2664e-04 - R2: 0.9195 - mae: 0.0183 - val_loss: 8.2258e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 209ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2635e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2264e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 209ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2496e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2305e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 208ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2584e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2268e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 205ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2572e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2260e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 205ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2490e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2291e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 209ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2497e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2288e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 203ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2530e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2309e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 202ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2601e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2282e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 204ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2499e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2267e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 8s/epoch - 206ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00082\n",
      "40/40 - 9s - loss: 6.2506e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2259e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 9s/epoch - 213ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2569e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2266e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 7s/epoch - 187ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00082\n",
      "40/40 - 6s - loss: 6.2596e-04 - R2: 0.9196 - mae: 0.0183 - val_loss: 8.2309e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-11 - 6s/epoch - 146ms/step\n",
      "lr changed to 7.134180746160013e-12\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2544e-04 - R2: 0.9197 - mae: 0.0183 - val_loss: 8.2280e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-12 - 8s/epoch - 192ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00082\n",
      "40/40 - 7s - loss: 6.2472e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2300e-04 - val_R2: 0.8945 - val_mae: 0.0208 - lr: 7.1342e-12 - 7s/epoch - 183ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00082\n",
      "40/40 - 8s - loss: 6.2430e-04 - R2: 0.9198 - mae: 0.0183 - val_loss: 8.2322e-04 - val_R2: 0.8944 - val_mae: 0.0208 - lr: 7.1342e-12 - 8s/epoch - 189ms/step\n",
      "Epoch 153: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f88482fc70>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2010\n",
      "{'units_choice': 8, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0007134180666249963}\n",
      "2616/2616 [==============================] - 26s 10ms/step - loss: 8.0904e-04 - R2: 0.8879 - mae: 0.0208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0008090377668850124, 0.8878769278526306, 0.02076665498316288]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (657288, 18, 1)\n",
      "X_validate shape: (197187, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2011\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 01m 28s]\n",
      "val_R2: -6.685684680938721\n",
      "\n",
      "Best val_R2 So Far: 0.893876314163208\n",
      "Total elapsed time: 03h 32m 43s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2011_best.hdf5\n",
      "41/41 - 6s - loss: 6.6714e-04 - R2: 0.9081 - mae: 0.0190 - val_loss: 7.7458e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 6s/epoch - 146ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6692e-04 - R2: 0.9079 - mae: 0.0190 - val_loss: 7.7490e-04 - val_R2: 0.8938 - val_mae: 0.0204 - lr: 4.1282e-06 - 4s/epoch - 99ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6660e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7468e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 104ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6657e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7470e-04 - val_R2: 0.8938 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 107ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6674e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7501e-04 - val_R2: 0.8938 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 100ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6606e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7495e-04 - val_R2: 0.8938 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 106ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6669e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7587e-04 - val_R2: 0.8937 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 104ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6668e-04 - R2: 0.9082 - mae: 0.0190 - val_loss: 7.7476e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 105ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6666e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7474e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 104ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6609e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7480e-04 - val_R2: 0.8938 - val_mae: 0.0204 - lr: 4.1282e-06 - 4s/epoch - 99ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2011_best.hdf5\n",
      "41/41 - 5s - loss: 6.6667e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7427e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 5s/epoch - 115ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6648e-04 - R2: 0.9079 - mae: 0.0190 - val_loss: 7.7462e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-06 - 4s/epoch - 106ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6652e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7472e-04 - val_R2: 0.8938 - val_mae: 0.0204 - lr: 4.1282e-06 - 4s/epoch - 105ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6647e-04 - R2: 0.9082 - mae: 0.0190 - val_loss: 7.7462e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 107ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6621e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7451e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 89ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00077\n",
      "41/41 - 3s - loss: 6.6609e-04 - R2: 0.9081 - mae: 0.0190 - val_loss: 7.7518e-04 - val_R2: 0.8938 - val_mae: 0.0205 - lr: 4.1282e-06 - 3s/epoch - 74ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00077\n",
      "41/41 - 3s - loss: 6.6620e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7493e-04 - val_R2: 0.8938 - val_mae: 0.0205 - lr: 4.1282e-06 - 3s/epoch - 76ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6636e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7473e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 109ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6584e-04 - R2: 0.9081 - mae: 0.0190 - val_loss: 7.7449e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 87ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2011_best.hdf5\n",
      "41/41 - 5s - loss: 6.6584e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7414e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 5s/epoch - 113ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6569e-04 - R2: 0.9078 - mae: 0.0190 - val_loss: 7.7462e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 101ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2011_best.hdf5\n",
      "41/41 - 4s - loss: 6.6539e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7407e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-06 - 4s/epoch - 107ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6522e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7412e-04 - val_R2: 0.8940 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 107ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6549e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7520e-04 - val_R2: 0.8938 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 104ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6568e-04 - R2: 0.9082 - mae: 0.0190 - val_loss: 7.7418e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 106ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6560e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7490e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-06 - 4s/epoch - 104ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6579e-04 - R2: 0.9076 - mae: 0.0190 - val_loss: 7.7423e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-06 - 4s/epoch - 101ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6577e-04 - R2: 0.9082 - mae: 0.0190 - val_loss: 7.7411e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 106ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6540e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7430e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-06 - 4s/epoch - 102ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6479e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7504e-04 - val_R2: 0.8938 - val_mae: 0.0205 - lr: 4.1282e-06 - 4s/epoch - 100ms/step\n",
      "lr changed to 4.128177351958584e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6476e-04 - R2: 0.9087 - mae: 0.0190 - val_loss: 7.7408e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-07 - 4s/epoch - 108ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6525e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7549e-04 - val_R2: 0.8938 - val_mae: 0.0204 - lr: 4.1282e-07 - 4s/epoch - 104ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2011_best.hdf5\n",
      "41/41 - 5s - loss: 6.6485e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7377e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-07 - 5s/epoch - 112ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6499e-04 - R2: 0.9081 - mae: 0.0190 - val_loss: 7.7535e-04 - val_R2: 0.8937 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 109ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6436e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7422e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 99ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6470e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7412e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 109ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6467e-04 - R2: 0.9078 - mae: 0.0190 - val_loss: 7.7428e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 105ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6494e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7514e-04 - val_R2: 0.8938 - val_mae: 0.0204 - lr: 4.1282e-07 - 4s/epoch - 101ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6495e-04 - R2: 0.9087 - mae: 0.0190 - val_loss: 7.7432e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 110ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6501e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7396e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-07 - 4s/epoch - 105ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6507e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7492e-04 - val_R2: 0.8938 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 102ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6466e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7503e-04 - val_R2: 0.8938 - val_mae: 0.0204 - lr: 4.1282e-07 - 4s/epoch - 109ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6493e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7532e-04 - val_R2: 0.8938 - val_mae: 0.0204 - lr: 4.1282e-07 - 4s/epoch - 102ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6443e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7434e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 103ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6500e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7390e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 108ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6514e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7406e-04 - val_R2: 0.8940 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 101ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2011_best.hdf5\n",
      "41/41 - 5s - loss: 6.6468e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7360e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-07 - 5s/epoch - 110ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6463e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7415e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 110ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6456e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7397e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-07 - 4s/epoch - 104ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6464e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7415e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 102ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00077\n",
      "41/41 - 5s - loss: 6.6485e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7408e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-07 - 5s/epoch - 111ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6450e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7426e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 101ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6480e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7429e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 102ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6508e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7416e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-07 - 4s/epoch - 109ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6508e-04 - R2: 0.9087 - mae: 0.0190 - val_loss: 7.7387e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-07 - 4s/epoch - 99ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6493e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7450e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 108ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6453e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7393e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-07 - 4s/epoch - 110ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6494e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7377e-04 - val_R2: 0.8940 - val_mae: 0.0205 - lr: 4.1282e-07 - 4s/epoch - 103ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2011_best.hdf5\n",
      "41/41 - 5s - loss: 6.6420e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7357e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-07 - 5s/epoch - 115ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6506e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7412e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-07 - 4s/epoch - 107ms/step\n",
      "lr changed to 4.128177408802003e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6472e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7423e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 101ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss improved from 0.00077 to 0.00077, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2011_best.hdf5\n",
      "41/41 - 5s - loss: 6.6460e-04 - R2: 0.9087 - mae: 0.0190 - val_loss: 7.7356e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-08 - 5s/epoch - 111ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6439e-04 - R2: 0.9088 - mae: 0.0190 - val_loss: 7.7431e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 104ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6485e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7442e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 101ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6428e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7436e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 107ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6459e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7469e-04 - val_R2: 0.8938 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 100ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6450e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7418e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 102ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6448e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7398e-04 - val_R2: 0.8940 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 109ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6460e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7392e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 101ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6471e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7465e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 105ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6462e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7370e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 104ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6494e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7453e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 101ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6419e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7386e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 108ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6428e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7415e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 104ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6451e-04 - R2: 0.9087 - mae: 0.0190 - val_loss: 7.7446e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 99ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6470e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7417e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 106ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6497e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7475e-04 - val_R2: 0.8938 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 101ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6443e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7443e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 106ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6478e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7419e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 105ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6428e-04 - R2: 0.9088 - mae: 0.0190 - val_loss: 7.7362e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 101ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6438e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7413e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 107ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6429e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7364e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 103ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6469e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7395e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 101ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00077\n",
      "41/41 - 5s - loss: 6.6421e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7420e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-08 - 5s/epoch - 111ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6473e-04 - R2: 0.9087 - mae: 0.0190 - val_loss: 7.7390e-04 - val_R2: 0.8940 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 104ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6486e-04 - R2: 0.9082 - mae: 0.0190 - val_loss: 7.7428e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 102ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6481e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7411e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 107ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6394e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7381e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 101ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6525e-04 - R2: 0.9083 - mae: 0.0190 - val_loss: 7.7493e-04 - val_R2: 0.8938 - val_mae: 0.0205 - lr: 4.1282e-08 - 4s/epoch - 106ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6482e-04 - R2: 0.9079 - mae: 0.0190 - val_loss: 7.7459e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-08 - 4s/epoch - 106ms/step\n",
      "lr changed to 4.128177266693456e-09\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6448e-04 - R2: 0.9087 - mae: 0.0190 - val_loss: 7.7386e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 100ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6441e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7378e-04 - val_R2: 0.8940 - val_mae: 0.0205 - lr: 4.1282e-09 - 4s/epoch - 107ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6437e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7470e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 104ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6457e-04 - R2: 0.9081 - mae: 0.0190 - val_loss: 7.7394e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 103ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00077\n",
      "41/41 - 5s - loss: 6.6455e-04 - R2: 0.9088 - mae: 0.0190 - val_loss: 7.7384e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-09 - 5s/epoch - 110ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00077\n",
      "41/41 - 3s - loss: 6.6453e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7433e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-09 - 3s/epoch - 81ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00077\n",
      "41/41 - 3s - loss: 6.6502e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7368e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-09 - 3s/epoch - 74ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6466e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7492e-04 - val_R2: 0.8938 - val_mae: 0.0205 - lr: 4.1282e-09 - 4s/epoch - 86ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00077\n",
      "41/41 - 5s - loss: 6.6455e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7374e-04 - val_R2: 0.8940 - val_mae: 0.0205 - lr: 4.1282e-09 - 5s/epoch - 113ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00077\n",
      "41/41 - 3s - loss: 6.6404e-04 - R2: 0.9087 - mae: 0.0190 - val_loss: 7.7407e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-09 - 3s/epoch - 85ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00077\n",
      "41/41 - 5s - loss: 6.6457e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7395e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-09 - 5s/epoch - 112ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6427e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7409e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 104ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6411e-04 - R2: 0.9084 - mae: 0.0190 - val_loss: 7.7420e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 109ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6436e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7434e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 105ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6472e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7387e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 107ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6439e-04 - R2: 0.9087 - mae: 0.0190 - val_loss: 7.7407e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 108ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6477e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7395e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 105ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00077\n",
      "41/41 - 5s - loss: 6.6478e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7407e-04 - val_R2: 0.8939 - val_mae: 0.0205 - lr: 4.1282e-09 - 5s/epoch - 112ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6452e-04 - R2: 0.9085 - mae: 0.0190 - val_loss: 7.7389e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 104ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00077\n",
      "41/41 - 5s - loss: 6.6476e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7360e-04 - val_R2: 0.8940 - val_mae: 0.0204 - lr: 4.1282e-09 - 5s/epoch - 110ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6492e-04 - R2: 0.9082 - mae: 0.0190 - val_loss: 7.7669e-04 - val_R2: 0.8936 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 105ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00077\n",
      "41/41 - 4s - loss: 6.6441e-04 - R2: 0.9086 - mae: 0.0190 - val_loss: 7.7423e-04 - val_R2: 0.8939 - val_mae: 0.0204 - lr: 4.1282e-09 - 4s/epoch - 104ms/step\n",
      "Epoch 112: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f88554d7c0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2011\n",
      "{'units_choice': 2, 'kernel_size': 5, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.004128177547095777}\n",
      "2641/2641 [==============================] - 24s 9ms/step - loss: 7.7608e-04 - R2: 0.8842 - mae: 0.0205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.000776084722019732, 0.8841922879219055, 0.02046854980289936]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2012 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (660527, 18, 1)\n",
      "X_validate shape: (198158, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2012\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 14m 02s]\n",
      "val_R2: 0.9061621427536011\n",
      "\n",
      "Best val_R2 So Far: 0.9061621427536011\n",
      "Total elapsed time: 04h 17m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2012_best.hdf5\n",
      "41/41 - 10s - loss: 6.3797e-04 - R2: 0.9214 - mae: 0.0185 - val_loss: 7.5872e-04 - val_R2: 0.9061 - val_mae: 0.0199 - lr: 2.5696e-06 - 10s/epoch - 247ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2012_best.hdf5\n",
      "41/41 - 9s - loss: 6.3824e-04 - R2: 0.9212 - mae: 0.0185 - val_loss: 7.5832e-04 - val_R2: 0.9061 - val_mae: 0.0198 - lr: 2.5696e-06 - 9s/epoch - 218ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3803e-04 - R2: 0.9214 - mae: 0.0185 - val_loss: 7.5928e-04 - val_R2: 0.9060 - val_mae: 0.0198 - lr: 2.5696e-06 - 9s/epoch - 216ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3871e-04 - R2: 0.9212 - mae: 0.0185 - val_loss: 7.6171e-04 - val_R2: 0.9057 - val_mae: 0.0199 - lr: 2.5696e-06 - 9s/epoch - 219ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2012_best.hdf5\n",
      "41/41 - 9s - loss: 6.3837e-04 - R2: 0.9213 - mae: 0.0185 - val_loss: 7.5790e-04 - val_R2: 0.9061 - val_mae: 0.0198 - lr: 2.5696e-06 - 9s/epoch - 219ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3835e-04 - R2: 0.9213 - mae: 0.0185 - val_loss: 7.5894e-04 - val_R2: 0.9060 - val_mae: 0.0198 - lr: 2.5696e-06 - 8s/epoch - 203ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2012_best.hdf5\n",
      "41/41 - 9s - loss: 6.3793e-04 - R2: 0.9213 - mae: 0.0185 - val_loss: 7.5732e-04 - val_R2: 0.9062 - val_mae: 0.0198 - lr: 2.5696e-06 - 9s/epoch - 210ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3848e-04 - R2: 0.9212 - mae: 0.0185 - val_loss: 7.6540e-04 - val_R2: 0.9053 - val_mae: 0.0200 - lr: 2.5696e-06 - 8s/epoch - 199ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3753e-04 - R2: 0.9213 - mae: 0.0185 - val_loss: 7.5935e-04 - val_R2: 0.9060 - val_mae: 0.0199 - lr: 2.5696e-06 - 9s/epoch - 212ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2012_best.hdf5\n",
      "41/41 - 9s - loss: 6.3757e-04 - R2: 0.9214 - mae: 0.0185 - val_loss: 7.5710e-04 - val_R2: 0.9062 - val_mae: 0.0198 - lr: 2.5696e-06 - 9s/epoch - 223ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00076\n",
      "41/41 - 6s - loss: 6.3743e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.5743e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-06 - 6s/epoch - 142ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00076\n",
      "41/41 - 7s - loss: 6.3708e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.5727e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-06 - 7s/epoch - 175ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3760e-04 - R2: 0.9212 - mae: 0.0185 - val_loss: 7.6338e-04 - val_R2: 0.9055 - val_mae: 0.0200 - lr: 2.5696e-06 - 8s/epoch - 186ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3814e-04 - R2: 0.9212 - mae: 0.0185 - val_loss: 7.7298e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 2.5696e-06 - 8s/epoch - 207ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3813e-04 - R2: 0.9213 - mae: 0.0185 - val_loss: 7.5890e-04 - val_R2: 0.9060 - val_mae: 0.0199 - lr: 2.5696e-06 - 9s/epoch - 214ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3775e-04 - R2: 0.9214 - mae: 0.0185 - val_loss: 7.5897e-04 - val_R2: 0.9060 - val_mae: 0.0199 - lr: 2.5696e-06 - 9s/epoch - 211ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3866e-04 - R2: 0.9213 - mae: 0.0185 - val_loss: 7.5973e-04 - val_R2: 0.9059 - val_mae: 0.0199 - lr: 2.5696e-06 - 9s/epoch - 209ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3815e-04 - R2: 0.9213 - mae: 0.0185 - val_loss: 7.5827e-04 - val_R2: 0.9061 - val_mae: 0.0198 - lr: 2.5696e-06 - 9s/epoch - 209ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3650e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.6110e-04 - val_R2: 0.9058 - val_mae: 0.0199 - lr: 2.5696e-06 - 9s/epoch - 209ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3686e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.5780e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-06 - 8s/epoch - 198ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3732e-04 - R2: 0.9214 - mae: 0.0185 - val_loss: 7.5915e-04 - val_R2: 0.9060 - val_mae: 0.0199 - lr: 2.5696e-06 - 8s/epoch - 204ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2012_best.hdf5\n",
      "41/41 - 9s - loss: 6.3702e-04 - R2: 0.9214 - mae: 0.0185 - val_loss: 7.5688e-04 - val_R2: 0.9063 - val_mae: 0.0198 - lr: 2.5696e-06 - 9s/epoch - 222ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2012_best.hdf5\n",
      "41/41 - 9s - loss: 6.3725e-04 - R2: 0.9213 - mae: 0.0185 - val_loss: 7.5669e-04 - val_R2: 0.9063 - val_mae: 0.0198 - lr: 2.5696e-06 - 9s/epoch - 214ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3789e-04 - R2: 0.9213 - mae: 0.0185 - val_loss: 7.5743e-04 - val_R2: 0.9062 - val_mae: 0.0198 - lr: 2.5696e-06 - 8s/epoch - 206ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3672e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.5915e-04 - val_R2: 0.9060 - val_mae: 0.0199 - lr: 2.5696e-06 - 8s/epoch - 206ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3672e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.6043e-04 - val_R2: 0.9058 - val_mae: 0.0198 - lr: 2.5696e-06 - 8s/epoch - 205ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3640e-04 - R2: 0.9216 - mae: 0.0185 - val_loss: 7.5730e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-06 - 9s/epoch - 217ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3623e-04 - R2: 0.9215 - mae: 0.0184 - val_loss: 7.5731e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-06 - 9s/epoch - 209ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3647e-04 - R2: 0.9216 - mae: 0.0185 - val_loss: 7.5766e-04 - val_R2: 0.9062 - val_mae: 0.0198 - lr: 2.5696e-06 - 9s/epoch - 208ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3601e-04 - R2: 0.9216 - mae: 0.0185 - val_loss: 7.5741e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-06 - 9s/epoch - 212ms/step\n",
      "lr changed to 2.569604021118721e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3555e-04 - R2: 0.9217 - mae: 0.0184 - val_loss: 7.5778e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 206ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3598e-04 - R2: 0.9215 - mae: 0.0184 - val_loss: 7.5781e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-07 - 9s/epoch - 211ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3712e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.5835e-04 - val_R2: 0.9061 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 202ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3654e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.6133e-04 - val_R2: 0.9057 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 199ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3548e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5790e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 203ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3608e-04 - R2: 0.9214 - mae: 0.0184 - val_loss: 7.5858e-04 - val_R2: 0.9061 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 200ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3487e-04 - R2: 0.9217 - mae: 0.0184 - val_loss: 7.5743e-04 - val_R2: 0.9062 - val_mae: 0.0198 - lr: 2.5696e-07 - 9s/epoch - 209ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3585e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5699e-04 - val_R2: 0.9063 - val_mae: 0.0198 - lr: 2.5696e-07 - 9s/epoch - 213ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3627e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.6178e-04 - val_R2: 0.9057 - val_mae: 0.0200 - lr: 2.5696e-07 - 9s/epoch - 211ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3580e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5702e-04 - val_R2: 0.9062 - val_mae: 0.0198 - lr: 2.5696e-07 - 8s/epoch - 202ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3508e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5716e-04 - val_R2: 0.9062 - val_mae: 0.0198 - lr: 2.5696e-07 - 8s/epoch - 201ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3654e-04 - R2: 0.9214 - mae: 0.0185 - val_loss: 7.6179e-04 - val_R2: 0.9057 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 202ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3559e-04 - R2: 0.9215 - mae: 0.0184 - val_loss: 7.6722e-04 - val_R2: 0.9050 - val_mae: 0.0201 - lr: 2.5696e-07 - 8s/epoch - 202ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3605e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.6264e-04 - val_R2: 0.9056 - val_mae: 0.0200 - lr: 2.5696e-07 - 8s/epoch - 200ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3579e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5677e-04 - val_R2: 0.9063 - val_mae: 0.0198 - lr: 2.5696e-07 - 9s/epoch - 211ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3500e-04 - R2: 0.9217 - mae: 0.0184 - val_loss: 7.5776e-04 - val_R2: 0.9062 - val_mae: 0.0198 - lr: 2.5696e-07 - 8s/epoch - 207ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3590e-04 - R2: 0.9216 - mae: 0.0185 - val_loss: 7.6095e-04 - val_R2: 0.9058 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 203ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3541e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5792e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 197ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3562e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.6115e-04 - val_R2: 0.9058 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 203ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3593e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5820e-04 - val_R2: 0.9061 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 199ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3621e-04 - R2: 0.9216 - mae: 0.0185 - val_loss: 7.6019e-04 - val_R2: 0.9059 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 204ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3509e-04 - R2: 0.9217 - mae: 0.0184 - val_loss: 7.5712e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-07 - 9s/epoch - 208ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3563e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.6010e-04 - val_R2: 0.9059 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 205ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3601e-04 - R2: 0.9214 - mae: 0.0185 - val_loss: 7.6537e-04 - val_R2: 0.9053 - val_mae: 0.0201 - lr: 2.5696e-07 - 8s/epoch - 199ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3649e-04 - R2: 0.9212 - mae: 0.0185 - val_loss: 8.6265e-04 - val_R2: 0.8934 - val_mae: 0.0217 - lr: 2.5696e-07 - 8s/epoch - 200ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3558e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5738e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-07 - 8s/epoch - 202ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3498e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5669e-04 - val_R2: 0.9063 - val_mae: 0.0198 - lr: 2.5696e-07 - 8s/epoch - 201ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3571e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5802e-04 - val_R2: 0.9061 - val_mae: 0.0199 - lr: 2.5696e-07 - 9s/epoch - 214ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3547e-04 - R2: 0.9217 - mae: 0.0184 - val_loss: 7.5870e-04 - val_R2: 0.9061 - val_mae: 0.0199 - lr: 2.5696e-07 - 9s/epoch - 214ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3601e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.5799e-04 - val_R2: 0.9061 - val_mae: 0.0198 - lr: 2.5696e-07 - 8s/epoch - 207ms/step\n",
      "lr changed to 2.5696039074318833e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3670e-04 - R2: 0.9210 - mae: 0.0185 - val_loss: 9.1712e-04 - val_R2: 0.8868 - val_mae: 0.0225 - lr: 2.5696e-08 - 8s/epoch - 204ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3516e-04 - R2: 0.9217 - mae: 0.0184 - val_loss: 7.5772e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-08 - 8s/epoch - 200ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3496e-04 - R2: 0.9218 - mae: 0.0184 - val_loss: 7.5738e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-08 - 9s/epoch - 208ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3569e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5800e-04 - val_R2: 0.9061 - val_mae: 0.0198 - lr: 2.5696e-08 - 9s/epoch - 208ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3505e-04 - R2: 0.9217 - mae: 0.0184 - val_loss: 7.5691e-04 - val_R2: 0.9063 - val_mae: 0.0198 - lr: 2.5696e-08 - 9s/epoch - 210ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3566e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5774e-04 - val_R2: 0.9062 - val_mae: 0.0198 - lr: 2.5696e-08 - 8s/epoch - 204ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3570e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5816e-04 - val_R2: 0.9061 - val_mae: 0.0199 - lr: 2.5696e-08 - 8s/epoch - 204ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3582e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5931e-04 - val_R2: 0.9060 - val_mae: 0.0199 - lr: 2.5696e-08 - 9s/epoch - 211ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00076\n",
      "41/41 - 6s - loss: 6.3508e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.6856e-04 - val_R2: 0.9049 - val_mae: 0.0201 - lr: 2.5696e-08 - 6s/epoch - 143ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00076\n",
      "41/41 - 7s - loss: 6.3605e-04 - R2: 0.9215 - mae: 0.0185 - val_loss: 7.5723e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-08 - 7s/epoch - 181ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3548e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5817e-04 - val_R2: 0.9061 - val_mae: 0.0199 - lr: 2.5696e-08 - 8s/epoch - 192ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00076\n",
      "41/41 - 9s - loss: 6.3580e-04 - R2: 0.9216 - mae: 0.0184 - val_loss: 7.5734e-04 - val_R2: 0.9062 - val_mae: 0.0199 - lr: 2.5696e-08 - 9s/epoch - 220ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00076\n",
      "41/41 - 8s - loss: 6.3566e-04 - R2: 0.9214 - mae: 0.0184 - val_loss: 7.5946e-04 - val_R2: 0.9060 - val_mae: 0.0199 - lr: 2.5696e-08 - 8s/epoch - 204ms/step\n",
      "Epoch 73: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f884bbe550>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2012\n",
      "{'units_choice': 10, 'kernel_size': 5, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0025696038852286752}\n",
      "2654/2654 [==============================] - 30s 11ms/step - loss: 7.5580e-04 - R2: 0.9019 - mae: 0.0199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0007557958015240729, 0.9018898606300354, 0.01985171064734459]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (647136, 18, 1)\n",
      "X_validate shape: (194140, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2013\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 09m 57s]\n",
      "val_R2: 0.819561779499054\n",
      "\n",
      "Best val_R2 So Far: 0.9089248180389404\n",
      "Total elapsed time: 05h 03m 07s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 12s - loss: 5.5070e-04 - R2: 0.9290 - mae: 0.0172 - val_loss: 7.0823e-04 - val_R2: 0.9089 - val_mae: 0.0194 - lr: 8.6725e-07 - 12s/epoch - 312ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 12s - loss: 5.5041e-04 - R2: 0.9290 - mae: 0.0172 - val_loss: 7.0776e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 288ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 12s - loss: 5.5017e-04 - R2: 0.9290 - mae: 0.0172 - val_loss: 7.0760e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 294ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.5056e-04 - R2: 0.9289 - mae: 0.0172 - val_loss: 7.0791e-04 - val_R2: 0.9089 - val_mae: 0.0194 - lr: 8.6725e-07 - 11s/epoch - 282ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.5007e-04 - R2: 0.9290 - mae: 0.0172 - val_loss: 7.0790e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 277ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 11s - loss: 5.4977e-04 - R2: 0.9291 - mae: 0.0172 - val_loss: 7.0758e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 278ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.5028e-04 - R2: 0.9290 - mae: 0.0172 - val_loss: 7.0807e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 283ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00071\n",
      "40/40 - 12s - loss: 5.4994e-04 - R2: 0.9290 - mae: 0.0172 - val_loss: 7.0780e-04 - val_R2: 0.9089 - val_mae: 0.0194 - lr: 8.6725e-07 - 12s/epoch - 289ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.5003e-04 - R2: 0.9290 - mae: 0.0171 - val_loss: 7.0770e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 280ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.5002e-04 - R2: 0.9291 - mae: 0.0172 - val_loss: 7.0764e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 278ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4986e-04 - R2: 0.9291 - mae: 0.0172 - val_loss: 7.0768e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 269ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4976e-04 - R2: 0.9290 - mae: 0.0172 - val_loss: 7.0776e-04 - val_R2: 0.9089 - val_mae: 0.0194 - lr: 8.6725e-07 - 11s/epoch - 283ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00071\n",
      "40/40 - 12s - loss: 5.4959e-04 - R2: 0.9291 - mae: 0.0172 - val_loss: 7.0763e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 290ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00071\n",
      "40/40 - 12s - loss: 5.4975e-04 - R2: 0.9291 - mae: 0.0172 - val_loss: 7.0764e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 296ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4957e-04 - R2: 0.9291 - mae: 0.0171 - val_loss: 7.0773e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 278ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 12s - loss: 5.4972e-04 - R2: 0.9291 - mae: 0.0172 - val_loss: 7.0747e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 292ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4981e-04 - R2: 0.9290 - mae: 0.0172 - val_loss: 7.0763e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 284ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4990e-04 - R2: 0.9290 - mae: 0.0172 - val_loss: 7.0770e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 285ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 12s - loss: 5.4969e-04 - R2: 0.9291 - mae: 0.0172 - val_loss: 7.0742e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 294ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00071\n",
      "40/40 - 12s - loss: 5.4966e-04 - R2: 0.9291 - mae: 0.0171 - val_loss: 7.0758e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 288ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00071\n",
      "40/40 - 12s - loss: 5.4948e-04 - R2: 0.9290 - mae: 0.0171 - val_loss: 7.0749e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 295ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4963e-04 - R2: 0.9291 - mae: 0.0171 - val_loss: 7.0767e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 278ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00071\n",
      "40/40 - 12s - loss: 5.4896e-04 - R2: 0.9291 - mae: 0.0171 - val_loss: 7.0762e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 296ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00071\n",
      "40/40 - 12s - loss: 5.4935e-04 - R2: 0.9291 - mae: 0.0171 - val_loss: 7.0749e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 290ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 12s - loss: 5.4907e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0727e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 298ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4904e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0765e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 280ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4925e-04 - R2: 0.9291 - mae: 0.0171 - val_loss: 7.0751e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 281ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4902e-04 - R2: 0.9291 - mae: 0.0171 - val_loss: 7.0769e-04 - val_R2: 0.9089 - val_mae: 0.0194 - lr: 8.6725e-07 - 11s/epoch - 282ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 12s - loss: 5.4946e-04 - R2: 0.9291 - mae: 0.0172 - val_loss: 7.0723e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-07 - 12s/epoch - 292ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4908e-04 - R2: 0.9291 - mae: 0.0171 - val_loss: 7.0751e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-07 - 11s/epoch - 275ms/step\n",
      "lr changed to 8.672502076478851e-08\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 11s - loss: 5.4893e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0714e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 284ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4874e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0738e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 287ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00071\n",
      "40/40 - 12s - loss: 5.4864e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0747e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-08 - 12s/epoch - 291ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4862e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0737e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 278ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4885e-04 - R2: 0.9291 - mae: 0.0171 - val_loss: 7.0780e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 273ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4850e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0768e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 285ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4866e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0731e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 281ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00071\n",
      "40/40 - 12s - loss: 5.4838e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0732e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 12s/epoch - 298ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4865e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0740e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 276ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4832e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0743e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 268ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00071\n",
      "40/40 - 8s - loss: 5.4867e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0749e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-08 - 8s/epoch - 193ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4885e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0755e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-08 - 10s/epoch - 245ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4845e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0750e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 264ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4920e-04 - R2: 0.9291 - mae: 0.0171 - val_loss: 7.0731e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 268ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4846e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0730e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 10s/epoch - 260ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4863e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0727e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 10s/epoch - 262ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4875e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0754e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-08 - 10s/epoch - 260ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4892e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0740e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 10s/epoch - 260ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4868e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0746e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 10s/epoch - 257ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4822e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0722e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 263ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4874e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0714e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 264ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4870e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0738e-04 - val_R2: 0.9090 - val_mae: 0.0194 - lr: 8.6725e-08 - 11s/epoch - 263ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4887e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0769e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-08 - 10s/epoch - 262ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4852e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0747e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 263ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 11s - loss: 5.4866e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0712e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 266ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4862e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0731e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 10s/epoch - 259ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4848e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0743e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 10s/epoch - 262ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4816e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0718e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 10s/epoch - 261ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4832e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0742e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 11s/epoch - 271ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4857e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0746e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-08 - 10s/epoch - 262ms/step\n",
      "lr changed to 8.672502360695944e-09\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4850e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0726e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 259ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4881e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0744e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 258ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4854e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0764e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-09 - 11s/epoch - 264ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4841e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0730e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 262ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4812e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0727e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 261ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4830e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0726e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 11s/epoch - 272ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4837e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0789e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 261ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4850e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0754e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 258ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4821e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0728e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 262ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4844e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0727e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 11s/epoch - 265ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 11s - loss: 5.4869e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0712e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 11s/epoch - 267ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4881e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0753e-04 - val_R2: 0.9089 - val_mae: 0.0194 - lr: 8.6725e-09 - 10s/epoch - 262ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4861e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0749e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-09 - 11s/epoch - 266ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4830e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0722e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 260ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4846e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0735e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 11s/epoch - 266ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4852e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0721e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 260ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4853e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0764e-04 - val_R2: 0.9089 - val_mae: 0.0194 - lr: 8.6725e-09 - 10s/epoch - 262ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4856e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0722e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 11s/epoch - 264ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4836e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0742e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 11s/epoch - 264ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4834e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0715e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 258ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4851e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0715e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 258ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4858e-04 - R2: 0.9291 - mae: 0.0171 - val_loss: 7.0738e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 261ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4873e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0724e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 11s/epoch - 264ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00071\n",
      "40/40 - 11s - loss: 5.4856e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0739e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 11s/epoch - 268ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00071\n",
      "40/40 - 9s - loss: 5.4833e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0728e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 9s/epoch - 215ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00071\n",
      "40/40 - 9s - loss: 5.4849e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0731e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 9s/epoch - 231ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00071\n",
      "40/40 - 9s - loss: 5.4833e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0746e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 9s/epoch - 236ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4846e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0768e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 248ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4820e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0720e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 251ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4839e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0757e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-09 - 10s/epoch - 248ms/step\n",
      "lr changed to 8.672502715967312e-10\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4879e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0731e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 247ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 10s - loss: 5.4826e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0711e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 258ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4820e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0744e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 251ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4840e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0733e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 248ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4844e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0716e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 250ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4861e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0731e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 249ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4845e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0730e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 251ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4864e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0727e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 248ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4814e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0719e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 248ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4802e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0739e-04 - val_R2: 0.9090 - val_mae: 0.0194 - lr: 8.6725e-10 - 10s/epoch - 249ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4856e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0735e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 249ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4850e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0751e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 251ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4821e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0721e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 248ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4846e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0720e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 248ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4826e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0718e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 249ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4825e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0748e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 252ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4851e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0742e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 246ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4840e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0794e-04 - val_R2: 0.9089 - val_mae: 0.0194 - lr: 8.6725e-10 - 10s/epoch - 249ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4837e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0727e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 253ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4837e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0725e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 250ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4842e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0727e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 249ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4846e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0730e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 250ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4864e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0760e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 249ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4808e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0733e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 247ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 10s - loss: 5.4850e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0709e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 258ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4835e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0733e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 248ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4831e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0730e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 249ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4790e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0766e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 249ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4854e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0728e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 249ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4836e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0734e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-10 - 10s/epoch - 248ms/step\n",
      "lr changed to 8.672502715967313e-11\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4857e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0720e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 250ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4839e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0723e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 248ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4849e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0738e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 249ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4886e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0715e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 250ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4847e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0735e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 249ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss improved from 0.00071 to 0.00071, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2013_best.hdf5\n",
      "40/40 - 10s - loss: 5.4843e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0701e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 259ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4865e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0742e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 251ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4803e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0726e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 249ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4848e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0738e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 250ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4828e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0731e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 248ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4862e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0732e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 248ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4865e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0719e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 251ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4839e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0742e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 252ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4876e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0715e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 253ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4847e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0743e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 250ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4854e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0773e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 248ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4883e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0752e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 250ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4825e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0732e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 254ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4856e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0763e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 249ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4845e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0712e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 252ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4844e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0731e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 252ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4860e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0774e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 252ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4831e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0749e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 253ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4847e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0731e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 251ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4842e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0780e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 250ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4875e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0762e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 251ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4853e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0728e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 250ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4851e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0756e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 250ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4853e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0735e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 250ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4905e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0733e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-11 - 10s/epoch - 252ms/step\n",
      "lr changed to 8.672502993523069e-12\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4844e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0753e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 252ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4842e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0737e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 248ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4894e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0723e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 251ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4822e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0739e-04 - val_R2: 0.9090 - val_mae: 0.0194 - lr: 8.6725e-12 - 10s/epoch - 252ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4837e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0760e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 250ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4844e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0751e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 249ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4851e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0735e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 247ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4803e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0716e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 250ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4843e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0729e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 251ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4825e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0720e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 252ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4823e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0722e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 252ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4868e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0721e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 248ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4823e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0726e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 250ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4835e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0752e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 250ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4852e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0711e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 250ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4838e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0705e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 251ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4840e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0711e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 254ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4839e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0742e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 252ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4835e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0725e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 251ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4843e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0753e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 251ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4866e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0778e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 251ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4802e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0709e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 253ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4837e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0715e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 248ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4814e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0733e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 249ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4853e-04 - R2: 0.9292 - mae: 0.0171 - val_loss: 7.0748e-04 - val_R2: 0.9089 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 251ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00071\n",
      "40/40 - 10s - loss: 5.4829e-04 - R2: 0.9293 - mae: 0.0171 - val_loss: 7.0729e-04 - val_R2: 0.9090 - val_mae: 0.0193 - lr: 8.6725e-12 - 10s/epoch - 250ms/step\n",
      "Epoch 176: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8844bd550>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2013\n",
      "{'units_choice': 9, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0008672502254279293}\n",
      "2601/2601 [==============================] - 26s 10ms/step - loss: 7.1029e-04 - R2: 0.9017 - mae: 0.0193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0007102890522219241, 0.901692807674408, 0.019311318174004555]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (603515, 18, 1)\n",
      "X_validate shape: (181055, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2014\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 13m 19s]\n",
      "val_R2: 0.8121931552886963\n",
      "\n",
      "Best val_R2 So Far: 0.9153472781181335\n",
      "Total elapsed time: 03h 26m 35s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00070, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2014_best.hdf5\n",
      "37/37 - 8s - loss: 6.2181e-04 - R2: 0.9251 - mae: 0.0182 - val_loss: 7.0355e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-06 - 8s/epoch - 223ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2069e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0464e-04 - val_R2: 0.9151 - val_mae: 0.0194 - lr: 1.8756e-06 - 7s/epoch - 180ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2173e-04 - R2: 0.9251 - mae: 0.0182 - val_loss: 7.0499e-04 - val_R2: 0.9151 - val_mae: 0.0194 - lr: 1.8756e-06 - 7s/epoch - 178ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2209e-04 - R2: 0.9250 - mae: 0.0182 - val_loss: 7.1129e-04 - val_R2: 0.9143 - val_mae: 0.0195 - lr: 1.8756e-06 - 7s/epoch - 182ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00070 to 0.00070, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2014_best.hdf5\n",
      "37/37 - 7s - loss: 6.2329e-04 - R2: 0.9249 - mae: 0.0183 - val_loss: 7.0201e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 189ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2139e-04 - R2: 0.9251 - mae: 0.0182 - val_loss: 7.0772e-04 - val_R2: 0.9147 - val_mae: 0.0194 - lr: 1.8756e-06 - 7s/epoch - 181ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2180e-04 - R2: 0.9251 - mae: 0.0182 - val_loss: 7.0795e-04 - val_R2: 0.9147 - val_mae: 0.0194 - lr: 1.8756e-06 - 7s/epoch - 182ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss improved from 0.00070 to 0.00070, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2014_best.hdf5\n",
      "37/37 - 7s - loss: 6.2066e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0141e-04 - val_R2: 0.9155 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 187ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2054e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0814e-04 - val_R2: 0.9147 - val_mae: 0.0195 - lr: 1.8756e-06 - 7s/epoch - 177ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2089e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0792e-04 - val_R2: 0.9147 - val_mae: 0.0194 - lr: 1.8756e-06 - 7s/epoch - 178ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2331e-04 - R2: 0.9249 - mae: 0.0183 - val_loss: 7.5134e-04 - val_R2: 0.9095 - val_mae: 0.0203 - lr: 1.8756e-06 - 7s/epoch - 180ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2112e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0980e-04 - val_R2: 0.9145 - val_mae: 0.0195 - lr: 1.8756e-06 - 7s/epoch - 180ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss improved from 0.00070 to 0.00070, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2014_best.hdf5\n",
      "37/37 - 7s - loss: 6.2052e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0043e-04 - val_R2: 0.9156 - val_mae: 0.0192 - lr: 1.8756e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2049e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0151e-04 - val_R2: 0.9155 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 178ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1982e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0203e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 179ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2125e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0313e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 177ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2154e-04 - R2: 0.9251 - mae: 0.0182 - val_loss: 7.0499e-04 - val_R2: 0.9151 - val_mae: 0.0194 - lr: 1.8756e-06 - 7s/epoch - 181ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2077e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0290e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 182ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2176e-04 - R2: 0.9251 - mae: 0.0182 - val_loss: 7.0744e-04 - val_R2: 0.9148 - val_mae: 0.0194 - lr: 1.8756e-06 - 7s/epoch - 178ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1983e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0214e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 181ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2095e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.1338e-04 - val_R2: 0.9141 - val_mae: 0.0196 - lr: 1.8756e-06 - 7s/epoch - 177ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2024e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0177e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 180ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2138e-04 - R2: 0.9251 - mae: 0.0182 - val_loss: 7.0225e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 182ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2220e-04 - R2: 0.9250 - mae: 0.0182 - val_loss: 7.0067e-04 - val_R2: 0.9156 - val_mae: 0.0192 - lr: 1.8756e-06 - 7s/epoch - 180ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2082e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0252e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 180ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2037e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0642e-04 - val_R2: 0.9149 - val_mae: 0.0194 - lr: 1.8756e-06 - 7s/epoch - 179ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1993e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0414e-04 - val_R2: 0.9151 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 178ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1937e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0060e-04 - val_R2: 0.9156 - val_mae: 0.0192 - lr: 1.8756e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss improved from 0.00070 to 0.00070, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2014_best.hdf5\n",
      "37/37 - 7s - loss: 6.1889e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0026e-04 - val_R2: 0.9156 - val_mae: 0.0192 - lr: 1.8756e-06 - 7s/epoch - 188ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2092e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0403e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-06 - 7s/epoch - 179ms/step\n",
      "lr changed to 1.8756181816570463e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2152e-04 - R2: 0.9251 - mae: 0.0182 - val_loss: 7.0378e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-07 - 7s/epoch - 179ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1861e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0380e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-07 - 7s/epoch - 179ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1973e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0064e-04 - val_R2: 0.9156 - val_mae: 0.0192 - lr: 1.8756e-07 - 7s/epoch - 178ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2026e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0293e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-07 - 7s/epoch - 180ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2003e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0509e-04 - val_R2: 0.9151 - val_mae: 0.0194 - lr: 1.8756e-07 - 7s/epoch - 179ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1803e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0490e-04 - val_R2: 0.9151 - val_mae: 0.0194 - lr: 1.8756e-07 - 7s/epoch - 180ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1905e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.1075e-04 - val_R2: 0.9144 - val_mae: 0.0195 - lr: 1.8756e-07 - 7s/epoch - 178ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2001e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0239e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-07 - 7s/epoch - 181ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2066e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0091e-04 - val_R2: 0.9155 - val_mae: 0.0192 - lr: 1.8756e-07 - 7s/epoch - 180ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2024e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0077e-04 - val_R2: 0.9156 - val_mae: 0.0193 - lr: 1.8756e-07 - 7s/epoch - 180ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1963e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0114e-04 - val_R2: 0.9155 - val_mae: 0.0192 - lr: 1.8756e-07 - 7s/epoch - 179ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1947e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0437e-04 - val_R2: 0.9151 - val_mae: 0.0194 - lr: 1.8756e-07 - 7s/epoch - 177ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss improved from 0.00070 to 0.00070, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2014_best.hdf5\n",
      "37/37 - 7s - loss: 6.1920e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 6.9982e-04 - val_R2: 0.9156 - val_mae: 0.0192 - lr: 1.8756e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2058e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0841e-04 - val_R2: 0.9147 - val_mae: 0.0194 - lr: 1.8756e-07 - 7s/epoch - 178ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1951e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0510e-04 - val_R2: 0.9150 - val_mae: 0.0194 - lr: 1.8756e-07 - 7s/epoch - 181ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2147e-04 - R2: 0.9251 - mae: 0.0182 - val_loss: 7.1313e-04 - val_R2: 0.9141 - val_mae: 0.0196 - lr: 1.8756e-07 - 7s/epoch - 181ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1989e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0292e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-07 - 6s/epoch - 175ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1962e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0605e-04 - val_R2: 0.9149 - val_mae: 0.0194 - lr: 1.8756e-07 - 7s/epoch - 180ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2064e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0931e-04 - val_R2: 0.9146 - val_mae: 0.0195 - lr: 1.8756e-07 - 7s/epoch - 177ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2008e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0929e-04 - val_R2: 0.9145 - val_mae: 0.0195 - lr: 1.8756e-07 - 7s/epoch - 184ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1970e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0065e-04 - val_R2: 0.9156 - val_mae: 0.0192 - lr: 1.8756e-07 - 7s/epoch - 176ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2041e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0160e-04 - val_R2: 0.9155 - val_mae: 0.0193 - lr: 1.8756e-07 - 7s/epoch - 178ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.2056e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0192e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-07 - 6s/epoch - 176ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1934e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0056e-04 - val_R2: 0.9156 - val_mae: 0.0193 - lr: 1.8756e-07 - 7s/epoch - 179ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1932e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0290e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-07 - 7s/epoch - 182ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1948e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0360e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-07 - 6s/epoch - 176ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2036e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0193e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-07 - 7s/epoch - 177ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1839e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0376e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-07 - 7s/epoch - 177ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2029e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0321e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1831e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.1110e-04 - val_R2: 0.9143 - val_mae: 0.0195 - lr: 1.8756e-07 - 6s/epoch - 149ms/step\n",
      "lr changed to 1.875618238500465e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1799e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0002e-04 - val_R2: 0.9157 - val_mae: 0.0192 - lr: 1.8756e-08 - 6s/epoch - 153ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1843e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0544e-04 - val_R2: 0.9150 - val_mae: 0.0194 - lr: 1.8756e-08 - 6s/epoch - 153ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1944e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0354e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 154ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss improved from 0.00070 to 0.00070, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2014_best.hdf5\n",
      "37/37 - 6s - loss: 6.1853e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 6.9961e-04 - val_R2: 0.9157 - val_mae: 0.0192 - lr: 1.8756e-08 - 6s/epoch - 160ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1844e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0337e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 153ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1928e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0625e-04 - val_R2: 0.9149 - val_mae: 0.0194 - lr: 1.8756e-08 - 6s/epoch - 153ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1913e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0017e-04 - val_R2: 0.9156 - val_mae: 0.0192 - lr: 1.8756e-08 - 6s/epoch - 152ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1996e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0431e-04 - val_R2: 0.9151 - val_mae: 0.0194 - lr: 1.8756e-08 - 6s/epoch - 152ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1968e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0177e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 154ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1875e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0602e-04 - val_R2: 0.9149 - val_mae: 0.0194 - lr: 1.8756e-08 - 6s/epoch - 154ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1930e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0609e-04 - val_R2: 0.9149 - val_mae: 0.0194 - lr: 1.8756e-08 - 6s/epoch - 152ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1892e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0386e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 154ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00070\n",
      "37/37 - 5s - loss: 6.1941e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0562e-04 - val_R2: 0.9150 - val_mae: 0.0194 - lr: 1.8756e-08 - 5s/epoch - 139ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00070\n",
      "37/37 - 5s - loss: 6.1993e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0094e-04 - val_R2: 0.9155 - val_mae: 0.0192 - lr: 1.8756e-08 - 5s/epoch - 129ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00070\n",
      "37/37 - 5s - loss: 6.1990e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.1709e-04 - val_R2: 0.9136 - val_mae: 0.0196 - lr: 1.8756e-08 - 5s/epoch - 129ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00070\n",
      "37/37 - 5s - loss: 6.1764e-04 - R2: 0.9256 - mae: 0.0182 - val_loss: 7.0071e-04 - val_R2: 0.9156 - val_mae: 0.0193 - lr: 1.8756e-08 - 5s/epoch - 129ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00070\n",
      "37/37 - 5s - loss: 6.2002e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0020e-04 - val_R2: 0.9156 - val_mae: 0.0192 - lr: 1.8756e-08 - 5s/epoch - 129ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00070\n",
      "37/37 - 5s - loss: 6.1939e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0324e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-08 - 5s/epoch - 129ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00070\n",
      "37/37 - 5s - loss: 6.2105e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.1487e-04 - val_R2: 0.9139 - val_mae: 0.0196 - lr: 1.8756e-08 - 5s/epoch - 129ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1892e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0068e-04 - val_R2: 0.9156 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 165ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1902e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0359e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 161ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1901e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0239e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 174ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1869e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0189e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 174ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1914e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0962e-04 - val_R2: 0.9145 - val_mae: 0.0195 - lr: 1.8756e-08 - 6s/epoch - 174ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1921e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0133e-04 - val_R2: 0.9155 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 175ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1872e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0306e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 172ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1904e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0300e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-08 - 7s/epoch - 179ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.2004e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0091e-04 - val_R2: 0.9155 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 173ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1979e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0332e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-08 - 6s/epoch - 174ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2026e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0148e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-08 - 7s/epoch - 178ms/step\n",
      "lr changed to 1.875618238500465e-09\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1921e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0205e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-09 - 6s/epoch - 175ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1798e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0302e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-09 - 7s/epoch - 176ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1873e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0105e-04 - val_R2: 0.9155 - val_mae: 0.0193 - lr: 1.8756e-09 - 6s/epoch - 172ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1841e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0268e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-09 - 7s/epoch - 178ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.2018e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0359e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-09 - 6s/epoch - 173ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1994e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0458e-04 - val_R2: 0.9151 - val_mae: 0.0194 - lr: 1.8756e-09 - 6s/epoch - 172ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1836e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0265e-04 - val_R2: 0.9153 - val_mae: 0.0193 - lr: 1.8756e-09 - 7s/epoch - 177ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1945e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0713e-04 - val_R2: 0.9148 - val_mae: 0.0194 - lr: 1.8756e-09 - 7s/epoch - 180ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1928e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0226e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-09 - 7s/epoch - 176ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.2081e-04 - R2: 0.9252 - mae: 0.0182 - val_loss: 7.0903e-04 - val_R2: 0.9146 - val_mae: 0.0195 - lr: 1.8756e-09 - 6s/epoch - 174ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1835e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 6.9973e-04 - val_R2: 0.9157 - val_mae: 0.0192 - lr: 1.8756e-09 - 6s/epoch - 173ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1934e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0548e-04 - val_R2: 0.9150 - val_mae: 0.0194 - lr: 1.8756e-09 - 7s/epoch - 179ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1903e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0385e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-09 - 6s/epoch - 174ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1805e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 6.9985e-04 - val_R2: 0.9156 - val_mae: 0.0192 - lr: 1.8756e-09 - 6s/epoch - 174ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1913e-04 - R2: 0.9254 - mae: 0.0182 - val_loss: 7.0563e-04 - val_R2: 0.9150 - val_mae: 0.0194 - lr: 1.8756e-09 - 6s/epoch - 175ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1988e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.2510e-04 - val_R2: 0.9127 - val_mae: 0.0198 - lr: 1.8756e-09 - 7s/epoch - 177ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1836e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0425e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-09 - 6s/epoch - 173ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1841e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0138e-04 - val_R2: 0.9155 - val_mae: 0.0193 - lr: 1.8756e-09 - 7s/epoch - 181ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1864e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0181e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-09 - 6s/epoch - 172ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1845e-04 - R2: 0.9255 - mae: 0.0182 - val_loss: 7.0244e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-09 - 6s/epoch - 174ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00070\n",
      "37/37 - 6s - loss: 6.1778e-04 - R2: 0.9256 - mae: 0.0182 - val_loss: 7.0029e-04 - val_R2: 0.9156 - val_mae: 0.0192 - lr: 1.8756e-09 - 6s/epoch - 174ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1988e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0202e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-09 - 7s/epoch - 178ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.2044e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0384e-04 - val_R2: 0.9152 - val_mae: 0.0193 - lr: 1.8756e-09 - 7s/epoch - 182ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00070\n",
      "37/37 - 7s - loss: 6.1991e-04 - R2: 0.9253 - mae: 0.0182 - val_loss: 7.0185e-04 - val_R2: 0.9154 - val_mae: 0.0193 - lr: 1.8756e-09 - 7s/epoch - 177ms/step\n",
      "Epoch 114: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f88570eac0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2014\n",
      "{'units_choice': 7, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0018756180813858188}\n",
      "2425/2425 [==============================] - 24s 10ms/step - loss: 6.9446e-04 - R2: 0.9096 - mae: 0.0193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006944561027921736, 0.9096441864967346, 0.019325878471136093]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (606046, 18, 1)\n",
      "X_validate shape: (181813, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2015\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 17m 35s]\n",
      "val_R2: 0.6960456371307373\n",
      "\n",
      "Best val_R2 So Far: 0.904409646987915\n",
      "Total elapsed time: 04h 15m 07s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2015_best.hdf5\n",
      "37/37 - 8s - loss: 5.9551e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6073e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 8s/epoch - 221ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2015_best.hdf5\n",
      "37/37 - 7s - loss: 5.9556e-04 - R2: 0.9263 - mae: 0.0180 - val_loss: 7.6062e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 7s/epoch - 181ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9567e-04 - R2: 0.9263 - mae: 0.0180 - val_loss: 7.6079e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 158ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9551e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6099e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 7s/epoch - 179ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9533e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6078e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 165ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9521e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6077e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 159ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9493e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6080e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 7s/epoch - 184ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9595e-04 - R2: 0.9263 - mae: 0.0180 - val_loss: 7.6068e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 155ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2015_best.hdf5\n",
      "37/37 - 7s - loss: 5.9602e-04 - R2: 0.9263 - mae: 0.0180 - val_loss: 7.6054e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 7s/epoch - 184ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2015_best.hdf5\n",
      "37/37 - 7s - loss: 5.9629e-04 - R2: 0.9263 - mae: 0.0180 - val_loss: 7.6049e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 7s/epoch - 187ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9569e-04 - R2: 0.9263 - mae: 0.0180 - val_loss: 7.6093e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 168ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2015_best.hdf5\n",
      "37/37 - 6s - loss: 5.9568e-04 - R2: 0.9263 - mae: 0.0180 - val_loss: 7.6040e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 169ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9598e-04 - R2: 0.9263 - mae: 0.0180 - val_loss: 7.6044e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 172ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9549e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6056e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 168ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9519e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6056e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 158ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9537e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6048e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 7s/epoch - 180ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9607e-04 - R2: 0.9263 - mae: 0.0180 - val_loss: 7.6072e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 164ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2015_best.hdf5\n",
      "37/37 - 6s - loss: 5.9527e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6029e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 170ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9514e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6057e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 7s/epoch - 179ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2015_best.hdf5\n",
      "37/37 - 6s - loss: 5.9493e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6024e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 170ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9518e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6030e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 160ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9539e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6049e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 7s/epoch - 178ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9521e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6039e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 164ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9475e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6039e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 160ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9548e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6036e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9517e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6031e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 159ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9448e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6024e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 172ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9520e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6118e-04 - val_R2: 0.9043 - val_mae: 0.0202 - lr: 6.3466e-07 - 7s/epoch - 181ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9501e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6037e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-07 - 6s/epoch - 165ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2015_best.hdf5\n",
      "37/37 - 7s - loss: 5.9480e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6000e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-07 - 7s/epoch - 180ms/step\n",
      "lr changed to 6.346630243569962e-08\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9418e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6003e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 6s/epoch - 174ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9476e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6027e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 6s/epoch - 169ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9465e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6030e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 6s/epoch - 161ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9486e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6075e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 178ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9452e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6025e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 6s/epoch - 165ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9482e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6034e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 6s/epoch - 159ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9437e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6033e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 181ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2015_best.hdf5\n",
      "37/37 - 7s - loss: 5.9450e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5996e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 185ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9503e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6039e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 5s/epoch - 136ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00076\n",
      "37/37 - 4s - loss: 5.9470e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6103e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 4s/epoch - 110ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9434e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5998e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 176ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9420e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6019e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 6s/epoch - 150ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9471e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6008e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 177ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9457e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6006e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 187ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9435e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6022e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 189ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9438e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5999e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 180ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9427e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6038e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 6s/epoch - 172ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9441e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6014e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 6s/epoch - 175ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9474e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6005e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 176ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9405e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6043e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 188ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9422e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6037e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 188ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9394e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6060e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 177ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9431e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6000e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 6s/epoch - 169ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9455e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5999e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 178ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9427e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6024e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 178ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9371e-04 - R2: 0.9266 - mae: 0.0179 - val_loss: 7.5998e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 191ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9394e-04 - R2: 0.9266 - mae: 0.0180 - val_loss: 7.6012e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 187ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9442e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6008e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 177ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9418e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6011e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 193ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9416e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6012e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-08 - 7s/epoch - 178ms/step\n",
      "lr changed to 6.346630243569962e-09\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9451e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5999e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 190ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9407e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6035e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 198ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9456e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6019e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 176ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9391e-04 - R2: 0.9266 - mae: 0.0180 - val_loss: 7.6022e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 176ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9457e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5999e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 185ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9431e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6029e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 191ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9446e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6010e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 186ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9486e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6046e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 181ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9428e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6065e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-09 - 6s/epoch - 173ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9432e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6052e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-09 - 6s/epoch - 175ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2015_best.hdf5\n",
      "37/37 - 7s - loss: 5.9410e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5992e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 184ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9433e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6005e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9433e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6068e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 194ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9474e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.5995e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 187ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9455e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6009e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 179ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9489e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6006e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 201ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9474e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6046e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-09 - 6s/epoch - 174ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9413e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6043e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 177ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9432e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5995e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 179ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9425e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6104e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 178ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9484e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6010e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 192ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9458e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6038e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 192ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9455e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6026e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 189ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss improved from 0.00076 to 0.00076, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2015_best.hdf5\n",
      "37/37 - 7s - loss: 5.9476e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.5984e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9466e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5987e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 177ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9479e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6026e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-09 - 6s/epoch - 174ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9444e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6017e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 6s/epoch - 176ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9488e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6020e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9461e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6006e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 192ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9436e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6008e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-09 - 7s/epoch - 187ms/step\n",
      "lr changed to 6.346630332387804e-10\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9451e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6027e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-10 - 6s/epoch - 174ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9471e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5997e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 6s/epoch - 175ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9411e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6059e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-10 - 7s/epoch - 181ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9435e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6002e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 7s/epoch - 176ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9410e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6050e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-10 - 7s/epoch - 192ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9427e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6025e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-10 - 7s/epoch - 190ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9501e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6030e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-10 - 7s/epoch - 190ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00076\n",
      "37/37 - 7s - loss: 5.9400e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6006e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 7s/epoch - 186ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9498e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6065e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 122ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9434e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6013e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 122ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9454e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6007e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 136ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9481e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.6086e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 147ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00076\n",
      "37/37 - 6s - loss: 5.9392e-04 - R2: 0.9266 - mae: 0.0180 - val_loss: 7.6080e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-10 - 6s/epoch - 149ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9438e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5994e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 148ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9420e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6009e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 147ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9434e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6014e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 147ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9506e-04 - R2: 0.9264 - mae: 0.0180 - val_loss: 7.5994e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 147ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9444e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5990e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 147ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9449e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6002e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 147ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9417e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6012e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 146ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9456e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6016e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 146ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9411e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6010e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 146ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9408e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6054e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 147ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9419e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5998e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 147ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9398e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5988e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 147ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9445e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6021e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 146ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9426e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5992e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 146ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9434e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6004e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 147ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9425e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6004e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 146ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9439e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6019e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-10 - 5s/epoch - 148ms/step\n",
      "lr changed to 6.346630443410106e-11\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9455e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6005e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 147ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9476e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6052e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 147ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9463e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6033e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 147ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9401e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6056e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 146ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9432e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6012e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 146ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9464e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6069e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 144ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9423e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.5994e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 145ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9453e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6053e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 148ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9381e-04 - R2: 0.9266 - mae: 0.0180 - val_loss: 7.6042e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 147ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9393e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6016e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 146ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9399e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6019e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 148ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9472e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6084e-04 - val_R2: 0.9044 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 146ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9403e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6011e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 147ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00076\n",
      "37/37 - 5s - loss: 5.9436e-04 - R2: 0.9265 - mae: 0.0180 - val_loss: 7.6024e-04 - val_R2: 0.9045 - val_mae: 0.0202 - lr: 6.3466e-11 - 5s/epoch - 148ms/step\n",
      "Epoch 134: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8856b7a90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2015\n",
      "{'units_choice': 6, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0006346630548574778}\n",
      "2436/2436 [==============================] - 21s 8ms/step - loss: 7.6253e-04 - R2: -inf - mae: 0.0202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0007625287398695946, -inf, 0.020168164744973183]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (636232, 18, 1)\n",
      "X_validate shape: (190870, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2016\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 03m 13s]\n",
      "val_R2: 0.821239173412323\n",
      "\n",
      "Best val_R2 So Far: 0.924795925617218\n",
      "Total elapsed time: 03h 42m 35s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00064, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2016_best.hdf5\n",
      "39/39 - 6s - loss: 4.9229e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4468e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 6s/epoch - 148ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 0.00064 to 0.00064, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2016_best.hdf5\n",
      "39/39 - 4s - loss: 4.9214e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4462e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 95ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00064 to 0.00064, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2016_best.hdf5\n",
      "39/39 - 4s - loss: 4.9208e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4455e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 114ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss improved from 0.00064 to 0.00064, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2016_best.hdf5\n",
      "39/39 - 4s - loss: 4.9249e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4425e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 109ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9207e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4453e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 87ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9197e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4475e-04 - val_R2: 0.9247 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 111ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9208e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4426e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 87ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9197e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4464e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 105ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9213e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4463e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 88ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9207e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4459e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 106ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9177e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4449e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 86ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9136e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4493e-04 - val_R2: 0.9247 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 102ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9216e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4426e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 85ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9175e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4483e-04 - val_R2: 0.9247 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 108ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss improved from 0.00064 to 0.00064, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2016_best.hdf5\n",
      "39/39 - 3s - loss: 4.9181e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4416e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 88ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00064\n",
      "39/39 - 2s - loss: 4.9140e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4461e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 2s/epoch - 61ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00064\n",
      "39/39 - 2s - loss: 4.9163e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4460e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 2s/epoch - 60ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9171e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4436e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 75ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9146e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4430e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 92ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9147e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4428e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 77ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9172e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4442e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 98ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9177e-04 - R2: 0.9427 - mae: 0.0162 - val_loss: 6.4438e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 89ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9160e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4450e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 86ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss improved from 0.00064 to 0.00064, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2016_best.hdf5\n",
      "39/39 - 4s - loss: 4.9161e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4412e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 104ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9120e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4468e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 90ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9117e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4465e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 91ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9128e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4427e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 95ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9152e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4432e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 87ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9125e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4443e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 4s/epoch - 99ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9106e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4417e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-06 - 3s/epoch - 87ms/step\n",
      "lr changed to 3.060879407712491e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9054e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4470e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 91ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9077e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4472e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 100ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9105e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4446e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 85ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9107e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4429e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 96ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9099e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4449e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 90ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9058e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4468e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 87ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9052e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4419e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 99ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9078e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4417e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 89ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9056e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4453e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 92ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9082e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4426e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 95ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9098e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4437e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 83ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss improved from 0.00064 to 0.00064, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2016_best.hdf5\n",
      "39/39 - 4s - loss: 4.9073e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4403e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 104ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9079e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4404e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 87ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9107e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4437e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 89ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9086e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4458e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 96ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9069e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4411e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 88ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9073e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4416e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 98ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss improved from 0.00064 to 0.00064, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2016_best.hdf5\n",
      "39/39 - 4s - loss: 4.9057e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4400e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 95ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss improved from 0.00064 to 0.00064, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2016_best.hdf5\n",
      "39/39 - 4s - loss: 4.9050e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4399e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 91ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9058e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4479e-04 - val_R2: 0.9247 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 98ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9046e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4417e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 89ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9055e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4422e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 88ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss improved from 0.00064 to 0.00064, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2016_best.hdf5\n",
      "39/39 - 4s - loss: 4.9046e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4399e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 99ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9086e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4456e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 95ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9063e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4419e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 91ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9079e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4420e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 94ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9051e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4424e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 87ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9071e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4421e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 4s/epoch - 96ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9060e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4418e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 89ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9069e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4420e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-07 - 3s/epoch - 88ms/step\n",
      "lr changed to 3.060879407712491e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9073e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4450e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 91ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9074e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4465e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 3s/epoch - 89ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9051e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4402e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 100ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9058e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4422e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 3s/epoch - 86ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9058e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4410e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 91ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9042e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4406e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 95ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9061e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4412e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 90ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9079e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4449e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 98ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9050e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4460e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 93ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9069e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4421e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 3s/epoch - 83ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9071e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4416e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 98ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9047e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4447e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 3s/epoch - 89ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9069e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4420e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 100ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9026e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4432e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 95ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9046e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4418e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 3s/epoch - 82ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9047e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4434e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 98ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9082e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4402e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 102ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9075e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4444e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 3s/epoch - 87ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9080e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4478e-04 - val_R2: 0.9247 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 95ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9072e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4418e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 95ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9075e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4438e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 3s/epoch - 87ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9044e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4458e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 100ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9089e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4415e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 92ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9075e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4448e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 3s/epoch - 89ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9046e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4438e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 101ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9059e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4431e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 91ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9059e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4407e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 3s/epoch - 89ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9050e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4439e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 99ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9071e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4454e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 91ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9077e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4418e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-08 - 4s/epoch - 94ms/step\n",
      "lr changed to 3.0608795498210384e-09\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9051e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4420e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 94ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9058e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4453e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 86ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss improved from 0.00064 to 0.00064, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2016_best.hdf5\n",
      "39/39 - 4s - loss: 4.9090e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4391e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 103ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9061e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4422e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 91ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9075e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4441e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 96ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9046e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4423e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 97ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9036e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4396e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 92ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9064e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4455e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 84ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00064\n",
      "39/39 - 2s - loss: 4.9073e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4502e-04 - val_R2: 0.9247 - val_mae: 0.0184 - lr: 3.0609e-09 - 2s/epoch - 61ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00064\n",
      "39/39 - 2s - loss: 4.9085e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4403e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 2s/epoch - 60ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00064\n",
      "39/39 - 2s - loss: 4.9056e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4416e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 2s/epoch - 60ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9070e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4420e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 86ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9041e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4401e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 81ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9029e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4410e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 76ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9081e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4432e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 96ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9074e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4415e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 85ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9070e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4422e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 93ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9055e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4437e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 89ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9052e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4406e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 86ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9064e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4396e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 96ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9052e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4421e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 86ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9065e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4416e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 92ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9078e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4424e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 84ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9042e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4407e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 92ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9080e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4455e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 87ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9040e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4418e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 91ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9042e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4423e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 89ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9061e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4424e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 87ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9072e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4444e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 4s/epoch - 96ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9060e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4468e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-09 - 3s/epoch - 85ms/step\n",
      "lr changed to 3.0608795498210386e-10\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9083e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4415e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 4s/epoch - 91ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9102e-04 - R2: 0.9428 - mae: 0.0162 - val_loss: 6.4431e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 84ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9074e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4396e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 4s/epoch - 93ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9074e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4449e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 90ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9067e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4492e-04 - val_R2: 0.9247 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 86ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9070e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4399e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 4s/epoch - 95ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9034e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4398e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 84ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9029e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4432e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 4s/epoch - 96ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9084e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4448e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 84ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9076e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4446e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 4s/epoch - 90ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9088e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4454e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 88ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9060e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4407e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 90ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9065e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4434e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 4s/epoch - 90ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9074e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4394e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 83ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9065e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4411e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 4s/epoch - 98ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9051e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4414e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 88ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9063e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4476e-04 - val_R2: 0.9247 - val_mae: 0.0184 - lr: 3.0609e-10 - 4s/epoch - 96ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9039e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4421e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 88ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9060e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4442e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 90ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9025e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4422e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 4s/epoch - 94ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9060e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4417e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 85ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00064\n",
      "39/39 - 4s - loss: 4.9055e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4443e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 4s/epoch - 95ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00064\n",
      "39/39 - 3s - loss: 4.9051e-04 - R2: 0.9429 - mae: 0.0162 - val_loss: 6.4442e-04 - val_R2: 0.9248 - val_mae: 0.0184 - lr: 3.0609e-10 - 3s/epoch - 86ms/step\n",
      "Epoch 143: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f885df7400>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2016\n",
      "{'units_choice': 1, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0030608790965779946}\n",
      "2557/2557 [==============================] - 24s 9ms/step - loss: 6.2884e-04 - R2: 0.9210 - mae: 0.0182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.000628840527497232, 0.9209580421447754, 0.018243618309497833]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (637490, 18, 1)\n",
      "X_validate shape: (191247, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2017\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 03m 02s]\n",
      "val_R2: -5.680734157562256\n",
      "\n",
      "Best val_R2 So Far: 0.9211273789405823\n",
      "Total elapsed time: 04h 01m 20s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 8s - loss: 5.5133e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8142e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 8s/epoch - 198ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 0.00068 to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 6s - loss: 5.5169e-04 - R2: 0.9360 - mae: 0.0172 - val_loss: 6.8127e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 164ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00068 to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 7s - loss: 5.5130e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8089e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 7s/epoch - 169ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00068\n",
      "39/39 - 7s - loss: 5.5112e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8140e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 7s/epoch - 168ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5144e-04 - R2: 0.9360 - mae: 0.0172 - val_loss: 6.8141e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 161ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5107e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8109e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 161ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5100e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8114e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 158ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5125e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8123e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 162ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5103e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8144e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 161ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5089e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8128e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 159ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss improved from 0.00068 to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 7s - loss: 5.5091e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8089e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 7s/epoch - 170ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5106e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8089e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 161ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5090e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8108e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 163ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5088e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8130e-04 - val_R2: 0.9211 - val_mae: 0.0189 - lr: 1.9037e-06 - 6s/epoch - 165ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss improved from 0.00068 to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 5s - loss: 5.5054e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8074e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-06 - 5s/epoch - 131ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00068\n",
      "39/39 - 5s - loss: 5.5038e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8080e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-06 - 5s/epoch - 120ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00068\n",
      "39/39 - 5s - loss: 5.5066e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8108e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 5s/epoch - 134ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5076e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8093e-04 - val_R2: 0.9211 - val_mae: 0.0189 - lr: 1.9037e-06 - 6s/epoch - 142ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5028e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8084e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 142ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5017e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8091e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 143ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5059e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8090e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 145ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5057e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8123e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 143ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5058e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8083e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 142ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss improved from 0.00068 to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 6s - loss: 5.5021e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8066e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 147ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss improved from 0.00068 to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 6s - loss: 5.5014e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8064e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 150ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5058e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8072e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 143ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5071e-04 - R2: 0.9361 - mae: 0.0172 - val_loss: 6.8083e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 143ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss improved from 0.00068 to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 6s - loss: 5.5050e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8061e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 149ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss improved from 0.00068 to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 6s - loss: 5.5019e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8050e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-06 - 6s/epoch - 150ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5006e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8056e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-06 - 6s/epoch - 144ms/step\n",
      "lr changed to 1.9036600633626223e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4989e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8075e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 144ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4968e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8055e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-07 - 6s/epoch - 142ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4947e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8060e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 144ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4984e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8059e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 144ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4964e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8069e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-07 - 6s/epoch - 144ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4956e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8058e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 144ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss improved from 0.00068 to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 6s - loss: 5.4995e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8049e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 149ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4953e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8078e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 143ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4941e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8066e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-07 - 6s/epoch - 141ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4964e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8050e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 145ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4958e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8063e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 145ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4989e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8069e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 143ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4958e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8069e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-07 - 6s/epoch - 144ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4982e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8058e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-07 - 6s/epoch - 144ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5000e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8058e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 142ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4979e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8098e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 141ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4986e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8067e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 143ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4969e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8083e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 143ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4997e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8070e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-07 - 6s/epoch - 142ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4933e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8072e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 144ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4940e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8059e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-07 - 6s/epoch - 142ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss improved from 0.00068 to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 6s - loss: 5.4980e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8034e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 148ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4964e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8065e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 144ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4943e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8072e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-07 - 6s/epoch - 144ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4984e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8068e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 142ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4964e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8061e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 143ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4947e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8072e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-07 - 6s/epoch - 145ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4966e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8060e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-07 - 6s/epoch - 143ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4970e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8071e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 6s/epoch - 141ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00068\n",
      "39/39 - 4s - loss: 5.4960e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8083e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-07 - 4s/epoch - 110ms/step\n",
      "lr changed to 1.903660091784332e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00068\n",
      "39/39 - 5s - loss: 5.4928e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8075e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 5s/epoch - 122ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00068\n",
      "39/39 - 5s - loss: 5.4942e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8078e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-08 - 5s/epoch - 133ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4952e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8064e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-08 - 6s/epoch - 146ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4956e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8041e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 145ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4936e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8071e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 143ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4977e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8052e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 142ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4939e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8061e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-08 - 6s/epoch - 144ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4931e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8069e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-08 - 6s/epoch - 143ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4952e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8077e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 144ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4978e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8043e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 144ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4954e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8043e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 146ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss improved from 0.00068 to 0.00068, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2017_best.hdf5\n",
      "39/39 - 6s - loss: 5.4938e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8028e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 148ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4963e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8066e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-08 - 6s/epoch - 147ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4937e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8039e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 144ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4929e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8060e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-08 - 6s/epoch - 141ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4939e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8070e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 144ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4950e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8054e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 146ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4971e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8060e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-08 - 6s/epoch - 146ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4966e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8063e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-08 - 6s/epoch - 144ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4987e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8069e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 146ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4947e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8056e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 144ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4932e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8054e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 142ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4943e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8051e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-08 - 6s/epoch - 145ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4961e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8054e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 143ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4957e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8050e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-08 - 6s/epoch - 144ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4949e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8043e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 142ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4976e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8089e-04 - val_R2: 0.9211 - val_mae: 0.0189 - lr: 1.9037e-08 - 6s/epoch - 145ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4952e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8061e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-08 - 6s/epoch - 143ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4958e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8103e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 145ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4941e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8082e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-08 - 6s/epoch - 144ms/step\n",
      "lr changed to 1.9036601628386054e-09\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4943e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8063e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 6s/epoch - 145ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4953e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8045e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 6s/epoch - 146ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4945e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8046e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 6s/epoch - 143ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4931e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8029e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 145ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4935e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8035e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 144ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4970e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8086e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 143ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4944e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8058e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 145ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4979e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8067e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 145ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4951e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8059e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 6s/epoch - 145ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4956e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8068e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 144ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4939e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8055e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 142ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4966e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8043e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 6s/epoch - 144ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4939e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8069e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 6s/epoch - 145ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4943e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8039e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 6s/epoch - 143ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4959e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8052e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 144ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4937e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8045e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 145ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4951e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8069e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 143ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4968e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8030e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 6s/epoch - 145ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4963e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8048e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 144ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4967e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8061e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 6s/epoch - 145ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4960e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8048e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 6s/epoch - 145ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4958e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8071e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 144ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4950e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8054e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 6s/epoch - 144ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4951e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8056e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 145ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00068\n",
      "39/39 - 5s - loss: 5.4975e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8105e-04 - val_R2: 0.9211 - val_mae: 0.0189 - lr: 1.9037e-09 - 5s/epoch - 129ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00068\n",
      "39/39 - 4s - loss: 5.4962e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8059e-04 - val_R2: 0.9212 - val_mae: 0.0189 - lr: 1.9037e-09 - 4s/epoch - 110ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4963e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8068e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 165ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.5001e-04 - R2: 0.9362 - mae: 0.0172 - val_loss: 6.8116e-04 - val_R2: 0.9211 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 164ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4953e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8081e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 6s/epoch - 167ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00068\n",
      "39/39 - 7s - loss: 5.4952e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8047e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-09 - 7s/epoch - 173ms/step\n",
      "lr changed to 1.9036601184296843e-10\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00068\n",
      "39/39 - 6s - loss: 5.4927e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8070e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-10 - 6s/epoch - 165ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00068\n",
      "39/39 - 7s - loss: 5.4934e-04 - R2: 0.9363 - mae: 0.0172 - val_loss: 6.8063e-04 - val_R2: 0.9212 - val_mae: 0.0190 - lr: 1.9037e-10 - 7s/epoch - 171ms/step\n",
      "Epoch 122: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f885f795b0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2017\n",
      "{'units_choice': 6, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0019036600889013378}\n",
      "2562/2562 [==============================] - 24s 10ms/step - loss: 6.8559e-04 - R2: 0.9145 - mae: 0.0191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006855916581116617, 0.9144935011863708, 0.01906181126832962]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (614272, 18, 1)\n",
      "X_validate shape: (184282, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2018\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 15m 06s]\n",
      "val_R2: 0.7567874789237976\n",
      "\n",
      "Best val_R2 So Far: 0.9170046448707581\n",
      "Total elapsed time: 04h 38m 46s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00073, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2018_best.hdf5\n",
      "38/38 - 7s - loss: 5.7402e-04 - R2: 0.9349 - mae: 0.0176 - val_loss: 7.2965e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 7s/epoch - 181ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7448e-04 - R2: 0.9349 - mae: 0.0176 - val_loss: 7.2998e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00073 to 0.00073, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2018_best.hdf5\n",
      "38/38 - 6s - loss: 5.7400e-04 - R2: 0.9349 - mae: 0.0176 - val_loss: 7.2961e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 6s/epoch - 147ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7383e-04 - R2: 0.9350 - mae: 0.0176 - val_loss: 7.2999e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 138ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7268e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2970e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7302e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2973e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss improved from 0.00073 to 0.00073, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2018_best.hdf5\n",
      "38/38 - 5s - loss: 5.7378e-04 - R2: 0.9350 - mae: 0.0176 - val_loss: 7.2950e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 143ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7300e-04 - R2: 0.9350 - mae: 0.0176 - val_loss: 7.2952e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7366e-04 - R2: 0.9350 - mae: 0.0176 - val_loss: 7.2980e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7333e-04 - R2: 0.9350 - mae: 0.0176 - val_loss: 7.3025e-04 - val_R2: 0.9169 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss improved from 0.00073 to 0.00073, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2018_best.hdf5\n",
      "38/38 - 5s - loss: 5.7379e-04 - R2: 0.9350 - mae: 0.0176 - val_loss: 7.2941e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 143ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7361e-04 - R2: 0.9350 - mae: 0.0176 - val_loss: 7.3064e-04 - val_R2: 0.9169 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7375e-04 - R2: 0.9350 - mae: 0.0176 - val_loss: 7.3044e-04 - val_R2: 0.9169 - val_mae: 0.0198 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7268e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.3006e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss improved from 0.00073 to 0.00073, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2018_best.hdf5\n",
      "38/38 - 5s - loss: 5.7379e-04 - R2: 0.9350 - mae: 0.0176 - val_loss: 7.2922e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 144ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7297e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2946e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss improved from 0.00073 to 0.00073, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2018_best.hdf5\n",
      "38/38 - 6s - loss: 5.7280e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2920e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-07 - 6s/epoch - 146ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7380e-04 - R2: 0.9349 - mae: 0.0176 - val_loss: 7.2976e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7250e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2938e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7253e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2930e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7291e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2944e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7225e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2932e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7276e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2930e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss improved from 0.00073 to 0.00073, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2018_best.hdf5\n",
      "38/38 - 6s - loss: 5.7235e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2902e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-07 - 6s/epoch - 145ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7271e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2963e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7151e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2905e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7166e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2939e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7208e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2915e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7199e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.3042e-04 - val_R2: 0.9169 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7220e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2909e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-07 - 5s/epoch - 137ms/step\n",
      "lr changed to 7.968852742124e-08\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7177e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2921e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7236e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2946e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7113e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2977e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7213e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2927e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7183e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2920e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7178e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2925e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss improved from 0.00073 to 0.00073, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2018_best.hdf5\n",
      "38/38 - 5s - loss: 5.7216e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2884e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 143ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7201e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2917e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 138ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7231e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2910e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7174e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2890e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7230e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2935e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7084e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2954e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7271e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2905e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7201e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2995e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7127e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2930e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss improved from 0.00073 to 0.00073, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2018_best.hdf5\n",
      "38/38 - 5s - loss: 5.7276e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2881e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 143ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7089e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2890e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7192e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2892e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7081e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.3027e-04 - val_R2: 0.9169 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7110e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2919e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7208e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2984e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7203e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2884e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7197e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2940e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7252e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.3048e-04 - val_R2: 0.9169 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7256e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2983e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7112e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2914e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7114e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2933e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7260e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2943e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7275e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2940e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7198e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2894e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-08 - 5s/epoch - 137ms/step\n",
      "lr changed to 7.968852600015453e-09\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7196e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2895e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7061e-04 - R2: 0.9354 - mae: 0.0175 - val_loss: 7.2943e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7111e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2928e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7181e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2900e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7160e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2898e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7120e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2901e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7126e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2939e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7082e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2896e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7139e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.3021e-04 - val_R2: 0.9169 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7265e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2924e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7234e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.3020e-04 - val_R2: 0.9169 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7172e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2928e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7262e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2914e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7263e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2924e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss improved from 0.00073 to 0.00073, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2018_best.hdf5\n",
      "38/38 - 5s - loss: 5.7096e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2880e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 143ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7150e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2931e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7145e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2908e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7228e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2907e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7206e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2921e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7191e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2895e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7150e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2920e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7252e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2908e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7230e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2909e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7126e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2927e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7121e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2957e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7109e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2911e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7175e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2953e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7109e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2909e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7114e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2905e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7087e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2896e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-09 - 5s/epoch - 137ms/step\n",
      "lr changed to 7.968852244744085e-10\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7116e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2969e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7078e-04 - R2: 0.9354 - mae: 0.0175 - val_loss: 7.2882e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7146e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2914e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7170e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2948e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7199e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2966e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7093e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2911e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7211e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.3053e-04 - val_R2: 0.9169 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7145e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2949e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7157e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2903e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7127e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2965e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7141e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2920e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7192e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2888e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7262e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2954e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7177e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2935e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7131e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2919e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7212e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2966e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7035e-04 - R2: 0.9354 - mae: 0.0175 - val_loss: 7.2914e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7252e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2923e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7149e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2919e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7143e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2916e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7163e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2969e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7138e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2902e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7053e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2883e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7192e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2897e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7052e-04 - R2: 0.9354 - mae: 0.0175 - val_loss: 7.2935e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7235e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2934e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7100e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2928e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7192e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2938e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7118e-04 - R2: 0.9353 - mae: 0.0175 - val_loss: 7.2910e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7251e-04 - R2: 0.9351 - mae: 0.0175 - val_loss: 7.2953e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-10 - 5s/epoch - 137ms/step\n",
      "lr changed to 7.968852244744085e-11\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7200e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2899e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-11 - 5s/epoch - 137ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7195e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2912e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-11 - 5s/epoch - 137ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7205e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2916e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-11 - 5s/epoch - 137ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7219e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2906e-04 - val_R2: 0.9171 - val_mae: 0.0197 - lr: 7.9689e-11 - 5s/epoch - 137ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00073\n",
      "38/38 - 5s - loss: 5.7135e-04 - R2: 0.9352 - mae: 0.0175 - val_loss: 7.2927e-04 - val_R2: 0.9170 - val_mae: 0.0197 - lr: 7.9689e-11 - 5s/epoch - 137ms/step\n",
      "Epoch 125: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f885ecf1f0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2018\n",
      "{'units_choice': 7, 'kernel_size': 5, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.0007968852418666189}\n",
      "2469/2469 [==============================] - 11s 4ms/step - loss: 7.3439e-04 - R2: 0.9101 - mae: 0.0198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0007343881297856569, 0.9101068377494812, 0.01982777565717697]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (625580, 18, 1)\n",
      "X_validate shape: (187674, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2019\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 14m 55s]\n",
      "val_R2: 0.6352357268333435\n",
      "\n",
      "Best val_R2 So Far: 0.9317988753318787\n",
      "Total elapsed time: 02h 28m 52s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00057, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2019_best.hdf5\n",
      "39/39 - 9s - loss: 4.5610e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6789e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 9s/epoch - 226ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5648e-04 - R2: 0.9455 - mae: 0.0157 - val_loss: 5.6805e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5645e-04 - R2: 0.9452 - mae: 0.0156 - val_loss: 5.6909e-04 - val_R2: 0.9317 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5663e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6852e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5648e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6813e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5639e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6793e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5607e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6805e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5602e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6826e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5605e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6833e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5594e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6805e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss improved from 0.00057 to 0.00057, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2019_best.hdf5\n",
      "39/39 - 7s - loss: 4.5630e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6789e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 192ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5577e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6829e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5636e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6796e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5583e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6850e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5611e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6791e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss improved from 0.00057 to 0.00057, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2019_best.hdf5\n",
      "39/39 - 7s - loss: 4.5563e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6759e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 190ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5586e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6938e-04 - val_R2: 0.9317 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5609e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6864e-04 - val_R2: 0.9317 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5579e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6838e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5578e-04 - R2: 0.9453 - mae: 0.0156 - val_loss: 5.6830e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5595e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6822e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5576e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6811e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5515e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6829e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5540e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6804e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5599e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6803e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5544e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6805e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5570e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6777e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5564e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6761e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5519e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6768e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5540e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6800e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-06 - 7s/epoch - 183ms/step\n",
      "lr changed to 1.9255646748206346e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss improved from 0.00057 to 0.00057, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2019_best.hdf5\n",
      "39/39 - 7s - loss: 4.5537e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6746e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 189ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5484e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6757e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5543e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6804e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5496e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6773e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5507e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6747e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5494e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6805e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5516e-04 - R2: 0.9453 - mae: 0.0156 - val_loss: 5.6788e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5468e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6763e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss improved from 0.00057 to 0.00057, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2019_best.hdf5\n",
      "39/39 - 7s - loss: 4.5465e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6738e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 189ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5468e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6743e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5461e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6787e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5488e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6768e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5535e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6793e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5444e-04 - R2: 0.9458 - mae: 0.0156 - val_loss: 5.6779e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5514e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6782e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5449e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6772e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5473e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6774e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5488e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6842e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5454e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6786e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5458e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6758e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5469e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6762e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5447e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6778e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5471e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6788e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5435e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6759e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5517e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6796e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5513e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6829e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5413e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6767e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5443e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6833e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5485e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6753e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 183ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss improved from 0.00057 to 0.00057, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2019_best.hdf5\n",
      "39/39 - 7s - loss: 4.5492e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6726e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-07 - 7s/epoch - 190ms/step\n",
      "lr changed to 1.9255647032423442e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5476e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6828e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5474e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6806e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5486e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6888e-04 - val_R2: 0.9317 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5428e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6800e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5493e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6818e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5460e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6781e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5487e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6757e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5492e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6757e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5474e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6794e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5445e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6755e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5459e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6845e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5447e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6786e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5509e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6855e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5425e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6752e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5450e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6760e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5428e-04 - R2: 0.9458 - mae: 0.0156 - val_loss: 5.6795e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5474e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6817e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5467e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6770e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5455e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6793e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5480e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6801e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5464e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6762e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5489e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6849e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5492e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6876e-04 - val_R2: 0.9317 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5468e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6831e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5549e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6816e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5449e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6809e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5474e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6753e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5459e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6775e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5486e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6775e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5472e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6814e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-08 - 7s/epoch - 183ms/step\n",
      "lr changed to 1.9255647742966177e-09\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5470e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6788e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5496e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6850e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5460e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6769e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5483e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6821e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5484e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6766e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5468e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6853e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5467e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6768e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5460e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6784e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5461e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6819e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5498e-04 - R2: 0.9454 - mae: 0.0156 - val_loss: 5.6761e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5459e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6780e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5481e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6750e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5482e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6754e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5446e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6736e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5454e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6859e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5434e-04 - R2: 0.9457 - mae: 0.0156 - val_loss: 5.6784e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5493e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6855e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5478e-04 - R2: 0.9453 - mae: 0.0156 - val_loss: 5.6743e-04 - val_R2: 0.9319 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5489e-04 - R2: 0.9455 - mae: 0.0156 - val_loss: 5.6874e-04 - val_R2: 0.9317 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00057\n",
      "39/39 - 7s - loss: 4.5489e-04 - R2: 0.9456 - mae: 0.0156 - val_loss: 5.6795e-04 - val_R2: 0.9318 - val_mae: 0.0173 - lr: 1.9256e-09 - 7s/epoch - 183ms/step\n",
      "Epoch 110: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8871cf5e0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2019\n",
      "{'units_choice': 9, 'kernel_size': 3, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.001925564703335844}\n",
      "2514/2514 [==============================] - 11s 4ms/step - loss: 5.6996e-04 - R2: 0.9263 - mae: 0.0174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0005699647590517998, 0.9263062477111816, 0.017356805503368378]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (709183, 18, 1)\n",
      "X_validate shape: (212755, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "year = 2020\n",
    "data_train = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','train_data_'+str(year)+'.csv'))\n",
    "data_validate = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','validate_data_'+str(year)+'.csv'))\n",
    "data_test = pd.read_csv(os.path.join('D:/SGYL/SM_Downscaling_data/Train/split/','test_data_'+str(year)+'.csv'))\n",
    "\n",
    "X_train = data_train.drop(['SM','Aspect'],axis = 1)\n",
    "y_train = data_train['SM'].copy()   \n",
    "X_validate = data_validate.drop(['SM','Aspect'],axis = 1)\n",
    "y_validate = data_validate['SM'].copy()\n",
    "X_test = data_test.drop(['SM','Aspect'],axis = 1)\n",
    "y_test = data_test['SM'].copy()\n",
    "\n",
    "standarder = StandardScaler()\n",
    "X_train = standarder.fit_transform(X_train)\n",
    "X_validate = standarder.transform(X_validate)\n",
    "X_test = standarder.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_validate shape:',X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 09m 39s]\n",
      "val_R2: 0.8425613641738892\n",
      "\n",
      "Best val_R2 So Far: 0.9292113184928894\n",
      "Total elapsed time: 03h 01m 12s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch,lr):\n",
    "    # 每隔30个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "        return lr * 0.1\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "hypermodel = MyHyperModel()\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective=keras_tuner.Objective('val_R2', direction=\"max\"),\n",
    "            num_initial_points=50,\n",
    "            max_trials=max_trials,\n",
    "            overwrite = True,\n",
    "            directory='D:/SGYL/SM_results_data/Bayesian_Opt/CNN/',\n",
    "            project_name=('CNN_'+str(year)))\n",
    "tuner.search(X_train,y_train,epochs=100,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = [reduce_lr,callback_early_stopping],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00055, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2020_best.hdf5\n",
      "44/44 - 8s - loss: 4.1106e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5166e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 8s/epoch - 182ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 0.00055 to 0.00055, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2020_best.hdf5\n",
      "44/44 - 6s - loss: 4.1126e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5139e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 144ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1157e-04 - R2: 0.9471 - mae: 0.0150 - val_loss: 5.5183e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1093e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5159e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1109e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5157e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1139e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5232e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1115e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5208e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1107e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5232e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss improved from 0.00055 to 0.00055, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2020_best.hdf5\n",
      "44/44 - 6s - loss: 4.1049e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5138e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 145ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1033e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5209e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1063e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5172e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1020e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5239e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1051e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5170e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1022e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5162e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1146e-04 - R2: 0.9471 - mae: 0.0150 - val_loss: 5.5309e-04 - val_R2: 0.9290 - val_mae: 0.0173 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1005e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5203e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1005e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5175e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0968e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5185e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1049e-04 - R2: 0.9471 - mae: 0.0150 - val_loss: 5.5214e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1011e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5161e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1036e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5183e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1026e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5170e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1090e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5169e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1017e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.5236e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1009e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5181e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1035e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5154e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1016e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5147e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0967e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5191e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss improved from 0.00055 to 0.00055, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2020_best.hdf5\n",
      "44/44 - 6s - loss: 4.0930e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5111e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 145ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0949e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5176e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-06 - 6s/epoch - 139ms/step\n",
      "lr changed to 2.9505160910048293e-07\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0901e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5189e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1003e-04 - R2: 0.9472 - mae: 0.0150 - val_loss: 5.6813e-04 - val_R2: 0.9270 - val_mae: 0.0176 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0976e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5169e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0981e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5135e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0930e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5144e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0916e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5176e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0912e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5117e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0919e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5213e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0972e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5194e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0961e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5166e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0923e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5204e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.1029e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5164e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0959e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5198e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0896e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.7771e-04 - val_R2: 0.9258 - val_mae: 0.0179 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0947e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5168e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss improved from 0.00055 to 0.00055, saving model to D:/SGYL/SM_results_data/check_points/CNN\\CNN_2020_best.hdf5\n",
      "44/44 - 6s - loss: 4.0944e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5104e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 145ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0929e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5269e-04 - val_R2: 0.9290 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0926e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5202e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0957e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5166e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0900e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5116e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0980e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5190e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0951e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5134e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0933e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5187e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0935e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5179e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 138ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0824e-04 - R2: 0.9476 - mae: 0.0150 - val_loss: 5.5138e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 138ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0946e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5180e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0962e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5210e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0967e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5181e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0931e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5219e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0948e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5307e-04 - val_R2: 0.9290 - val_mae: 0.0173 - lr: 2.9505e-07 - 6s/epoch - 139ms/step\n",
      "lr changed to 2.950516204691667e-08\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0960e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5236e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0987e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5134e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0913e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5173e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0922e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5181e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0876e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5128e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0946e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5187e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0916e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5158e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0925e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5120e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0959e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5278e-04 - val_R2: 0.9290 - val_mae: 0.0173 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0912e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5230e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0997e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5223e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0904e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5147e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0934e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5154e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0912e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5131e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0868e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5169e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0883e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5169e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0893e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5124e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0929e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5233e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0917e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5158e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0874e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5194e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0956e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5186e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0888e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5119e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0896e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5194e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0892e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5286e-04 - val_R2: 0.9290 - val_mae: 0.0173 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0943e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5711e-04 - val_R2: 0.9285 - val_mae: 0.0174 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0966e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5125e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0883e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5184e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0912e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5150e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 138ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0944e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5174e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0921e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5119e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-08 - 6s/epoch - 139ms/step\n",
      "lr changed to 2.9505162757459402e-09\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0905e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5136e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-09 - 6s/epoch - 139ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0902e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5245e-04 - val_R2: 0.9291 - val_mae: 0.0172 - lr: 2.9505e-09 - 6s/epoch - 139ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0900e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5106e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-09 - 6s/epoch - 139ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0859e-04 - R2: 0.9475 - mae: 0.0150 - val_loss: 5.5163e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-09 - 6s/epoch - 139ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0924e-04 - R2: 0.9473 - mae: 0.0150 - val_loss: 5.5576e-04 - val_R2: 0.9286 - val_mae: 0.0173 - lr: 2.9505e-09 - 6s/epoch - 138ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00055\n",
      "44/44 - 6s - loss: 4.0897e-04 - R2: 0.9474 - mae: 0.0150 - val_loss: 5.5145e-04 - val_R2: 0.9292 - val_mae: 0.0172 - lr: 2.9505e-09 - 6s/epoch - 139ms/step\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f88748cd00>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"CNN_\"+str(year)+\"_best.hdf5\"\n",
    "callback_checkpoints = keras.callbacks.ModelCheckpoint(os.path.join('D:/SGYL/SM_results_data/check_points/CNN/',filepath),monitor='val_loss',save_best_only=True,verbose=1)\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,verbose=1)\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks = [reduce_lr,callback_early_stopping,callback_checkpoints]\n",
    "\n",
    "if training_mode == 'model':\n",
    "    model_best = tuner.get_best_models()[0]\n",
    "else :\n",
    "    model_best = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "model_best.fit(X_train,y_train,epochs=300,batch_size = batch_size,validation_data=(X_validate,y_validate),shuffle = True,callbacks = callbacks,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model for year: 2020\n",
      "{'units_choice': 10, 'kernel_size': 5, 'dropout': False, 'activate_dense1': 'sigmoid', 'lr': 0.002950516092627498}\n",
      "2850/2850 [==============================] - 13s 5ms/step - loss: 5.6503e-04 - R2: 0.9217 - mae: 0.0172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0005650329985655844, 0.9216988682746887, 0.01724882982671261]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = os.path.join('D:/SGYL/SM_results_data/model/CNN/','CNN_'+str(year)+'.hdf5')\n",
    "model_best.save(save_path)\n",
    "if (os.path.exists(save_path)):\n",
    "    print('save model for year:',year)\n",
    "\n",
    "#save model config\n",
    "import json\n",
    "bestConfig=tuner.get_best_hyperparameters()[0].get_config()\n",
    "f = open(os.path.join('D:/SGYL/SM_results_data/Bayesian_Opt/CNN/Best_Config/','CNN_'+str(year)+'.json'), 'w')\n",
    "json.dump(bestConfig,f)\n",
    "f.close()\n",
    "print(bestConfig['values'])\n",
    "\n",
    "model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12f4ae37f749e26047b6c90ec13e3c0736099234c7c5f03a9452dabd216507b1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('sgyl_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86e2ddda5f68ae1c79ac72022cc8c2d7af6bbc181db9ebedd4d8f03368fea52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
